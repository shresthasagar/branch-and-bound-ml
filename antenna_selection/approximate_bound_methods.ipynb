{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1e851ea",
   "metadata": {},
   "source": [
    "## Design a GNN for beamforming and beamforming with antenna selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769f117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn as nn\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NB_EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "EARLY_STOPPING = 20\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMB_SIZE = 64\n",
    "\n",
    "from models.setting import *\n",
    "\n",
    "ANTENNA_NFEATS = 2\n",
    "EDGE_NFEATS = 3\n",
    "VAR_NFEATS = 1\n",
    "\n",
    "NUM_TRAIN_H = 1000\n",
    "N, M = 8,3\n",
    "L = 5\n",
    "FCN_FEATS_SIZE = 88\n",
    "\n",
    "class FCNLowerBound(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "                    nn.Linear(FCN_FEATS_SIZE, 512),\n",
    "                    nn.BatchNorm1d(512),\n",
    "                    nn.ReLU(),\n",
    "            \n",
    "#                     nn.Linear(512, 512),\n",
    "#                     nn.BatchNorm1d(512),\n",
    "#                     nn.ReLU(),\n",
    "            \n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.BatchNorm1d(256),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "        self.z_module = torch.nn.Sequential(\n",
    "                    nn.Linear(256, 64),\n",
    "                    nn.BatchNorm1d(64),\n",
    "                    nn.ReLU(),\n",
    "                    \n",
    "                    nn.Linear(64, N),\n",
    "                    nn.Sigmoid()\n",
    "                    )\n",
    "        self.power_module = torch.nn.Sequential(\n",
    "                    nn.Linear(256, 64),\n",
    "                    nn.BatchNorm1d(64),\n",
    "                    nn.ReLU(),\n",
    "                    \n",
    "                    nn.Linear(64, 1),\n",
    "                    nn.ReLU()\n",
    "                    )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        latent = self.main(inp)\n",
    "        return self.z_module(latent), self.power_module(latent)\n",
    "\n",
    "class GNNLowerBound(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # ANTENNA EMBEDDING\n",
    "        self.antenna_embedding = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(ANTENNA_NFEATS),\n",
    "            torch.nn.Linear(ANTENNA_NFEATS, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # EDGE EMBEDDING\n",
    "        self.edge_embedding = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(EDGE_NFEATS),\n",
    "            torch.nn.Linear(EDGE_NFEATS, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # USER EMBEDDING\n",
    "        self.user_embedding = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(VAR_NFEATS),\n",
    "            torch.nn.Linear(VAR_NFEATS, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv_user_to_antenna = BipartiteGraphConvolution()\n",
    "        self.conv_antenna_to_user = BipartiteGraphConvolution()\n",
    "        self.conv_antenna_to_user_final = BipartiteGraphConvolution()\n",
    "        \n",
    "        self.output_integral_module = torch.nn.Sequential(\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, 1, bias=False),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        self.output_power_module = torch.nn.Sequential(\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, 1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return self.pass_nn(obs.antenna_features, obs.edge_index, obs.edge_attr, obs.variable_features)\n",
    "    \n",
    "    def pass_nn(self, antenna_features, edge_indices, edge_features, user_features):\n",
    "        reversed_edge_indices = torch.stack([edge_indices[1], edge_indices[0]], dim=0)\n",
    "\n",
    "        # First step: linear embedding layers to a common dimension (64)\n",
    "        antenna_features = self.antenna_embedding(antenna_features)\n",
    "        edge_features = self.edge_embedding(edge_features)\n",
    "        user_features = self.user_embedding(user_features)\n",
    "        \n",
    "        # Two half convolutions\n",
    "        user_features = self.conv_antenna_to_user(antenna_features, edge_indices, edge_features, user_features)\n",
    "        antenna_features = self.conv_user_to_antenna(user_features, reversed_edge_indices, edge_features, antenna_features)\n",
    "        \n",
    "        final_user_features = self.conv_antenna_to_user(antenna_features, edge_indices, edge_features, user_features)\n",
    "\n",
    "        # A final MLP on the antenna features\n",
    "        output_integral_relaxed = self.output_integral_module(antenna_features).squeeze(-1)\n",
    "        \n",
    "        output_power = self.output_power_module(final_user_features)\n",
    "        output_power = output_power.sum()\n",
    "        return (output_integral_relaxed, output_power)\n",
    "\n",
    "class BipartiteGraphConvolution(torch_geometric.nn.MessagePassing):\n",
    "    \"\"\"\n",
    "    The bipartite graph convolution is already provided by pytorch geometric and we merely need \n",
    "    to provide the exact form of the messages being passed.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__('add')\n",
    "        \n",
    "        self.feature_module_left = torch.nn.Sequential(\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE)\n",
    "        )\n",
    "        self.feature_module_edge = torch.nn.Sequential(\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE, bias=False)\n",
    "        )\n",
    "        self.feature_module_right = torch.nn.Sequential(\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE, bias=False)\n",
    "        )\n",
    "        self.feature_module_final = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE)\n",
    "        )\n",
    "        \n",
    "        self.post_conv_module = torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(EMB_SIZE)\n",
    "        )\n",
    "\n",
    "        # output_layers\n",
    "        self.output_module = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2*EMB_SIZE, EMB_SIZE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(EMB_SIZE, EMB_SIZE),\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, left_features, edge_indices, edge_features, right_features):\n",
    "        \"\"\"\n",
    "        This method sends the messages, computed in the message method.\n",
    "        \"\"\"\n",
    "        output = self.propagate(edge_indices, size=(left_features.shape[0], right_features.shape[0]), \n",
    "                                node_features=(left_features, right_features), edge_features=edge_features)\n",
    "        return self.output_module(torch.cat([self.post_conv_module(output), right_features], dim=-1))\n",
    "\n",
    "    def message(self, node_features_i, node_features_j, edge_features):\n",
    "        output = self.feature_module_final(self.feature_module_left(node_features_i) \n",
    "                                           + self.feature_module_edge(edge_features) \n",
    "                                           + self.feature_module_right(node_features_j))\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class LowerBoundObservation(object):\n",
    "    def __init__(self, H_complex, z_sol, z_mask):\n",
    "        self.antenna_features  = None # np.zeros(N, 3) # three features for each antenna\n",
    "        self.variable_features = None # np.zeros(M, 15)\n",
    "        \n",
    "        self.candidates        = [0] # np.arange(M)\n",
    "        \n",
    "        N, M = H_complex.shape\n",
    "        \n",
    "        # edge indices\n",
    "        self.edge_index = np.stack((np.repeat(np.arange(N), M), np.tile(np.arange(M), N)))\n",
    "        \n",
    "        # edge features definition\n",
    "        self.edge_features = np.zeros((M*N, EDGE_NFEATS))\n",
    "        self.edge_features[:,0] = np.real(H_complex.reshape(-1))\n",
    "        self.edge_features[:,1] = np.imag(H_complex.reshape(-1))\n",
    "        self.edge_features[:,2] = np.abs(H_complex.reshape(-1))\n",
    "        \n",
    "        # antenna features definition\n",
    "        self.antenna_features = np.zeros((N, ANTENNA_NFEATS))\n",
    "        self.antenna_features[:,0] = z_sol\n",
    "        self.antenna_features[:,1] = z_mask\n",
    "        \n",
    "        # user features definition\n",
    "        self.variable_features = np.ones((M, VAR_NFEATS))\n",
    "        \n",
    "    def extract(self):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class LinearLowerBoundObservation(object):\n",
    "    def __init__(self, H_complex, z_sol, z_mask):\n",
    "        self.observation = np.concatenate((np.real(H_complex.reshape(-1)), \n",
    "                                            np.imag(H_complex.reshape(-1)),\n",
    "                                            np.abs(H_complex.reshape(-1))))\n",
    "        self.observation = np.concatenate((self.observation, \n",
    "                                         z_sol.reshape(-1),\n",
    "                                         z_mask.reshape(-1)))\n",
    "        \n",
    "    def extract(self):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class LinearLowerBoundDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_filepath):\n",
    "        super().__init__()\n",
    "        with open(data_filepath, 'rb') as handle:\n",
    "            self.data = pickle.load(handle)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['out'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_observation, np_target = self.data['in'][index], self.data['out'][index]\n",
    "        \n",
    "        target = []\n",
    "        for i in range(len(np_target)):\n",
    "            target.append(torch.tensor(np_target[i]))\n",
    "        \n",
    "        return sample_observation.observation, target\n",
    "        \n",
    "    \n",
    "class GraphLowerBoundDataset(torch_geometric.data.Dataset):\n",
    "    \"\"\"\n",
    "    This class encodes a collection of graphs, as well as a method to load such graphs from the disk.\n",
    "    It can be used in turn by the data loaders provided by pytorch geometric.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_filepath):\n",
    "        super().__init__(root=None, transform=None, pre_transform=None)\n",
    "        with open(data_filepath, 'rb') as handle:\n",
    "            self.data = pickle.load(handle)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data['out'])\n",
    "\n",
    "    def get(self, index):\n",
    "        \"\"\"\n",
    "        This method loads a node bipartite graph observation as saved on the disk during data collection.\n",
    "        \"\"\"\n",
    "        \n",
    "        sample_observation, np_target = self.data['in'][index], self.data['out'][index]\n",
    "        \n",
    "        target = []\n",
    "        for i in range(len(np_target)):\n",
    "            target.append(torch.tensor(np_target[i]))\n",
    "            \n",
    "        # not important\n",
    "        candidates = torch.LongTensor(np.array([1,2,3], dtype=np.int32))\n",
    "        candidate_choice = 1 \n",
    "        sample_observation.variable_features = np.ones((M, VAR_NFEATS))\n",
    "#         print(target[2])\n",
    "        if target[2] < 0:\n",
    "            target[2] = torch.FloatTensor(np.array(0.0))\n",
    "        if target[2] > 1:\n",
    "            target[2] = torch.FloatTensor(np.array(1.0))\n",
    "        graph = BipartiteNodeData(sample_observation.antenna_features, sample_observation.edge_index, \n",
    "                                  sample_observation.edge_features, sample_observation.variable_features,\n",
    "                                  candidates, candidate_choice)\n",
    "        \n",
    "        # We must tell pytorch geometric how many nodes there are, for indexing purposes\n",
    "        graph.num_nodes = sample_observation.antenna_features.shape[0] + sample_observation.variable_features.shape[0]\n",
    "        \n",
    "        return graph, target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0ed9f",
   "metadata": {},
   "source": [
    "## GNN Relaxed antenna Beamforming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d80b5c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "  0%|          | 0/131 [00:00<?, ?it/s]/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      " 97%|█████████▋| 127/131 [00:03<00:00, 35.43it/s]/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([48])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 131/131 [00:03<00:00, 33.55it/s]\n",
      " 75%|███████▌  | 12/16 [00:00<00:00, 55.39it/s]/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([40])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.46768057346343994, valid loss: 0.516101598739624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.77it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 39.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.4719253480434418, valid loss: 0.5957508683204651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:04<00:00, 32.33it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.4462070167064667, valid loss: 0.46035444736480713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.90it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.48023152351379395, valid loss: 0.47765105962753296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.02it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.35952210426330566, valid loss: 0.4718726873397827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 34.59it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3700847327709198, valid loss: 0.3989936113357544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.30it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.33503299951553345, valid loss: 0.381969690322876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.28it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.28115931153297424, valid loss: 0.3679596185684204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.36it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 62.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.4388917088508606, valid loss: 0.44196709990501404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.54it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 64.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3091740906238556, valid loss: 0.34988826513290405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.40it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 62.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.36405619978904724, valid loss: 0.37657418847084045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 34.72it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 50.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.40158557891845703, valid loss: 0.40566450357437134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.58it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30892086029052734, valid loss: 0.36241692304611206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 34.70it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3142533004283905, valid loss: 0.3748288154602051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.85it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.33063623309135437, valid loss: 0.35942667722702026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.37it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3051203787326813, valid loss: 0.40703001618385315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 36.72it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.27392786741256714, valid loss: 0.43701863288879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.17it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2951206564903259, valid loss: 0.43457189202308655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.66it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.34776854515075684, valid loss: 0.3643620014190674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.09it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.345192551612854, valid loss: 0.3283292055130005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.46it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.34427410364151, valid loss: 0.39938682317733765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.11it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.255595862865448, valid loss: 0.35498422384262085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.46it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.33751314878463745, valid loss: 0.40878725051879883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.78it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3053927421569824, valid loss: 0.3582421839237213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.288928747177124, valid loss: 0.40208637714385986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.35it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3050110340118408, valid loss: 0.3775705099105835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.47it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 61.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.31519025564193726, valid loss: 0.34794652462005615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 43.85it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3189358711242676, valid loss: 0.30903729796409607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.37it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 63.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.27615416049957275, valid loss: 0.3153423070907593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 44.09it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3023919463157654, valid loss: 0.2694651484489441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.14it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3538574278354645, valid loss: 0.4297703802585602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 46.98it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 71.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.29183074831962585, valid loss: 0.380098819732666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 45.06it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 62.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.301535964012146, valid loss: 0.34500235319137573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.85it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30894601345062256, valid loss: 0.37638944387435913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.67it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3655066192150116, valid loss: 0.36209362745285034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.28it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 47.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.31906646490097046, valid loss: 0.3998977243900299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.61it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.27796217799186707, valid loss: 0.36761757731437683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.31it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 48.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2966352105140686, valid loss: 0.332929790019989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.36it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.35089901089668274, valid loss: 0.3842630386352539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.57it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 58.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.32792532444000244, valid loss: 0.40205469727516174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.89it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 62.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.35304492712020874, valid loss: 0.3564513325691223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.63it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.37093669176101685, valid loss: 0.40458962321281433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.08it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2897804379463196, valid loss: 0.3721744418144226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.07it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30437105894088745, valid loss: 0.35795626044273376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 45.31it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 67.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.27421119809150696, valid loss: 0.37516844272613525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 45.40it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 71.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2957090735435486, valid loss: 0.3496364951133728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.45it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 69.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2807910144329071, valid loss: 0.39877116680145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 46.55it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 63.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.31776192784309387, valid loss: 0.3810705840587616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 36.08it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30909693241119385, valid loss: 0.3386942446231842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.38it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.26978811621665955, valid loss: 0.4106333255767822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 33.95it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3508056402206421, valid loss: 0.3934006094932556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.43it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 49.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.26659074425697327, valid loss: 0.31355953216552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 35.53it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 50.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2745888829231262, valid loss: 0.3166998326778412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.24it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3109041452407837, valid loss: 0.3962063789367676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.35it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.304914653301239, valid loss: 0.31430840492248535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 36.80it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 52.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3119797110557556, valid loss: 0.3594144880771637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 35.92it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30758872628211975, valid loss: 0.338541179895401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 34.90it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30143216252326965, valid loss: 0.3563607931137085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 36.75it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 49.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3354279398918152, valid loss: 0.40420666337013245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.79it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 62.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.31096023321151733, valid loss: 0.3403853178024292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.22it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 64.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.29343631863594055, valid loss: 0.35941725969314575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 46.05it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 68.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3182772099971771, valid loss: 0.3439257740974426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 46.43it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3521653413772583, valid loss: 0.3356936573982239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 45.46it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 61.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.31794196367263794, valid loss: 0.3987475633621216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.93it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 59.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30010390281677246, valid loss: 0.36217063665390015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.11it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2679130733013153, valid loss: 0.3055421710014343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:04<00:00, 30.44it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2885948121547699, valid loss: 0.34908562898635864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.44it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2767467796802521, valid loss: 0.31977221369743347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.09it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2996816039085388, valid loss: 0.3179095983505249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.42it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.34432679414749146, valid loss: 0.380767285823822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.59it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 51.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.275278776884079, valid loss: 0.39986929297447205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.36it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 56.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.285375714302063, valid loss: 0.3704702854156494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.85it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3046683073043823, valid loss: 0.3648768961429596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.19it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 51.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3022057116031647, valid loss: 0.33929622173309326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.81it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.33048805594444275, valid loss: 0.3746638894081116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.69it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 51.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.29886263608932495, valid loss: 0.2966708838939667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 45.02it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 66.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2390182614326477, valid loss: 0.35082852840423584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.00it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 50.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.31662672758102417, valid loss: 0.4167730510234833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.66it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 64.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3147980868816376, valid loss: 0.35410478711128235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 42.97it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 65.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2659808397293091, valid loss: 0.3348965048789978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.65it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 50.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3281403183937073, valid loss: 0.34352850914001465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.18it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 46.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.28543993830680847, valid loss: 0.3429262042045593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.83it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2850934863090515, valid loss: 0.37559205293655396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 39.49it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2883685231208801, valid loss: 0.35485124588012695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.43it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3327752351760864, valid loss: 0.32663607597351074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 36.65it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 58.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.36730024218559265, valid loss: 0.3855200409889221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.25it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 54.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3141593337059021, valid loss: 0.39355990290641785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 36.69it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 50.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3352273106575012, valid loss: 0.4152200222015381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 35.73it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 33.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.2857319712638855, valid loss: 0.325951486825943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 33.33it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 52.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.32735711336135864, valid loss: 0.3281105160713196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 34.27it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 53.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.28879380226135254, valid loss: 0.3672609329223633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 35.77it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.34054604172706604, valid loss: 0.39036843180656433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.06it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3202846646308899, valid loss: 0.31636595726013184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 43.30it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 58.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3082285225391388, valid loss: 0.3487163186073303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 41.41it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 61.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.29907718300819397, valid loss: 0.33747726678848267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:02<00:00, 44.96it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 60.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.28450217843055725, valid loss: 0.40423834323883057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.24it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.33732882142066956, valid loss: 0.41096457839012146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 38.70it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 55.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.26592129468917847, valid loss: 0.31281042098999023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 37.82it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 57.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.30652856826782227, valid loss: 0.4382251799106598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131/131 [00:03<00:00, 40.19it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 48.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.32280561327934265, valid loss: 0.3482179641723633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "from models.gnn_dataset import *\n",
    "\n",
    "### Train the GNN policy using supervised learning (L2-norm loss)\n",
    "\n",
    "# Instantiate model and training parameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "wt_power = 1\n",
    "Device = 'cuda'\n",
    "\n",
    "model = GNNLowerBound()\n",
    "model = model.to(Device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "data_filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/trainset1_pruned.pkl'\n",
    "train_dataset = GraphLowerBoundDataset(data_filepath)\n",
    "train_dataloader = torch_geometric.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/validset1_pruned.pkl'\n",
    "valid_dataset =  GraphLowerBoundDataset(valid_filepath)\n",
    "valid_dataloader = torch_geometric.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss_sum = 0\n",
    "    for batch in tqdm(train_dataloader):        \n",
    "        graph, (z_target, _, power_target) = batch\n",
    "        graph = graph.to(Device)\n",
    "        z_target = z_target.to(Device).to(torch.float32)\n",
    "        power_target = power_target.to(Device).to(torch.float32)\n",
    "        \n",
    "        z_out, power_out = model(graph)\n",
    "#         print(loss_func(z_out, z_target.flatten()), wt_power*loss_func(power_out, power_target))\n",
    "        train_loss = loss_func(z_out, z_target.flatten()) + wt_power*loss_func(power_out, power_target)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_sum += train_loss.item()\n",
    "    train_losses.append(train_loss_sum/(len(train_dataset)/batch_size))\n",
    "#         print(next(model.parameters()))\n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    valid_loss_sum = 0\n",
    "    for batch in tqdm(valid_dataloader):\n",
    "        graph, (z_target, _, power_target) = batch\n",
    "        graph = graph.to(Device)\n",
    "        z_target = z_target.to(Device).to(torch.float32)\n",
    "        power_target = power_target.to(Device).to(torch.float32)\n",
    "        \n",
    "        z_out, power_out = model(graph)\n",
    "        valid_loss = loss_func(z_out, z_target.flatten()) + wt_power*loss_func(power_out, power_target) \n",
    "        valid_loss_sum += valid_loss.item()\n",
    "    valid_losses.append(valid_loss_sum/(len(valid_dataset)/batch_size))\n",
    "        \n",
    "    print('training loss: {}, valid loss: {}'.format(train_loss, valid_loss) )\n",
    "        \n",
    "\n",
    "# Using the supervised model do antenna selection with branch and bound (as_bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e438f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1516af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save( model.to('cpu').eval().state_dict(),'trained_models/lower_bound_gnn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a0aada6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNLowerBound(\n",
       "  (antenna_embedding): Sequential(\n",
       "    (0): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (edge_embedding): Sequential(\n",
       "    (0): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (user_embedding): Sequential(\n",
       "    (0): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (conv_user_to_antenna): BipartiteGraphConvolution(\n",
       "    (feature_module_left): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (feature_module_edge): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "    (feature_module_right): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "    (feature_module_final): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (post_conv_module): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (output_module): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_antenna_to_user): BipartiteGraphConvolution(\n",
       "    (feature_module_left): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (feature_module_edge): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "    (feature_module_right): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "    (feature_module_final): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (post_conv_module): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (output_module): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_antenna_to_user_final): BipartiteGraphConvolution(\n",
       "    (feature_module_left): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (feature_module_edge): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "    (feature_module_right): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "    (feature_module_final): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (post_conv_module): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (output_module): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (output_integral_module): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (output_power_module): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560af7e9",
   "metadata": {},
   "source": [
    "## FCN Relaxed antenna Beamforming Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbb2ac91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, lr: 0.01, bs: 32, btraining loss: 0.42861735820770264, valid loss: 0.620774507522583\n",
      "epoch: 1, lr: 0.01, bs: 32, btraining loss: 0.1980932503938675, valid loss: 0.16368108987808228\n",
      "epoch: 2, lr: 0.01, bs: 32, btraining loss: 0.2511577606201172, valid loss: 0.1387057900428772\n",
      "epoch: 3, lr: 0.01, bs: 32, btraining loss: 0.34826773405075073, valid loss: 0.1005231961607933\n",
      "epoch: 4, lr: 0.01, bs: 32, btraining loss: 0.278256893157959, valid loss: 0.0837225466966629\n",
      "epoch: 5, lr: 0.01, bs: 32, btraining loss: 0.2947612404823303, valid loss: 0.08160193264484406\n",
      "epoch: 6, lr: 0.01, bs: 32, btraining loss: 0.15046468377113342, valid loss: 0.09768325090408325\n",
      "epoch: 7, lr: 0.01, bs: 32, btraining loss: 0.1726491004228592, valid loss: 0.08520328998565674\n",
      "epoch: 8, lr: 0.01, bs: 32, btraining loss: 0.20644529163837433, valid loss: 0.13015218079090118\n",
      "epoch: 9, lr: 0.01, bs: 32, btraining loss: 0.21209506690502167, valid loss: 0.08680062741041183\n",
      "epoch: 10, lr: 0.01, bs: 32, btraining loss: 0.2516207993030548, valid loss: 0.14709056913852692\n",
      "epoch: 11, lr: 0.01, bs: 32, btraining loss: 0.3293854594230652, valid loss: 0.19932608306407928\n",
      "epoch: 12, lr: 0.01, bs: 32, btraining loss: 0.30607572197914124, valid loss: 0.09555547684431076\n",
      "epoch: 13, lr: 0.01, bs: 32, btraining loss: 0.19939585030078888, valid loss: 0.21674244105815887\n",
      "epoch: 14, lr: 0.01, bs: 32, btraining loss: 0.14896836876869202, valid loss: 0.1849658489227295\n",
      "epoch: 15, lr: 0.01, bs: 32, btraining loss: 0.34294360876083374, valid loss: 0.16077207028865814\n",
      "epoch: 16, lr: 0.01, bs: 32, btraining loss: 0.1428578495979309, valid loss: 0.13521236181259155\n",
      "epoch: 17, lr: 0.01, bs: 32, btraining loss: 0.14008215069770813, valid loss: 0.2307313233613968\n",
      "epoch: 18, lr: 0.01, bs: 32, btraining loss: 0.24691364169120789, valid loss: 0.1468350887298584\n",
      "epoch: 19, lr: 0.01, bs: 32, btraining loss: 0.297899067401886, valid loss: 0.12393271923065186\n",
      "epoch: 20, lr: 0.01, bs: 32, btraining loss: 0.17228913307189941, valid loss: 0.3340609073638916\n",
      "epoch: 21, lr: 0.01, bs: 32, btraining loss: 0.24002116918563843, valid loss: 0.395844042301178\n",
      "epoch: 22, lr: 0.01, bs: 32, btraining loss: 0.12076519429683685, valid loss: 0.12944234907627106\n",
      "epoch: 23, lr: 0.01, bs: 32, btraining loss: 0.19110165536403656, valid loss: 0.11333300173282623\n",
      "epoch: 24, lr: 0.01, bs: 32, btraining loss: 0.1665932536125183, valid loss: 0.10148138552904129\n",
      "epoch: 25, lr: 0.01, bs: 32, btraining loss: 0.22628548741340637, valid loss: 0.13148346543312073\n",
      "epoch: 26, lr: 0.01, bs: 32, btraining loss: 0.3251906633377075, valid loss: 0.15389569103717804\n",
      "epoch: 27, lr: 0.01, bs: 32, btraining loss: 0.23946698009967804, valid loss: 0.13170868158340454\n",
      "epoch: 28, lr: 0.01, bs: 32, btraining loss: 0.2874489426612854, valid loss: 0.19842828810214996\n",
      "epoch: 29, lr: 0.01, bs: 32, btraining loss: 0.31906023621559143, valid loss: 0.21588146686553955\n",
      "epoch: 30, lr: 0.01, bs: 32, btraining loss: 0.1464059203863144, valid loss: 0.1231556236743927\n",
      "epoch: 31, lr: 0.01, bs: 32, btraining loss: 0.3179328143596649, valid loss: 0.07355070114135742\n",
      "epoch: 32, lr: 0.01, bs: 32, btraining loss: 0.33335840702056885, valid loss: 0.25897783041000366\n",
      "epoch: 33, lr: 0.01, bs: 32, btraining loss: 0.2571070194244385, valid loss: 0.8748995661735535\n",
      "epoch: 34, lr: 0.01, bs: 32, btraining loss: 0.18481673300266266, valid loss: 0.13783840835094452\n",
      "epoch: 35, lr: 0.01, bs: 32, btraining loss: 0.22389395534992218, valid loss: 0.1136246845126152\n",
      "epoch: 36, lr: 0.01, bs: 32, btraining loss: 0.23412151634693146, valid loss: 0.046687375754117966\n",
      "epoch: 37, lr: 0.01, bs: 32, btraining loss: 0.25404092669487, valid loss: 0.11389023810625076\n",
      "epoch: 38, lr: 0.01, bs: 32, btraining loss: 0.5390449166297913, valid loss: 0.551872968673706\n",
      "epoch: 39, lr: 0.01, bs: 32, btraining loss: 0.1258726716041565, valid loss: 0.16574303805828094\n",
      "epoch: 40, lr: 0.01, bs: 32, btraining loss: 0.15558423101902008, valid loss: 0.6261515617370605\n",
      "epoch: 41, lr: 0.01, bs: 32, btraining loss: 0.1648235023021698, valid loss: 0.3439195156097412\n",
      "epoch: 42, lr: 0.01, bs: 32, btraining loss: 0.22443760931491852, valid loss: 0.775443434715271\n",
      "epoch: 43, lr: 0.01, bs: 32, btraining loss: 0.21186742186546326, valid loss: 0.05753450468182564\n",
      "epoch: 44, lr: 0.01, bs: 32, btraining loss: 0.16487206518650055, valid loss: 0.14008687436580658\n",
      "epoch: 45, lr: 0.01, bs: 32, btraining loss: 0.15186099708080292, valid loss: 0.06922672688961029\n",
      "epoch: 46, lr: 0.01, bs: 32, btraining loss: 0.33491867780685425, valid loss: 0.08657144010066986\n",
      "epoch: 47, lr: 0.01, bs: 32, btraining loss: 0.14819398522377014, valid loss: 0.07735946029424667\n",
      "epoch: 48, lr: 0.01, bs: 32, btraining loss: 0.18806247413158417, valid loss: 0.13390986621379852\n",
      "epoch: 49, lr: 0.01, bs: 32, btraining loss: 0.16843293607234955, valid loss: 0.12155447900295258\n",
      "epoch: 50, lr: 0.01, bs: 32, btraining loss: 0.23534272611141205, valid loss: 0.15589506924152374\n",
      "epoch: 51, lr: 0.01, bs: 32, btraining loss: 0.17971175909042358, valid loss: 0.3594233989715576\n",
      "epoch: 52, lr: 0.01, bs: 32, btraining loss: 0.16440556943416595, valid loss: 0.11115701496601105\n",
      "epoch: 53, lr: 0.01, bs: 32, btraining loss: 0.22741581499576569, valid loss: 0.238925963640213\n",
      "epoch: 54, lr: 0.01, bs: 32, btraining loss: 0.3312264680862427, valid loss: 0.09148772060871124\n",
      "epoch: 55, lr: 0.01, bs: 32, btraining loss: 0.30825531482696533, valid loss: 0.5661605596542358\n",
      "epoch: 56, lr: 0.01, bs: 32, btraining loss: 0.18711376190185547, valid loss: 0.17309559881687164\n",
      "epoch: 57, lr: 0.01, bs: 32, btraining loss: 0.13449175655841827, valid loss: 0.5975548028945923\n",
      "epoch: 58, lr: 0.01, bs: 32, btraining loss: 0.24116353690624237, valid loss: 0.057816434651613235\n",
      "epoch: 59, lr: 0.01, bs: 32, btraining loss: 0.19266219437122345, valid loss: 0.16988524794578552\n",
      "epoch: 60, lr: 0.01, bs: 32, btraining loss: 0.20107650756835938, valid loss: 0.07032464444637299\n",
      "epoch: 61, lr: 0.01, bs: 32, btraining loss: 0.1978580355644226, valid loss: 0.334057480096817\n",
      "epoch: 62, lr: 0.01, bs: 32, btraining loss: 0.2103976607322693, valid loss: 0.11792320013046265\n",
      "epoch: 63, lr: 0.01, bs: 32, btraining loss: 0.19741374254226685, valid loss: 0.05762987211346626\n",
      "epoch: 64, lr: 0.01, bs: 32, btraining loss: 0.17008155584335327, valid loss: 0.1061987355351448\n",
      "epoch: 65, lr: 0.01, bs: 32, btraining loss: 0.2294180542230606, valid loss: 0.6727237701416016\n",
      "epoch: 66, lr: 0.01, bs: 32, btraining loss: 0.24659200012683868, valid loss: 0.056205376982688904\n",
      "epoch: 67, lr: 0.01, bs: 32, btraining loss: 0.1654798835515976, valid loss: 0.15247274935245514\n",
      "epoch: 68, lr: 0.01, bs: 32, btraining loss: 0.2526342272758484, valid loss: 0.1325710117816925\n",
      "epoch: 69, lr: 0.01, bs: 32, btraining loss: 0.2163073569536209, valid loss: 0.14035582542419434\n",
      "epoch: 70, lr: 0.01, bs: 32, btraining loss: 0.14520163834095, valid loss: 0.5881087779998779\n",
      "epoch: 71, lr: 0.01, bs: 32, btraining loss: 0.2748861312866211, valid loss: 0.07947313040494919\n",
      "epoch: 72, lr: 0.01, bs: 32, btraining loss: 0.28543561697006226, valid loss: 0.18686208128929138\n",
      "epoch: 73, lr: 0.01, bs: 32, btraining loss: 0.20155134797096252, valid loss: 0.07224778085947037\n",
      "epoch: 74, lr: 0.01, bs: 32, btraining loss: 0.1415160894393921, valid loss: 0.5085384249687195\n",
      "epoch: 75, lr: 0.01, bs: 32, btraining loss: 0.16287057101726532, valid loss: 0.023513352498412132\n",
      "epoch: 76, lr: 0.01, bs: 32, btraining loss: 0.14581739902496338, valid loss: 0.20427392423152924\n",
      "epoch: 77, lr: 0.01, bs: 32, btraining loss: 0.15857619047164917, valid loss: 0.22162975370883942\n",
      "epoch: 78, lr: 0.01, bs: 32, btraining loss: 0.2335870862007141, valid loss: 0.06433726102113724\n",
      "epoch: 79, lr: 0.01, bs: 32, btraining loss: 0.1562977284193039, valid loss: 0.06503195315599442\n",
      "epoch: 80, lr: 0.01, bs: 32, btraining loss: 0.22651875019073486, valid loss: 0.6990949511528015\n",
      "epoch: 81, lr: 0.01, bs: 32, btraining loss: 0.19672639667987823, valid loss: 0.08686026930809021\n",
      "epoch: 82, lr: 0.01, bs: 32, btraining loss: 0.18374241888523102, valid loss: 0.2093062698841095\n",
      "epoch: 83, lr: 0.01, bs: 32, btraining loss: 0.20552444458007812, valid loss: 0.27687573432922363\n",
      "epoch: 84, lr: 0.01, bs: 32, btraining loss: 0.13772717118263245, valid loss: 0.6088598966598511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85, lr: 0.01, bs: 32, btraining loss: 0.20617803931236267, valid loss: 0.04368310421705246\n",
      "epoch: 86, lr: 0.01, bs: 32, btraining loss: 0.27887749671936035, valid loss: 0.1301981508731842\n",
      "epoch: 87, lr: 0.01, bs: 32, btraining loss: 0.16623005270957947, valid loss: 0.09551891684532166\n",
      "epoch: 88, lr: 0.01, bs: 32, btraining loss: 0.2498883157968521, valid loss: 0.07278881222009659\n",
      "epoch: 89, lr: 0.01, bs: 32, btraining loss: 0.2552330493927002, valid loss: 0.08410249650478363\n",
      "epoch: 90, lr: 0.01, bs: 32, btraining loss: 0.2655291259288788, valid loss: 0.4106316566467285\n",
      "epoch: 91, lr: 0.01, bs: 32, btraining loss: 0.2497379034757614, valid loss: 0.08771899342536926\n",
      "epoch: 92, lr: 0.01, bs: 32, btraining loss: 0.3539169728755951, valid loss: 0.16160091757774353\n",
      "epoch: 93, lr: 0.01, bs: 32, btraining loss: 0.22796094417572021, valid loss: 0.44299566745758057\n",
      "epoch: 94, lr: 0.01, bs: 32, btraining loss: 0.22112859785556793, valid loss: 0.24217849969863892\n",
      "epoch: 95, lr: 0.01, bs: 32, btraining loss: 0.13670316338539124, valid loss: 0.1464204043149948\n",
      "epoch: 96, lr: 0.01, bs: 32, btraining loss: 0.16049522161483765, valid loss: 0.03735751658678055\n",
      "epoch: 97, lr: 0.01, bs: 32, btraining loss: 0.12879504263401031, valid loss: 0.15685944259166718\n",
      "epoch: 98, lr: 0.01, bs: 32, btraining loss: 0.2336442619562149, valid loss: 0.04395349323749542\n",
      "epoch: 99, lr: 0.01, bs: 32, btraining loss: 0.2089773714542389, valid loss: 0.04266045615077019\n",
      "epoch: 0, lr: 0.01, bs: 64, btraining loss: 0.24193279445171356, valid loss: 0.285624235868454\n",
      "epoch: 1, lr: 0.01, bs: 64, btraining loss: 0.17829662561416626, valid loss: 0.1389082968235016\n",
      "epoch: 2, lr: 0.01, bs: 64, btraining loss: 0.16791923344135284, valid loss: 0.1094069704413414\n",
      "epoch: 3, lr: 0.01, bs: 64, btraining loss: 0.1644705981016159, valid loss: 0.18869461119174957\n",
      "epoch: 4, lr: 0.01, bs: 64, btraining loss: 0.19294138252735138, valid loss: 0.11652317643165588\n",
      "epoch: 5, lr: 0.01, bs: 64, btraining loss: 0.3002130091190338, valid loss: 0.0364663265645504\n",
      "epoch: 6, lr: 0.01, bs: 64, btraining loss: 0.3017385005950928, valid loss: 0.12363161891698837\n",
      "epoch: 7, lr: 0.01, bs: 64, btraining loss: 0.1407439410686493, valid loss: 0.03037475049495697\n",
      "epoch: 8, lr: 0.01, bs: 64, btraining loss: 0.1407553255558014, valid loss: 0.7778633236885071\n",
      "epoch: 9, lr: 0.01, bs: 64, btraining loss: 0.17793799936771393, valid loss: 0.12074720859527588\n",
      "epoch: 10, lr: 0.01, bs: 64, btraining loss: 0.22806316614151, valid loss: 0.04036903753876686\n",
      "epoch: 11, lr: 0.01, bs: 64, btraining loss: 0.18800756335258484, valid loss: 1.073907494544983\n",
      "epoch: 12, lr: 0.01, bs: 64, btraining loss: 0.20546992123126984, valid loss: 0.14709462225437164\n",
      "epoch: 13, lr: 0.01, bs: 64, btraining loss: 0.23173414170742035, valid loss: 0.5721685290336609\n",
      "epoch: 14, lr: 0.01, bs: 64, btraining loss: 0.21110600233078003, valid loss: 0.5799105167388916\n",
      "epoch: 15, lr: 0.01, bs: 64, btraining loss: 0.1463266909122467, valid loss: 0.2165004014968872\n",
      "epoch: 16, lr: 0.01, bs: 64, btraining loss: 0.17748498916625977, valid loss: 0.1336565762758255\n",
      "epoch: 17, lr: 0.01, bs: 64, btraining loss: 0.22601798176765442, valid loss: 0.3421841263771057\n",
      "epoch: 18, lr: 0.01, bs: 64, btraining loss: 0.21600309014320374, valid loss: 0.17088457942008972\n",
      "epoch: 19, lr: 0.01, bs: 64, btraining loss: 0.15874740481376648, valid loss: 0.15015248954296112\n",
      "epoch: 20, lr: 0.01, bs: 64, btraining loss: 0.26613375544548035, valid loss: 0.13177147507667542\n",
      "epoch: 21, lr: 0.01, bs: 64, btraining loss: 0.12409702688455582, valid loss: 0.7549650073051453\n",
      "epoch: 22, lr: 0.01, bs: 64, btraining loss: 0.19551774859428406, valid loss: 0.28827527165412903\n",
      "epoch: 23, lr: 0.01, bs: 64, btraining loss: 0.1536305695772171, valid loss: 0.0682142823934555\n",
      "epoch: 24, lr: 0.01, bs: 64, btraining loss: 0.16859348118305206, valid loss: 0.1020117998123169\n",
      "epoch: 25, lr: 0.01, bs: 64, btraining loss: 0.14923465251922607, valid loss: 0.6199086904525757\n",
      "epoch: 26, lr: 0.01, bs: 64, btraining loss: 0.1723986715078354, valid loss: 0.5091444849967957\n",
      "epoch: 27, lr: 0.01, bs: 64, btraining loss: 0.23501135408878326, valid loss: 0.27951371669769287\n",
      "epoch: 28, lr: 0.01, bs: 64, btraining loss: 0.22398152947425842, valid loss: 0.49446114897727966\n",
      "epoch: 29, lr: 0.01, bs: 64, btraining loss: 0.17514750361442566, valid loss: 0.1612716168165207\n",
      "epoch: 30, lr: 0.01, bs: 64, btraining loss: 0.2014021873474121, valid loss: 0.4950224459171295\n",
      "epoch: 31, lr: 0.01, bs: 64, btraining loss: 0.19850674271583557, valid loss: 0.11464408040046692\n",
      "epoch: 32, lr: 0.01, bs: 64, btraining loss: 0.182663232088089, valid loss: 0.12017768621444702\n",
      "epoch: 33, lr: 0.01, bs: 64, btraining loss: 0.1738881915807724, valid loss: 0.46334975957870483\n",
      "epoch: 34, lr: 0.01, bs: 64, btraining loss: 0.25244417786598206, valid loss: 0.6391996145248413\n",
      "epoch: 35, lr: 0.01, bs: 64, btraining loss: 0.20265193283557892, valid loss: 0.08617410063743591\n",
      "epoch: 36, lr: 0.01, bs: 64, btraining loss: 0.23014385998249054, valid loss: 0.0889686867594719\n",
      "epoch: 37, lr: 0.01, bs: 64, btraining loss: 0.16268324851989746, valid loss: 0.367515504360199\n",
      "epoch: 38, lr: 0.01, bs: 64, btraining loss: 0.16490596532821655, valid loss: 0.21710732579231262\n",
      "epoch: 39, lr: 0.01, bs: 64, btraining loss: 0.14888204634189606, valid loss: 0.1317025125026703\n",
      "epoch: 40, lr: 0.01, bs: 64, btraining loss: 0.14354994893074036, valid loss: 0.5602155923843384\n",
      "epoch: 41, lr: 0.01, bs: 64, btraining loss: 0.24309246242046356, valid loss: 0.28132471442222595\n",
      "epoch: 42, lr: 0.01, bs: 64, btraining loss: 0.1782497614622116, valid loss: 0.7770556211471558\n",
      "epoch: 43, lr: 0.01, bs: 64, btraining loss: 0.19125370681285858, valid loss: 0.10242748260498047\n",
      "epoch: 44, lr: 0.01, bs: 64, btraining loss: 0.17752386629581451, valid loss: 0.38219717144966125\n",
      "epoch: 45, lr: 0.01, bs: 64, btraining loss: 0.21627718210220337, valid loss: 0.1585855334997177\n",
      "epoch: 46, lr: 0.01, bs: 64, btraining loss: 0.13954833149909973, valid loss: 0.03830796480178833\n",
      "epoch: 47, lr: 0.01, bs: 64, btraining loss: 0.2378184050321579, valid loss: 0.02373177744448185\n",
      "epoch: 48, lr: 0.01, bs: 64, btraining loss: 0.2051328420639038, valid loss: 0.08301713317632675\n",
      "epoch: 49, lr: 0.01, bs: 64, btraining loss: 0.21022579073905945, valid loss: 0.3617357015609741\n",
      "epoch: 50, lr: 0.01, bs: 64, btraining loss: 0.1934564709663391, valid loss: 0.10035115480422974\n",
      "epoch: 51, lr: 0.01, bs: 64, btraining loss: 0.24136579036712646, valid loss: 0.09254156798124313\n",
      "epoch: 52, lr: 0.01, bs: 64, btraining loss: 0.2121148407459259, valid loss: 0.24946746230125427\n",
      "epoch: 53, lr: 0.01, bs: 64, btraining loss: 0.2218191921710968, valid loss: 0.08927802741527557\n",
      "epoch: 54, lr: 0.01, bs: 64, btraining loss: 0.12580962479114532, valid loss: 0.13330577313899994\n",
      "epoch: 55, lr: 0.01, bs: 64, btraining loss: 0.2157006561756134, valid loss: 0.19354775547981262\n",
      "epoch: 56, lr: 0.01, bs: 64, btraining loss: 0.19384412467479706, valid loss: 0.1681925356388092\n",
      "epoch: 57, lr: 0.01, bs: 64, btraining loss: 0.20319810509681702, valid loss: 0.09658773243427277\n",
      "epoch: 58, lr: 0.01, bs: 64, btraining loss: 0.15710841119289398, valid loss: 0.10729784518480301\n",
      "epoch: 59, lr: 0.01, bs: 64, btraining loss: 0.24709691107273102, valid loss: 0.09662781655788422\n",
      "epoch: 60, lr: 0.01, bs: 64, btraining loss: 0.1945626437664032, valid loss: 0.33693093061447144\n",
      "epoch: 61, lr: 0.01, bs: 64, btraining loss: 0.2065526694059372, valid loss: 0.3066427707672119\n",
      "epoch: 62, lr: 0.01, bs: 64, btraining loss: 0.19711868464946747, valid loss: 0.059690073132514954\n",
      "epoch: 63, lr: 0.01, bs: 64, btraining loss: 0.14448213577270508, valid loss: 0.1289098858833313\n",
      "epoch: 64, lr: 0.01, bs: 64, btraining loss: 0.21968841552734375, valid loss: 0.08803151547908783\n",
      "epoch: 65, lr: 0.01, bs: 64, btraining loss: 0.22971752285957336, valid loss: 0.030231226235628128\n",
      "epoch: 66, lr: 0.01, bs: 64, btraining loss: 0.17987048625946045, valid loss: 0.09427271783351898\n",
      "epoch: 67, lr: 0.01, bs: 64, btraining loss: 0.14446592330932617, valid loss: 0.16035263240337372\n",
      "epoch: 68, lr: 0.01, bs: 64, btraining loss: 0.2542494833469391, valid loss: 0.27547091245651245\n",
      "epoch: 69, lr: 0.01, bs: 64, btraining loss: 0.2318185567855835, valid loss: 0.2172321081161499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 70, lr: 0.01, bs: 64, btraining loss: 0.1746852844953537, valid loss: 0.13959725201129913\n",
      "epoch: 71, lr: 0.01, bs: 64, btraining loss: 0.1550050526857376, valid loss: 0.13410373032093048\n",
      "epoch: 72, lr: 0.01, bs: 64, btraining loss: 0.23616857826709747, valid loss: 0.2957310378551483\n",
      "epoch: 73, lr: 0.01, bs: 64, btraining loss: 0.15014448761940002, valid loss: 0.1456078439950943\n",
      "epoch: 74, lr: 0.01, bs: 64, btraining loss: 0.3400086462497711, valid loss: 0.4472547173500061\n",
      "epoch: 75, lr: 0.01, bs: 64, btraining loss: 0.18218840658664703, valid loss: 0.14871864020824432\n",
      "epoch: 76, lr: 0.01, bs: 64, btraining loss: 0.1661524921655655, valid loss: 0.0913306400179863\n",
      "epoch: 77, lr: 0.01, bs: 64, btraining loss: 0.17897862195968628, valid loss: 0.10661643743515015\n",
      "epoch: 78, lr: 0.01, bs: 64, btraining loss: 0.16879519820213318, valid loss: 0.281566858291626\n",
      "epoch: 79, lr: 0.01, bs: 64, btraining loss: 0.204035684466362, valid loss: 0.2604861259460449\n",
      "epoch: 80, lr: 0.01, bs: 64, btraining loss: 0.1377461552619934, valid loss: 0.3288935124874115\n",
      "epoch: 81, lr: 0.01, bs: 64, btraining loss: 0.22846539318561554, valid loss: 0.08106149733066559\n",
      "epoch: 82, lr: 0.01, bs: 64, btraining loss: 0.191311776638031, valid loss: 0.08402642607688904\n",
      "epoch: 83, lr: 0.01, bs: 64, btraining loss: 0.2071709781885147, valid loss: 0.11771459877490997\n",
      "epoch: 84, lr: 0.01, bs: 64, btraining loss: 0.214167982339859, valid loss: 0.03630051761865616\n",
      "epoch: 85, lr: 0.01, bs: 64, btraining loss: 0.1775089055299759, valid loss: 0.10357276350259781\n",
      "epoch: 86, lr: 0.01, bs: 64, btraining loss: 0.18809007108211517, valid loss: 0.11760929226875305\n",
      "epoch: 87, lr: 0.01, bs: 64, btraining loss: 0.21449072659015656, valid loss: 0.08041290938854218\n",
      "epoch: 88, lr: 0.01, bs: 64, btraining loss: 0.21506646275520325, valid loss: 0.055272310972213745\n",
      "epoch: 89, lr: 0.01, bs: 64, btraining loss: 0.12237571179866791, valid loss: 0.22908951342105865\n",
      "epoch: 90, lr: 0.01, bs: 64, btraining loss: 0.15723170340061188, valid loss: 0.13422465324401855\n",
      "epoch: 91, lr: 0.01, bs: 64, btraining loss: 0.21876142919063568, valid loss: 0.017063617706298828\n",
      "epoch: 92, lr: 0.01, bs: 64, btraining loss: 0.1841953545808792, valid loss: 0.06087605655193329\n",
      "epoch: 93, lr: 0.01, bs: 64, btraining loss: 0.14577369391918182, valid loss: 0.10144003480672836\n",
      "epoch: 94, lr: 0.01, bs: 64, btraining loss: 0.15057691931724548, valid loss: 0.10644177347421646\n",
      "epoch: 95, lr: 0.01, bs: 64, btraining loss: 0.1650286763906479, valid loss: 0.2014179825782776\n",
      "epoch: 96, lr: 0.01, bs: 64, btraining loss: 0.13221029937267303, valid loss: 0.1409563571214676\n",
      "epoch: 97, lr: 0.01, bs: 64, btraining loss: 0.11074579507112503, valid loss: 0.07724957168102264\n",
      "epoch: 98, lr: 0.01, bs: 64, btraining loss: 0.18569953739643097, valid loss: 0.05625326931476593\n",
      "epoch: 99, lr: 0.01, bs: 64, btraining loss: 0.1728692650794983, valid loss: 0.1476336419582367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([66])) that is different to the input size (torch.Size([66, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, lr: 0.01, bs: 128, btraining loss: 0.2462499439716339, valid loss: 0.15773998200893402\n",
      "epoch: 1, lr: 0.01, bs: 128, btraining loss: 0.17410412430763245, valid loss: 0.1879466325044632\n",
      "epoch: 2, lr: 0.01, bs: 128, btraining loss: 0.18950895965099335, valid loss: 0.1878136396408081\n",
      "epoch: 3, lr: 0.01, bs: 128, btraining loss: 0.2510768175125122, valid loss: 0.18551401793956757\n",
      "epoch: 4, lr: 0.01, bs: 128, btraining loss: 0.21838273108005524, valid loss: 0.18197934329509735\n",
      "epoch: 5, lr: 0.01, bs: 128, btraining loss: 0.22598178684711456, valid loss: 0.20305757224559784\n",
      "epoch: 6, lr: 0.01, bs: 128, btraining loss: 0.1736539602279663, valid loss: 0.21951591968536377\n",
      "epoch: 7, lr: 0.01, bs: 128, btraining loss: 0.16728997230529785, valid loss: 0.18695750832557678\n",
      "epoch: 8, lr: 0.01, bs: 128, btraining loss: 0.22008229792118073, valid loss: 0.21456685662269592\n",
      "epoch: 9, lr: 0.01, bs: 128, btraining loss: 0.22053126990795135, valid loss: 0.1947254091501236\n",
      "epoch: 10, lr: 0.01, bs: 128, btraining loss: 0.19314150512218475, valid loss: 0.21887917816638947\n",
      "epoch: 11, lr: 0.01, bs: 128, btraining loss: 0.18511125445365906, valid loss: 0.202720046043396\n",
      "epoch: 12, lr: 0.01, bs: 128, btraining loss: 0.17067678272724152, valid loss: 0.17875166237354279\n",
      "epoch: 13, lr: 0.01, bs: 128, btraining loss: 0.20706787705421448, valid loss: 0.2550419569015503\n",
      "epoch: 14, lr: 0.01, bs: 128, btraining loss: 0.1470417082309723, valid loss: 0.21441000699996948\n",
      "epoch: 15, lr: 0.01, bs: 128, btraining loss: 0.15057456493377686, valid loss: 0.15151552855968475\n",
      "epoch: 16, lr: 0.01, bs: 128, btraining loss: 0.22229082882404327, valid loss: 0.24108190834522247\n",
      "epoch: 17, lr: 0.01, bs: 128, btraining loss: 0.19038453698158264, valid loss: 0.17550651729106903\n",
      "epoch: 18, lr: 0.01, bs: 128, btraining loss: 0.16103322803974152, valid loss: 0.1931859850883484\n",
      "epoch: 19, lr: 0.01, bs: 128, btraining loss: 0.23791491985321045, valid loss: 0.20906135439872742\n",
      "epoch: 20, lr: 0.01, bs: 128, btraining loss: 0.24758613109588623, valid loss: 0.21694284677505493\n",
      "epoch: 21, lr: 0.01, bs: 128, btraining loss: 0.10196030884981155, valid loss: 0.1770731657743454\n",
      "epoch: 22, lr: 0.01, bs: 128, btraining loss: 0.17573747038841248, valid loss: 0.2162681668996811\n",
      "epoch: 23, lr: 0.01, bs: 128, btraining loss: 0.1622203290462494, valid loss: 0.1701793372631073\n",
      "epoch: 24, lr: 0.01, bs: 128, btraining loss: 0.1624484658241272, valid loss: 0.2102271020412445\n",
      "epoch: 25, lr: 0.01, bs: 128, btraining loss: 0.15921422839164734, valid loss: 0.16044040024280548\n",
      "epoch: 26, lr: 0.01, bs: 128, btraining loss: 0.1505863517522812, valid loss: 0.18741413950920105\n",
      "epoch: 27, lr: 0.01, bs: 128, btraining loss: 0.2182106226682663, valid loss: 0.2331448793411255\n",
      "epoch: 28, lr: 0.01, bs: 128, btraining loss: 0.14798225462436676, valid loss: 0.202765554189682\n",
      "epoch: 29, lr: 0.01, bs: 128, btraining loss: 0.18524454534053802, valid loss: 0.17608138918876648\n",
      "epoch: 30, lr: 0.01, bs: 128, btraining loss: 0.20736266672611237, valid loss: 0.22200974822044373\n",
      "epoch: 31, lr: 0.01, bs: 128, btraining loss: 0.12442484498023987, valid loss: 0.2042631208896637\n",
      "epoch: 32, lr: 0.01, bs: 128, btraining loss: 0.17878831923007965, valid loss: 0.20624281466007233\n",
      "epoch: 33, lr: 0.01, bs: 128, btraining loss: 0.21518957614898682, valid loss: 0.1841849684715271\n",
      "epoch: 34, lr: 0.01, bs: 128, btraining loss: 0.22257927060127258, valid loss: 0.17191137373447418\n",
      "epoch: 35, lr: 0.01, bs: 128, btraining loss: 0.21665140986442566, valid loss: 0.22980943322181702\n",
      "epoch: 36, lr: 0.01, bs: 128, btraining loss: 0.13553737103939056, valid loss: 0.19202055037021637\n",
      "epoch: 37, lr: 0.01, bs: 128, btraining loss: 0.17480212450027466, valid loss: 0.1789080798625946\n",
      "epoch: 38, lr: 0.01, bs: 128, btraining loss: 0.2798317074775696, valid loss: 0.22896462678909302\n",
      "epoch: 39, lr: 0.01, bs: 128, btraining loss: 0.18026293814182281, valid loss: 0.18942636251449585\n",
      "epoch: 40, lr: 0.01, bs: 128, btraining loss: 0.16483812034130096, valid loss: 0.21043598651885986\n",
      "epoch: 41, lr: 0.01, bs: 128, btraining loss: 0.165915846824646, valid loss: 0.20799142122268677\n",
      "epoch: 42, lr: 0.01, bs: 128, btraining loss: 0.20952802896499634, valid loss: 0.23950259387493134\n",
      "epoch: 43, lr: 0.01, bs: 128, btraining loss: 0.24949465692043304, valid loss: 0.1998479813337326\n",
      "epoch: 44, lr: 0.01, bs: 128, btraining loss: 0.1683000773191452, valid loss: 0.24008412659168243\n",
      "epoch: 45, lr: 0.01, bs: 128, btraining loss: 0.20133143663406372, valid loss: 0.19552774727344513\n",
      "epoch: 46, lr: 0.01, bs: 128, btraining loss: 0.1883661448955536, valid loss: 0.18059101700782776\n",
      "epoch: 47, lr: 0.01, bs: 128, btraining loss: 0.2319885641336441, valid loss: 0.20612235367298126\n",
      "epoch: 48, lr: 0.01, bs: 128, btraining loss: 0.17720375955104828, valid loss: 0.23266717791557312\n",
      "epoch: 49, lr: 0.01, bs: 128, btraining loss: 0.18970736861228943, valid loss: 0.16579970717430115\n",
      "epoch: 50, lr: 0.01, bs: 128, btraining loss: 0.23692944645881653, valid loss: 0.2554607391357422\n",
      "epoch: 51, lr: 0.01, bs: 128, btraining loss: 0.23952679336071014, valid loss: 0.17053449153900146\n",
      "epoch: 52, lr: 0.01, bs: 128, btraining loss: 0.21016700565814972, valid loss: 0.14743687212467194\n",
      "epoch: 53, lr: 0.01, bs: 128, btraining loss: 0.1532164216041565, valid loss: 0.17204588651657104\n",
      "epoch: 54, lr: 0.01, bs: 128, btraining loss: 0.14349505305290222, valid loss: 0.17068493366241455\n",
      "epoch: 55, lr: 0.01, bs: 128, btraining loss: 0.1908504217863083, valid loss: 0.18087199330329895\n",
      "epoch: 56, lr: 0.01, bs: 128, btraining loss: 0.2285904437303543, valid loss: 0.2146293818950653\n",
      "epoch: 57, lr: 0.01, bs: 128, btraining loss: 0.15514855086803436, valid loss: 0.22526462376117706\n",
      "epoch: 58, lr: 0.01, bs: 128, btraining loss: 0.23860201239585876, valid loss: 0.22003234922885895\n",
      "epoch: 59, lr: 0.01, bs: 128, btraining loss: 0.17592236399650574, valid loss: 0.2093803882598877\n",
      "epoch: 60, lr: 0.01, bs: 128, btraining loss: 0.1532810926437378, valid loss: 0.27327603101730347\n",
      "epoch: 61, lr: 0.01, bs: 128, btraining loss: 0.16235658526420593, valid loss: 0.20498085021972656\n",
      "epoch: 62, lr: 0.01, bs: 128, btraining loss: 0.15762928128242493, valid loss: 0.20576635003089905\n",
      "epoch: 63, lr: 0.01, bs: 128, btraining loss: 0.20724231004714966, valid loss: 0.17926499247550964\n",
      "epoch: 64, lr: 0.01, bs: 128, btraining loss: 0.20738282799720764, valid loss: 0.19625404477119446\n",
      "epoch: 65, lr: 0.01, bs: 128, btraining loss: 0.24896319210529327, valid loss: 0.21058379113674164\n",
      "epoch: 66, lr: 0.01, bs: 128, btraining loss: 0.14998136460781097, valid loss: 0.17472949624061584\n",
      "epoch: 67, lr: 0.01, bs: 128, btraining loss: 0.2493821680545807, valid loss: 0.18002080917358398\n",
      "epoch: 68, lr: 0.01, bs: 128, btraining loss: 0.2185293436050415, valid loss: 0.17596125602722168\n",
      "epoch: 69, lr: 0.01, bs: 128, btraining loss: 0.17117272317409515, valid loss: 0.23291856050491333\n",
      "epoch: 70, lr: 0.01, bs: 128, btraining loss: 0.13416671752929688, valid loss: 0.18692104518413544\n",
      "epoch: 71, lr: 0.01, bs: 128, btraining loss: 0.211961030960083, valid loss: 0.19550584256649017\n",
      "epoch: 72, lr: 0.01, bs: 128, btraining loss: 0.15016448497772217, valid loss: 0.26089346408843994\n",
      "epoch: 73, lr: 0.01, bs: 128, btraining loss: 0.1358179897069931, valid loss: 0.20446401834487915\n",
      "epoch: 74, lr: 0.01, bs: 128, btraining loss: 0.2527860403060913, valid loss: 0.21273940801620483\n",
      "epoch: 75, lr: 0.01, bs: 128, btraining loss: 0.24815644323825836, valid loss: 0.2124072164297104\n",
      "epoch: 76, lr: 0.01, bs: 128, btraining loss: 0.20179638266563416, valid loss: 0.23527604341506958\n",
      "epoch: 77, lr: 0.01, bs: 128, btraining loss: 0.15935391187667847, valid loss: 0.19524748623371124\n",
      "epoch: 78, lr: 0.01, bs: 128, btraining loss: 0.1893243044614792, valid loss: 0.24472321569919586\n",
      "epoch: 79, lr: 0.01, bs: 128, btraining loss: 0.15090353786945343, valid loss: 0.24256551265716553\n",
      "epoch: 80, lr: 0.01, bs: 128, btraining loss: 0.16171009838581085, valid loss: 0.2376016080379486\n",
      "epoch: 81, lr: 0.01, bs: 128, btraining loss: 0.19580091536045074, valid loss: 0.19811078906059265\n",
      "epoch: 82, lr: 0.01, bs: 128, btraining loss: 0.3072807788848877, valid loss: 0.20324818789958954\n",
      "epoch: 83, lr: 0.01, bs: 128, btraining loss: 0.16135482490062714, valid loss: 0.18316924571990967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 84, lr: 0.01, bs: 128, btraining loss: 0.21754783391952515, valid loss: 0.28944000601768494\n",
      "epoch: 85, lr: 0.01, bs: 128, btraining loss: 0.10192521661520004, valid loss: 0.22301727533340454\n",
      "epoch: 86, lr: 0.01, bs: 128, btraining loss: 0.244963139295578, valid loss: 0.17978191375732422\n",
      "epoch: 87, lr: 0.01, bs: 128, btraining loss: 0.20832401514053345, valid loss: 0.220857173204422\n",
      "epoch: 88, lr: 0.01, bs: 128, btraining loss: 0.15976960957050323, valid loss: 0.23112545907497406\n",
      "epoch: 89, lr: 0.01, bs: 128, btraining loss: 0.22629880905151367, valid loss: 0.18064527213573456\n",
      "epoch: 90, lr: 0.01, bs: 128, btraining loss: 0.19466866552829742, valid loss: 0.19486075639724731\n",
      "epoch: 91, lr: 0.01, bs: 128, btraining loss: 0.14782719314098358, valid loss: 0.16212134063243866\n",
      "epoch: 92, lr: 0.01, bs: 128, btraining loss: 0.1606265902519226, valid loss: 0.244197279214859\n",
      "epoch: 93, lr: 0.01, bs: 128, btraining loss: 0.1708143651485443, valid loss: 0.19383607804775238\n",
      "epoch: 94, lr: 0.01, bs: 128, btraining loss: 0.18204183876514435, valid loss: 0.24386101961135864\n",
      "epoch: 95, lr: 0.01, bs: 128, btraining loss: 0.1438606232404709, valid loss: 0.20558667182922363\n",
      "epoch: 96, lr: 0.01, bs: 128, btraining loss: 0.1852099597454071, valid loss: 0.18385179340839386\n",
      "epoch: 97, lr: 0.01, bs: 128, btraining loss: 0.1988152116537094, valid loss: 0.2972375154495239\n",
      "epoch: 98, lr: 0.01, bs: 128, btraining loss: 0.20961309969425201, valid loss: 0.215301513671875\n",
      "epoch: 99, lr: 0.01, bs: 128, btraining loss: 0.19528283178806305, valid loss: 0.20021091401576996\n",
      "epoch: 0, lr: 0.001, bs: 32, btraining loss: 0.1593259572982788, valid loss: 0.13609054684638977\n",
      "epoch: 1, lr: 0.001, bs: 32, btraining loss: 0.15829505026340485, valid loss: 0.08909308165311813\n",
      "epoch: 2, lr: 0.001, bs: 32, btraining loss: 0.1411513388156891, valid loss: 0.5755797624588013\n",
      "epoch: 3, lr: 0.001, bs: 32, btraining loss: 0.26705604791641235, valid loss: 0.03132328763604164\n",
      "epoch: 4, lr: 0.001, bs: 32, btraining loss: 0.1639418601989746, valid loss: 0.12320667505264282\n",
      "epoch: 5, lr: 0.001, bs: 32, btraining loss: 0.14368124306201935, valid loss: 0.18712443113327026\n",
      "epoch: 6, lr: 0.001, bs: 32, btraining loss: 0.1773928552865982, valid loss: 0.11637426167726517\n",
      "epoch: 7, lr: 0.001, bs: 32, btraining loss: 0.07939410209655762, valid loss: 0.15495048463344574\n",
      "epoch: 8, lr: 0.001, bs: 32, btraining loss: 0.15501579642295837, valid loss: 0.0705714225769043\n",
      "epoch: 9, lr: 0.001, bs: 32, btraining loss: 0.15455882251262665, valid loss: 0.4865872263908386\n",
      "epoch: 10, lr: 0.001, bs: 32, btraining loss: 0.2854748070240021, valid loss: 0.12277261912822723\n",
      "epoch: 11, lr: 0.001, bs: 32, btraining loss: 0.15323863923549652, valid loss: 0.2845653295516968\n",
      "epoch: 12, lr: 0.001, bs: 32, btraining loss: 0.21188700199127197, valid loss: 0.051636263728141785\n",
      "epoch: 13, lr: 0.001, bs: 32, btraining loss: 0.19964048266410828, valid loss: 0.19934684038162231\n",
      "epoch: 14, lr: 0.001, bs: 32, btraining loss: 0.3254900574684143, valid loss: 0.1002378761768341\n",
      "epoch: 15, lr: 0.001, bs: 32, btraining loss: 0.17351919412612915, valid loss: 0.06251256167888641\n",
      "epoch: 16, lr: 0.001, bs: 32, btraining loss: 0.12903153896331787, valid loss: 0.10857120156288147\n",
      "epoch: 17, lr: 0.001, bs: 32, btraining loss: 0.12287412583827972, valid loss: 0.12368109822273254\n",
      "epoch: 18, lr: 0.001, bs: 32, btraining loss: 0.2473907619714737, valid loss: 0.3660716116428375\n",
      "epoch: 19, lr: 0.001, bs: 32, btraining loss: 0.19330009818077087, valid loss: 0.049373216927051544\n",
      "epoch: 20, lr: 0.001, bs: 32, btraining loss: 0.08150570839643478, valid loss: 0.08931364119052887\n",
      "epoch: 21, lr: 0.001, bs: 32, btraining loss: 0.18251478672027588, valid loss: 0.15669208765029907\n",
      "epoch: 22, lr: 0.001, bs: 32, btraining loss: 0.20914529263973236, valid loss: 0.07706525176763535\n",
      "epoch: 23, lr: 0.001, bs: 32, btraining loss: 0.2980619966983795, valid loss: 0.17563559114933014\n",
      "epoch: 24, lr: 0.001, bs: 32, btraining loss: 0.231143981218338, valid loss: 0.207188218832016\n",
      "epoch: 25, lr: 0.001, bs: 32, btraining loss: 0.1735447347164154, valid loss: 0.20069219172000885\n",
      "epoch: 26, lr: 0.001, bs: 32, btraining loss: 0.20469120144844055, valid loss: 0.6142796874046326\n",
      "epoch: 27, lr: 0.001, bs: 32, btraining loss: 0.323151558637619, valid loss: 0.13868556916713715\n",
      "epoch: 28, lr: 0.001, bs: 32, btraining loss: 0.20682968199253082, valid loss: 0.7770652770996094\n",
      "epoch: 29, lr: 0.001, bs: 32, btraining loss: 0.19307000935077667, valid loss: 0.7971382141113281\n",
      "epoch: 30, lr: 0.001, bs: 32, btraining loss: 0.22561202943325043, valid loss: 0.15676213800907135\n",
      "epoch: 31, lr: 0.001, bs: 32, btraining loss: 0.2770945429801941, valid loss: 0.11219343543052673\n",
      "epoch: 32, lr: 0.001, bs: 32, btraining loss: 0.13057486712932587, valid loss: 0.08457113057374954\n",
      "epoch: 33, lr: 0.001, bs: 32, btraining loss: 0.21566058695316315, valid loss: 0.046963803470134735\n",
      "epoch: 34, lr: 0.001, bs: 32, btraining loss: 0.23224197328090668, valid loss: 0.14128008484840393\n",
      "epoch: 35, lr: 0.001, bs: 32, btraining loss: 0.16057652235031128, valid loss: 0.21115773916244507\n",
      "epoch: 36, lr: 0.001, bs: 32, btraining loss: 0.15114237368106842, valid loss: 0.18759579956531525\n",
      "epoch: 37, lr: 0.001, bs: 32, btraining loss: 0.11711778491735458, valid loss: 0.12807691097259521\n",
      "epoch: 38, lr: 0.001, bs: 32, btraining loss: 0.14711378514766693, valid loss: 0.4698455035686493\n",
      "epoch: 39, lr: 0.001, bs: 32, btraining loss: 0.14897453784942627, valid loss: 0.4462870955467224\n",
      "epoch: 40, lr: 0.001, bs: 32, btraining loss: 0.22536110877990723, valid loss: 0.5472447276115417\n",
      "epoch: 41, lr: 0.001, bs: 32, btraining loss: 0.25710591673851013, valid loss: 0.032762426882982254\n",
      "epoch: 42, lr: 0.001, bs: 32, btraining loss: 0.20164363086223602, valid loss: 0.2483801692724228\n",
      "epoch: 43, lr: 0.001, bs: 32, btraining loss: 0.2553216218948364, valid loss: 0.1041674092411995\n",
      "epoch: 44, lr: 0.001, bs: 32, btraining loss: 0.17318643629550934, valid loss: 0.1656983494758606\n",
      "epoch: 45, lr: 0.001, bs: 32, btraining loss: 0.15252786874771118, valid loss: 0.16373774409294128\n",
      "epoch: 46, lr: 0.001, bs: 32, btraining loss: 0.12035879492759705, valid loss: 0.2773028314113617\n",
      "epoch: 47, lr: 0.001, bs: 32, btraining loss: 0.1494482308626175, valid loss: 0.07406692951917648\n",
      "epoch: 48, lr: 0.001, bs: 32, btraining loss: 0.34706205129623413, valid loss: 0.4824883043766022\n",
      "epoch: 49, lr: 0.001, bs: 32, btraining loss: 0.21186162531375885, valid loss: 0.09728173911571503\n",
      "epoch: 50, lr: 0.001, bs: 32, btraining loss: 0.1775800734758377, valid loss: 0.16266405582427979\n",
      "epoch: 51, lr: 0.001, bs: 32, btraining loss: 0.2770601212978363, valid loss: 0.13850519061088562\n",
      "epoch: 52, lr: 0.001, bs: 32, btraining loss: 0.30980363488197327, valid loss: 0.10235826671123505\n",
      "epoch: 53, lr: 0.001, bs: 32, btraining loss: 0.1586802899837494, valid loss: 0.1414739489555359\n",
      "epoch: 54, lr: 0.001, bs: 32, btraining loss: 0.17963840067386627, valid loss: 0.12259431183338165\n",
      "epoch: 55, lr: 0.001, bs: 32, btraining loss: 0.19427433609962463, valid loss: 0.2714087963104248\n",
      "epoch: 56, lr: 0.001, bs: 32, btraining loss: 0.10494354367256165, valid loss: 0.14189578592777252\n",
      "epoch: 57, lr: 0.001, bs: 32, btraining loss: 0.23984862864017487, valid loss: 0.25672563910484314\n",
      "epoch: 58, lr: 0.001, bs: 32, btraining loss: 0.3025026321411133, valid loss: 0.14122356474399567\n",
      "epoch: 59, lr: 0.001, bs: 32, btraining loss: 0.2484385371208191, valid loss: 0.29373738169670105\n",
      "epoch: 60, lr: 0.001, bs: 32, btraining loss: 0.1593087613582611, valid loss: 0.19541306793689728\n",
      "epoch: 61, lr: 0.001, bs: 32, btraining loss: 0.2092539668083191, valid loss: 0.04581836983561516\n",
      "epoch: 62, lr: 0.001, bs: 32, btraining loss: 0.1388903260231018, valid loss: 0.0853722020983696\n",
      "epoch: 63, lr: 0.001, bs: 32, btraining loss: 0.2807074785232544, valid loss: 0.13909907639026642\n",
      "epoch: 64, lr: 0.001, bs: 32, btraining loss: 0.2710188329219818, valid loss: 0.12711554765701294\n",
      "epoch: 65, lr: 0.001, bs: 32, btraining loss: 0.2287411391735077, valid loss: 0.0754491314291954\n",
      "epoch: 66, lr: 0.001, bs: 32, btraining loss: 0.158212810754776, valid loss: 0.13695628941059113\n",
      "epoch: 67, lr: 0.001, bs: 32, btraining loss: 0.19938763976097107, valid loss: 0.6498271226882935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 68, lr: 0.001, bs: 32, btraining loss: 0.2300819307565689, valid loss: 0.6990950107574463\n",
      "epoch: 69, lr: 0.001, bs: 32, btraining loss: 0.10540086030960083, valid loss: 0.6875508427619934\n",
      "epoch: 70, lr: 0.001, bs: 32, btraining loss: 0.1557997167110443, valid loss: 0.2231239527463913\n",
      "epoch: 71, lr: 0.001, bs: 32, btraining loss: 0.09745059907436371, valid loss: 0.5312969088554382\n",
      "epoch: 72, lr: 0.001, bs: 32, btraining loss: 0.15657994151115417, valid loss: 0.08017559349536896\n",
      "epoch: 73, lr: 0.001, bs: 32, btraining loss: 0.1842527687549591, valid loss: 0.2081259936094284\n",
      "epoch: 74, lr: 0.001, bs: 32, btraining loss: 0.23900507390499115, valid loss: 0.14955392479896545\n",
      "epoch: 75, lr: 0.001, bs: 32, btraining loss: 0.279443621635437, valid loss: 0.07971204817295074\n",
      "epoch: 76, lr: 0.001, bs: 32, btraining loss: 0.15267950296401978, valid loss: 0.19539755582809448\n",
      "epoch: 77, lr: 0.001, bs: 32, btraining loss: 0.1663547158241272, valid loss: 0.17653816938400269\n",
      "epoch: 78, lr: 0.001, bs: 32, btraining loss: 0.21566666662693024, valid loss: 0.11217507719993591\n",
      "epoch: 79, lr: 0.001, bs: 32, btraining loss: 0.257223516702652, valid loss: 0.1068800836801529\n",
      "epoch: 80, lr: 0.001, bs: 32, btraining loss: 0.1823802888393402, valid loss: 0.1784428060054779\n",
      "epoch: 81, lr: 0.001, bs: 32, btraining loss: 0.19988290965557098, valid loss: 0.12784622609615326\n",
      "epoch: 82, lr: 0.001, bs: 32, btraining loss: 0.1749613732099533, valid loss: 0.07968443632125854\n",
      "epoch: 83, lr: 0.001, bs: 32, btraining loss: 0.19733163714408875, valid loss: 0.1282189041376114\n",
      "epoch: 84, lr: 0.001, bs: 32, btraining loss: 0.1138911098241806, valid loss: 0.13216720521450043\n",
      "epoch: 85, lr: 0.001, bs: 32, btraining loss: 0.2744624614715576, valid loss: 0.13775517046451569\n",
      "epoch: 86, lr: 0.001, bs: 32, btraining loss: 0.26750120520591736, valid loss: 0.11951123923063278\n",
      "epoch: 87, lr: 0.001, bs: 32, btraining loss: 0.1706506311893463, valid loss: 0.3147025406360626\n",
      "epoch: 88, lr: 0.001, bs: 32, btraining loss: 0.19659511744976044, valid loss: 0.05040987581014633\n",
      "epoch: 89, lr: 0.001, bs: 32, btraining loss: 0.27129673957824707, valid loss: 0.08933007717132568\n",
      "epoch: 90, lr: 0.001, bs: 32, btraining loss: 0.1701352596282959, valid loss: 0.06981068104505539\n",
      "epoch: 91, lr: 0.001, bs: 32, btraining loss: 0.1915869563817978, valid loss: 0.12300515919923782\n",
      "epoch: 92, lr: 0.001, bs: 32, btraining loss: 0.09241344034671783, valid loss: 0.11192823946475983\n",
      "epoch: 93, lr: 0.001, bs: 32, btraining loss: 0.22748105227947235, valid loss: 0.08196716755628586\n",
      "epoch: 94, lr: 0.001, bs: 32, btraining loss: 0.1715284287929535, valid loss: 0.1801200956106186\n",
      "epoch: 95, lr: 0.001, bs: 32, btraining loss: 0.2273479849100113, valid loss: 0.22118674218654633\n",
      "epoch: 96, lr: 0.001, bs: 32, btraining loss: 0.28479066491127014, valid loss: 0.04891135171055794\n",
      "epoch: 97, lr: 0.001, bs: 32, btraining loss: 0.22108986973762512, valid loss: 0.19482284784317017\n",
      "epoch: 98, lr: 0.001, bs: 32, btraining loss: 0.2157866209745407, valid loss: 0.4013802409172058\n",
      "epoch: 99, lr: 0.001, bs: 32, btraining loss: 0.1305132359266281, valid loss: 0.0046879807487130165\n",
      "epoch: 0, lr: 0.001, bs: 64, btraining loss: 0.24635063111782074, valid loss: 0.4253690242767334\n",
      "epoch: 1, lr: 0.001, bs: 64, btraining loss: 0.17247849702835083, valid loss: 0.07484747469425201\n",
      "epoch: 2, lr: 0.001, bs: 64, btraining loss: 0.19072309136390686, valid loss: 0.11175629496574402\n",
      "epoch: 3, lr: 0.001, bs: 64, btraining loss: 0.13402992486953735, valid loss: 0.08319803327322006\n",
      "epoch: 4, lr: 0.001, bs: 64, btraining loss: 0.19152547419071198, valid loss: 0.1995311826467514\n",
      "epoch: 5, lr: 0.001, bs: 64, btraining loss: 0.1673467755317688, valid loss: 1.0129752159118652\n",
      "epoch: 6, lr: 0.001, bs: 64, btraining loss: 0.1468019038438797, valid loss: 0.15571357309818268\n",
      "epoch: 7, lr: 0.001, bs: 64, btraining loss: 0.17203082144260406, valid loss: 0.48129719495773315\n",
      "epoch: 8, lr: 0.001, bs: 64, btraining loss: 0.14914514124393463, valid loss: 0.16716748476028442\n",
      "epoch: 9, lr: 0.001, bs: 64, btraining loss: 0.18282972276210785, valid loss: 0.5412409901618958\n",
      "epoch: 10, lr: 0.001, bs: 64, btraining loss: 0.18008139729499817, valid loss: 0.5672943592071533\n",
      "epoch: 11, lr: 0.001, bs: 64, btraining loss: 0.17186452448368073, valid loss: 0.09294489771127701\n",
      "epoch: 12, lr: 0.001, bs: 64, btraining loss: 0.27138301730155945, valid loss: 0.1022258847951889\n",
      "epoch: 13, lr: 0.001, bs: 64, btraining loss: 0.1603805422782898, valid loss: 0.09381033480167389\n",
      "epoch: 14, lr: 0.001, bs: 64, btraining loss: 0.16890235245227814, valid loss: 0.48629069328308105\n",
      "epoch: 15, lr: 0.001, bs: 64, btraining loss: 0.18871453404426575, valid loss: 0.04883687570691109\n",
      "epoch: 16, lr: 0.001, bs: 64, btraining loss: 0.1834888607263565, valid loss: 0.1345674991607666\n",
      "epoch: 17, lr: 0.001, bs: 64, btraining loss: 0.1476365327835083, valid loss: 0.8147526383399963\n",
      "epoch: 18, lr: 0.001, bs: 64, btraining loss: 0.17529146373271942, valid loss: 0.1231851875782013\n",
      "epoch: 19, lr: 0.001, bs: 64, btraining loss: 0.21526311337947845, valid loss: 0.8853162527084351\n",
      "epoch: 20, lr: 0.001, bs: 64, btraining loss: 0.23369742929935455, valid loss: 0.06686791777610779\n",
      "epoch: 21, lr: 0.001, bs: 64, btraining loss: 0.2715826630592346, valid loss: 0.06208592653274536\n",
      "epoch: 22, lr: 0.001, bs: 64, btraining loss: 0.2278728038072586, valid loss: 0.500336766242981\n",
      "epoch: 23, lr: 0.001, bs: 64, btraining loss: 0.2095860242843628, valid loss: 0.12868398427963257\n",
      "epoch: 24, lr: 0.001, bs: 64, btraining loss: 0.25299546122550964, valid loss: 0.11632072180509567\n",
      "epoch: 25, lr: 0.001, bs: 64, btraining loss: 0.15862424671649933, valid loss: 0.03065422549843788\n",
      "epoch: 26, lr: 0.001, bs: 64, btraining loss: 0.24428249895572662, valid loss: 0.09892363101243973\n",
      "epoch: 27, lr: 0.001, bs: 64, btraining loss: 0.18621158599853516, valid loss: 0.1016748696565628\n",
      "epoch: 28, lr: 0.001, bs: 64, btraining loss: 0.19416740536689758, valid loss: 0.11377730965614319\n",
      "epoch: 29, lr: 0.001, bs: 64, btraining loss: 0.2944035828113556, valid loss: 0.26406434178352356\n",
      "epoch: 30, lr: 0.001, bs: 64, btraining loss: 0.21357165277004242, valid loss: 0.15812835097312927\n",
      "epoch: 31, lr: 0.001, bs: 64, btraining loss: 0.16293516755104065, valid loss: 0.15355077385902405\n",
      "epoch: 32, lr: 0.001, bs: 64, btraining loss: 0.1878640502691269, valid loss: 0.09964940696954727\n",
      "epoch: 33, lr: 0.001, bs: 64, btraining loss: 0.19246645271778107, valid loss: 0.07327103614807129\n",
      "epoch: 34, lr: 0.001, bs: 64, btraining loss: 0.1473095566034317, valid loss: 0.0907849594950676\n",
      "epoch: 35, lr: 0.001, bs: 64, btraining loss: 0.18293637037277222, valid loss: 0.07241742312908173\n",
      "epoch: 36, lr: 0.001, bs: 64, btraining loss: 0.16082929074764252, valid loss: 0.14038531482219696\n",
      "epoch: 37, lr: 0.001, bs: 64, btraining loss: 0.1610742062330246, valid loss: 0.01521739549934864\n",
      "epoch: 38, lr: 0.001, bs: 64, btraining loss: 0.1999460756778717, valid loss: 0.14807817339897156\n",
      "epoch: 39, lr: 0.001, bs: 64, btraining loss: 0.1667725145816803, valid loss: 0.7866167426109314\n",
      "epoch: 40, lr: 0.001, bs: 64, btraining loss: 0.21157556772232056, valid loss: 0.17794331908226013\n",
      "epoch: 41, lr: 0.001, bs: 64, btraining loss: 0.21987858414649963, valid loss: 0.11758170276880264\n",
      "epoch: 42, lr: 0.001, bs: 64, btraining loss: 0.22370323538780212, valid loss: 0.3242940604686737\n",
      "epoch: 43, lr: 0.001, bs: 64, btraining loss: 0.18133991956710815, valid loss: 0.11778717488050461\n",
      "epoch: 44, lr: 0.001, bs: 64, btraining loss: 0.23170067369937897, valid loss: 0.40044838190078735\n",
      "epoch: 45, lr: 0.001, bs: 64, btraining loss: 0.23255696892738342, valid loss: 0.2819903492927551\n",
      "epoch: 46, lr: 0.001, bs: 64, btraining loss: 0.24888569116592407, valid loss: 0.08225840330123901\n",
      "epoch: 47, lr: 0.001, bs: 64, btraining loss: 0.2430756837129593, valid loss: 0.7145686149597168\n",
      "epoch: 48, lr: 0.001, bs: 64, btraining loss: 0.1268194019794464, valid loss: 0.08420433849096298\n",
      "epoch: 49, lr: 0.001, bs: 64, btraining loss: 0.18750110268592834, valid loss: 0.10163916647434235\n",
      "epoch: 50, lr: 0.001, bs: 64, btraining loss: 0.24927464127540588, valid loss: 0.05872549116611481\n",
      "epoch: 51, lr: 0.001, bs: 64, btraining loss: 0.1913996934890747, valid loss: 0.08850570768117905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 52, lr: 0.001, bs: 64, btraining loss: 0.2325618863105774, valid loss: 0.08784695714712143\n",
      "epoch: 53, lr: 0.001, bs: 64, btraining loss: 0.16911444067955017, valid loss: 0.05044303461909294\n",
      "epoch: 54, lr: 0.001, bs: 64, btraining loss: 0.19800862669944763, valid loss: 0.21563392877578735\n",
      "epoch: 55, lr: 0.001, bs: 64, btraining loss: 0.1650567650794983, valid loss: 0.18472445011138916\n",
      "epoch: 56, lr: 0.001, bs: 64, btraining loss: 0.2251727283000946, valid loss: 0.17548580467700958\n",
      "epoch: 57, lr: 0.001, bs: 64, btraining loss: 0.172071635723114, valid loss: 0.10651221871376038\n",
      "epoch: 58, lr: 0.001, bs: 64, btraining loss: 0.18242493271827698, valid loss: 0.16538779437541962\n",
      "epoch: 59, lr: 0.001, bs: 64, btraining loss: 0.16539797186851501, valid loss: 0.05886217951774597\n",
      "epoch: 60, lr: 0.001, bs: 64, btraining loss: 0.2284504622220993, valid loss: 0.07284128665924072\n",
      "epoch: 61, lr: 0.001, bs: 64, btraining loss: 0.2356988489627838, valid loss: 0.13166238367557526\n",
      "epoch: 62, lr: 0.001, bs: 64, btraining loss: 0.15760071575641632, valid loss: 0.07033424824476242\n",
      "epoch: 63, lr: 0.001, bs: 64, btraining loss: 0.15050746500492096, valid loss: 0.17899608612060547\n",
      "epoch: 64, lr: 0.001, bs: 64, btraining loss: 0.25145193934440613, valid loss: 0.14723265171051025\n",
      "epoch: 65, lr: 0.001, bs: 64, btraining loss: 0.17041386663913727, valid loss: 0.09816151857376099\n",
      "epoch: 66, lr: 0.001, bs: 64, btraining loss: 0.13390664756298065, valid loss: 0.11765404790639877\n",
      "epoch: 67, lr: 0.001, bs: 64, btraining loss: 0.27930954098701477, valid loss: 0.12717106938362122\n",
      "epoch: 68, lr: 0.001, bs: 64, btraining loss: 0.11703889816999435, valid loss: 0.18779805302619934\n",
      "epoch: 69, lr: 0.001, bs: 64, btraining loss: 0.2359190732240677, valid loss: 0.36038151383399963\n",
      "epoch: 70, lr: 0.001, bs: 64, btraining loss: 0.23572814464569092, valid loss: 0.15680330991744995\n",
      "epoch: 71, lr: 0.001, bs: 64, btraining loss: 0.17002519965171814, valid loss: 0.44996345043182373\n",
      "epoch: 72, lr: 0.001, bs: 64, btraining loss: 0.1725645512342453, valid loss: 0.5304642915725708\n",
      "epoch: 73, lr: 0.001, bs: 64, btraining loss: 0.22714021801948547, valid loss: 0.14229565858840942\n",
      "epoch: 74, lr: 0.001, bs: 64, btraining loss: 0.19951952993869781, valid loss: 0.012870434671640396\n",
      "epoch: 75, lr: 0.001, bs: 64, btraining loss: 0.17503416538238525, valid loss: 0.07923130691051483\n",
      "epoch: 76, lr: 0.001, bs: 64, btraining loss: 0.2072763293981552, valid loss: 0.0684380829334259\n",
      "epoch: 77, lr: 0.001, bs: 64, btraining loss: 0.17878538370132446, valid loss: 0.1995946168899536\n",
      "epoch: 78, lr: 0.001, bs: 64, btraining loss: 0.15827211737632751, valid loss: 0.2147255390882492\n",
      "epoch: 79, lr: 0.001, bs: 64, btraining loss: 0.19558371603488922, valid loss: 0.13611918687820435\n",
      "epoch: 80, lr: 0.001, bs: 64, btraining loss: 0.18962562084197998, valid loss: 0.5366195440292358\n",
      "epoch: 81, lr: 0.001, bs: 64, btraining loss: 0.16561809182167053, valid loss: 0.38540124893188477\n",
      "epoch: 82, lr: 0.001, bs: 64, btraining loss: 0.18949638307094574, valid loss: 0.15447990596294403\n",
      "epoch: 83, lr: 0.001, bs: 64, btraining loss: 0.2831391990184784, valid loss: 0.11695194989442825\n",
      "epoch: 84, lr: 0.001, bs: 64, btraining loss: 0.18819081783294678, valid loss: 0.03738728165626526\n",
      "epoch: 85, lr: 0.001, bs: 64, btraining loss: 0.19018059968948364, valid loss: 0.33392611145973206\n",
      "epoch: 86, lr: 0.001, bs: 64, btraining loss: 0.2428659200668335, valid loss: 0.03852984681725502\n",
      "epoch: 87, lr: 0.001, bs: 64, btraining loss: 0.17769350111484528, valid loss: 0.14158962666988373\n",
      "epoch: 88, lr: 0.001, bs: 64, btraining loss: 0.2007732391357422, valid loss: 0.06526566296815872\n",
      "epoch: 89, lr: 0.001, bs: 64, btraining loss: 0.1675507128238678, valid loss: 0.04991243779659271\n",
      "epoch: 90, lr: 0.001, bs: 64, btraining loss: 0.15762680768966675, valid loss: 0.333099365234375\n",
      "epoch: 91, lr: 0.001, bs: 64, btraining loss: 0.16661643981933594, valid loss: 0.16383033990859985\n",
      "epoch: 92, lr: 0.001, bs: 64, btraining loss: 0.11825146526098251, valid loss: 0.6252923011779785\n",
      "epoch: 93, lr: 0.001, bs: 64, btraining loss: 0.1594131737947464, valid loss: 0.14128108322620392\n",
      "epoch: 94, lr: 0.001, bs: 64, btraining loss: 0.19248273968696594, valid loss: 0.07197573781013489\n",
      "epoch: 95, lr: 0.001, bs: 64, btraining loss: 0.14728012681007385, valid loss: 0.33440032601356506\n",
      "epoch: 96, lr: 0.001, bs: 64, btraining loss: 0.14895692467689514, valid loss: 0.17720630764961243\n",
      "epoch: 97, lr: 0.001, bs: 64, btraining loss: 0.2170339971780777, valid loss: 0.05021258443593979\n",
      "epoch: 98, lr: 0.001, bs: 64, btraining loss: 0.14861415326595306, valid loss: 0.7380467653274536\n",
      "epoch: 99, lr: 0.001, bs: 64, btraining loss: 0.17870667576789856, valid loss: 0.0181659534573555\n",
      "epoch: 0, lr: 0.001, bs: 128, btraining loss: 0.16996429860591888, valid loss: 0.23544852435588837\n",
      "epoch: 1, lr: 0.001, bs: 128, btraining loss: 0.18083634972572327, valid loss: 0.20926837623119354\n",
      "epoch: 2, lr: 0.001, bs: 128, btraining loss: 0.13818193972110748, valid loss: 0.1821797639131546\n",
      "epoch: 3, lr: 0.001, bs: 128, btraining loss: 0.21225281059741974, valid loss: 0.21442539989948273\n",
      "epoch: 4, lr: 0.001, bs: 128, btraining loss: 0.18947409093379974, valid loss: 0.18893611431121826\n",
      "epoch: 5, lr: 0.001, bs: 128, btraining loss: 0.2082027643918991, valid loss: 0.2108563333749771\n",
      "epoch: 6, lr: 0.001, bs: 128, btraining loss: 0.3367966413497925, valid loss: 0.2146013081073761\n",
      "epoch: 7, lr: 0.001, bs: 128, btraining loss: 0.1400730162858963, valid loss: 0.2556650638580322\n",
      "epoch: 8, lr: 0.001, bs: 128, btraining loss: 0.17777276039123535, valid loss: 0.21708957850933075\n",
      "epoch: 9, lr: 0.001, bs: 128, btraining loss: 0.18286430835723877, valid loss: 0.24785752594470978\n",
      "epoch: 10, lr: 0.001, bs: 128, btraining loss: 0.10173024982213974, valid loss: 0.1901908665895462\n",
      "epoch: 11, lr: 0.001, bs: 128, btraining loss: 0.1374940276145935, valid loss: 0.2464345097541809\n",
      "epoch: 12, lr: 0.001, bs: 128, btraining loss: 0.28324609994888306, valid loss: 0.20820821821689606\n",
      "epoch: 13, lr: 0.001, bs: 128, btraining loss: 0.26201939582824707, valid loss: 0.24220912158489227\n",
      "epoch: 14, lr: 0.001, bs: 128, btraining loss: 0.15527236461639404, valid loss: 0.15001200139522552\n",
      "epoch: 15, lr: 0.001, bs: 128, btraining loss: 0.21215268969535828, valid loss: 0.21182909607887268\n",
      "epoch: 16, lr: 0.001, bs: 128, btraining loss: 0.1882544904947281, valid loss: 0.1946818083524704\n",
      "epoch: 17, lr: 0.001, bs: 128, btraining loss: 0.2711930572986603, valid loss: 0.2062748521566391\n",
      "epoch: 18, lr: 0.001, bs: 128, btraining loss: 0.21064580976963043, valid loss: 0.19850556552410126\n",
      "epoch: 19, lr: 0.001, bs: 128, btraining loss: 0.11916958540678024, valid loss: 0.23745368421077728\n",
      "epoch: 20, lr: 0.001, bs: 128, btraining loss: 0.22864778339862823, valid loss: 0.196365624666214\n",
      "epoch: 21, lr: 0.001, bs: 128, btraining loss: 0.19123871624469757, valid loss: 0.20041586458683014\n",
      "epoch: 22, lr: 0.001, bs: 128, btraining loss: 0.2205110788345337, valid loss: 0.2098863273859024\n",
      "epoch: 23, lr: 0.001, bs: 128, btraining loss: 0.16297529637813568, valid loss: 0.2516356408596039\n",
      "epoch: 24, lr: 0.001, bs: 128, btraining loss: 0.2584899067878723, valid loss: 0.2195379137992859\n",
      "epoch: 25, lr: 0.001, bs: 128, btraining loss: 0.20301733911037445, valid loss: 0.25217974185943604\n",
      "epoch: 26, lr: 0.001, bs: 128, btraining loss: 0.1729367971420288, valid loss: 0.19122286140918732\n",
      "epoch: 27, lr: 0.001, bs: 128, btraining loss: 0.17277829349040985, valid loss: 0.21808558702468872\n",
      "epoch: 28, lr: 0.001, bs: 128, btraining loss: 0.14274682104587555, valid loss: 0.1975613832473755\n",
      "epoch: 29, lr: 0.001, bs: 128, btraining loss: 0.17290997505187988, valid loss: 0.18914270401000977\n",
      "epoch: 30, lr: 0.001, bs: 128, btraining loss: 0.1598949432373047, valid loss: 0.2642574906349182\n",
      "epoch: 31, lr: 0.001, bs: 128, btraining loss: 0.20492321252822876, valid loss: 0.24817438423633575\n",
      "epoch: 32, lr: 0.001, bs: 128, btraining loss: 0.1411413550376892, valid loss: 0.21288113296031952\n",
      "epoch: 33, lr: 0.001, bs: 128, btraining loss: 0.15111054480075836, valid loss: 0.21226061880588531\n",
      "epoch: 34, lr: 0.001, bs: 128, btraining loss: 0.18904827535152435, valid loss: 0.20636825263500214\n",
      "epoch: 35, lr: 0.001, bs: 128, btraining loss: 0.23879052698612213, valid loss: 0.18787848949432373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36, lr: 0.001, bs: 128, btraining loss: 0.19135016202926636, valid loss: 0.255973219871521\n",
      "epoch: 37, lr: 0.001, bs: 128, btraining loss: 0.1683947592973709, valid loss: 0.19238775968551636\n",
      "epoch: 38, lr: 0.001, bs: 128, btraining loss: 0.13929244875907898, valid loss: 0.2120518833398819\n",
      "epoch: 39, lr: 0.001, bs: 128, btraining loss: 0.16779226064682007, valid loss: 0.16062390804290771\n",
      "epoch: 40, lr: 0.001, bs: 128, btraining loss: 0.27085360884666443, valid loss: 0.1955685317516327\n",
      "epoch: 41, lr: 0.001, bs: 128, btraining loss: 0.20572184026241302, valid loss: 0.24442027509212494\n",
      "epoch: 42, lr: 0.001, bs: 128, btraining loss: 0.15452156960964203, valid loss: 0.1443583071231842\n",
      "epoch: 43, lr: 0.001, bs: 128, btraining loss: 0.13727231323719025, valid loss: 0.238702654838562\n",
      "epoch: 44, lr: 0.001, bs: 128, btraining loss: 0.20949721336364746, valid loss: 0.2568823993206024\n",
      "epoch: 45, lr: 0.001, bs: 128, btraining loss: 0.16823087632656097, valid loss: 0.1695389449596405\n",
      "epoch: 46, lr: 0.001, bs: 128, btraining loss: 0.18299899995326996, valid loss: 0.3001490831375122\n",
      "epoch: 47, lr: 0.001, bs: 128, btraining loss: 0.22614406049251556, valid loss: 0.1849917322397232\n",
      "epoch: 48, lr: 0.001, bs: 128, btraining loss: 0.2845473289489746, valid loss: 0.25186073780059814\n",
      "epoch: 49, lr: 0.001, bs: 128, btraining loss: 0.19745910167694092, valid loss: 0.1603686809539795\n",
      "epoch: 50, lr: 0.001, bs: 128, btraining loss: 0.17254899442195892, valid loss: 0.20584222674369812\n",
      "epoch: 51, lr: 0.001, bs: 128, btraining loss: 0.17514079809188843, valid loss: 0.18471254408359528\n",
      "epoch: 52, lr: 0.001, bs: 128, btraining loss: 0.16243988275527954, valid loss: 0.22271250188350677\n",
      "epoch: 53, lr: 0.001, bs: 128, btraining loss: 0.17748573422431946, valid loss: 0.23989543318748474\n",
      "epoch: 54, lr: 0.001, bs: 128, btraining loss: 0.20670899748802185, valid loss: 0.1658843457698822\n",
      "epoch: 55, lr: 0.001, bs: 128, btraining loss: 0.2029549777507782, valid loss: 0.21751168370246887\n",
      "epoch: 56, lr: 0.001, bs: 128, btraining loss: 0.1673465371131897, valid loss: 0.22754652798175812\n",
      "epoch: 57, lr: 0.001, bs: 128, btraining loss: 0.16947758197784424, valid loss: 0.21430522203445435\n",
      "epoch: 58, lr: 0.001, bs: 128, btraining loss: 0.18552523851394653, valid loss: 0.19904837012290955\n",
      "epoch: 59, lr: 0.001, bs: 128, btraining loss: 0.1514998823404312, valid loss: 0.2715739905834198\n",
      "epoch: 60, lr: 0.001, bs: 128, btraining loss: 0.2700246274471283, valid loss: 0.16197960078716278\n",
      "epoch: 61, lr: 0.001, bs: 128, btraining loss: 0.20640303194522858, valid loss: 0.18758782744407654\n",
      "epoch: 62, lr: 0.001, bs: 128, btraining loss: 0.15468119084835052, valid loss: 0.19212780892848969\n",
      "epoch: 63, lr: 0.001, bs: 128, btraining loss: 0.16698846220970154, valid loss: 0.2534051537513733\n",
      "epoch: 64, lr: 0.001, bs: 128, btraining loss: 0.1865866631269455, valid loss: 0.20157870650291443\n",
      "epoch: 65, lr: 0.001, bs: 128, btraining loss: 0.2190462052822113, valid loss: 0.2007499486207962\n",
      "epoch: 66, lr: 0.001, bs: 128, btraining loss: 0.2267356961965561, valid loss: 0.12893791496753693\n",
      "epoch: 67, lr: 0.001, bs: 128, btraining loss: 0.20585572719573975, valid loss: 0.19141536951065063\n",
      "epoch: 68, lr: 0.001, bs: 128, btraining loss: 0.23308877646923065, valid loss: 0.1964743435382843\n",
      "epoch: 69, lr: 0.001, bs: 128, btraining loss: 0.17037634551525116, valid loss: 0.16352184116840363\n",
      "epoch: 70, lr: 0.001, bs: 128, btraining loss: 0.13271568715572357, valid loss: 0.19234898686408997\n",
      "epoch: 71, lr: 0.001, bs: 128, btraining loss: 0.12860603630542755, valid loss: 0.21116726100444794\n",
      "epoch: 72, lr: 0.001, bs: 128, btraining loss: 0.16540852189064026, valid loss: 0.15950757265090942\n",
      "epoch: 73, lr: 0.001, bs: 128, btraining loss: 0.2076965570449829, valid loss: 0.2108796238899231\n",
      "epoch: 74, lr: 0.001, bs: 128, btraining loss: 0.17393192648887634, valid loss: 0.26878735423088074\n",
      "epoch: 75, lr: 0.001, bs: 128, btraining loss: 0.1485726237297058, valid loss: 0.23620615899562836\n",
      "epoch: 76, lr: 0.001, bs: 128, btraining loss: 0.194971963763237, valid loss: 0.18642888963222504\n",
      "epoch: 77, lr: 0.001, bs: 128, btraining loss: 0.12857647240161896, valid loss: 0.17291681468486786\n",
      "epoch: 78, lr: 0.001, bs: 128, btraining loss: 0.2089868038892746, valid loss: 0.16278378665447235\n",
      "epoch: 79, lr: 0.001, bs: 128, btraining loss: 0.18782564997673035, valid loss: 0.2098069190979004\n",
      "epoch: 80, lr: 0.001, bs: 128, btraining loss: 0.28624284267425537, valid loss: 0.199884831905365\n",
      "epoch: 81, lr: 0.001, bs: 128, btraining loss: 0.228907972574234, valid loss: 0.269380122423172\n",
      "epoch: 82, lr: 0.001, bs: 128, btraining loss: 0.14461055397987366, valid loss: 0.20456597208976746\n",
      "epoch: 83, lr: 0.001, bs: 128, btraining loss: 0.2068336009979248, valid loss: 0.24627111852169037\n",
      "epoch: 84, lr: 0.001, bs: 128, btraining loss: 0.18398775160312653, valid loss: 0.21706105768680573\n",
      "epoch: 85, lr: 0.001, bs: 128, btraining loss: 0.21211029589176178, valid loss: 0.24425069987773895\n",
      "epoch: 86, lr: 0.001, bs: 128, btraining loss: 0.2268262505531311, valid loss: 0.21143415570259094\n",
      "epoch: 87, lr: 0.001, bs: 128, btraining loss: 0.22245246171951294, valid loss: 0.22961370646953583\n",
      "epoch: 88, lr: 0.001, bs: 128, btraining loss: 0.2030978798866272, valid loss: 0.1581418812274933\n",
      "epoch: 89, lr: 0.001, bs: 128, btraining loss: 0.23255400359630585, valid loss: 0.24072280526161194\n",
      "epoch: 90, lr: 0.001, bs: 128, btraining loss: 0.1638697385787964, valid loss: 0.21158695220947266\n",
      "epoch: 91, lr: 0.001, bs: 128, btraining loss: 0.16038699448108673, valid loss: 0.2239963263273239\n",
      "epoch: 92, lr: 0.001, bs: 128, btraining loss: 0.16205692291259766, valid loss: 0.19816239178180695\n",
      "epoch: 93, lr: 0.001, bs: 128, btraining loss: 0.12318103015422821, valid loss: 0.22095701098442078\n",
      "epoch: 94, lr: 0.001, bs: 128, btraining loss: 0.18744318187236786, valid loss: 0.17197661101818085\n",
      "epoch: 95, lr: 0.001, bs: 128, btraining loss: 0.1519574671983719, valid loss: 0.2040524035692215\n",
      "epoch: 96, lr: 0.001, bs: 128, btraining loss: 0.1721915900707245, valid loss: 0.18790273368358612\n",
      "epoch: 97, lr: 0.001, bs: 128, btraining loss: 0.1517016440629959, valid loss: 0.27022990584373474\n",
      "epoch: 98, lr: 0.001, bs: 128, btraining loss: 0.24605202674865723, valid loss: 0.2046947181224823\n",
      "epoch: 99, lr: 0.001, bs: 128, btraining loss: 0.23502376675605774, valid loss: 0.18592017889022827\n",
      "epoch: 0, lr: 0.0001, bs: 32, btraining loss: 0.22535216808319092, valid loss: 0.09548625349998474\n",
      "epoch: 1, lr: 0.0001, bs: 32, btraining loss: 0.1381329745054245, valid loss: 0.10331469774246216\n",
      "epoch: 2, lr: 0.0001, bs: 32, btraining loss: 0.15914733707904816, valid loss: 0.22651737928390503\n",
      "epoch: 3, lr: 0.0001, bs: 32, btraining loss: 0.24276040494441986, valid loss: 0.2394062578678131\n",
      "epoch: 4, lr: 0.0001, bs: 32, btraining loss: 0.2818642854690552, valid loss: 0.08682279288768768\n",
      "epoch: 5, lr: 0.0001, bs: 32, btraining loss: 0.2369275689125061, valid loss: 0.05588485673069954\n",
      "epoch: 6, lr: 0.0001, bs: 32, btraining loss: 0.3844630718231201, valid loss: 0.08552087098360062\n",
      "epoch: 7, lr: 0.0001, bs: 32, btraining loss: 0.2864513099193573, valid loss: 0.15548157691955566\n",
      "epoch: 8, lr: 0.0001, bs: 32, btraining loss: 0.31106075644493103, valid loss: 0.05387076735496521\n",
      "epoch: 9, lr: 0.0001, bs: 32, btraining loss: 0.2561417520046234, valid loss: 0.09143327176570892\n",
      "epoch: 10, lr: 0.0001, bs: 32, btraining loss: 0.25491225719451904, valid loss: 0.0852191150188446\n",
      "epoch: 11, lr: 0.0001, bs: 32, btraining loss: 0.25757351517677307, valid loss: 0.09552697837352753\n",
      "epoch: 12, lr: 0.0001, bs: 32, btraining loss: 0.270636647939682, valid loss: 0.4158213138580322\n",
      "epoch: 13, lr: 0.0001, bs: 32, btraining loss: 0.34353145956993103, valid loss: 0.0727139264345169\n",
      "epoch: 14, lr: 0.0001, bs: 32, btraining loss: 0.17911776900291443, valid loss: 0.04830164462327957\n",
      "epoch: 15, lr: 0.0001, bs: 32, btraining loss: 0.2784102261066437, valid loss: 0.14153416454792023\n",
      "epoch: 16, lr: 0.0001, bs: 32, btraining loss: 0.21843279898166656, valid loss: 0.5217142105102539\n",
      "epoch: 17, lr: 0.0001, bs: 32, btraining loss: 0.18215784430503845, valid loss: 0.1305324286222458\n",
      "epoch: 18, lr: 0.0001, bs: 32, btraining loss: 0.18112578988075256, valid loss: 0.35635828971862793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19, lr: 0.0001, bs: 32, btraining loss: 0.27652108669281006, valid loss: 0.28421977162361145\n",
      "epoch: 20, lr: 0.0001, bs: 32, btraining loss: 0.16055777668952942, valid loss: 0.6347615718841553\n",
      "epoch: 21, lr: 0.0001, bs: 32, btraining loss: 0.20885638892650604, valid loss: 0.058525364845991135\n",
      "epoch: 22, lr: 0.0001, bs: 32, btraining loss: 0.1900562047958374, valid loss: 0.1468896120786667\n",
      "epoch: 23, lr: 0.0001, bs: 32, btraining loss: 0.16950638592243195, valid loss: 0.30618128180503845\n",
      "epoch: 24, lr: 0.0001, bs: 32, btraining loss: 0.17543944716453552, valid loss: 0.8121111989021301\n",
      "epoch: 25, lr: 0.0001, bs: 32, btraining loss: 0.19728294014930725, valid loss: 0.29472851753234863\n",
      "epoch: 26, lr: 0.0001, bs: 32, btraining loss: 0.3045680522918701, valid loss: 0.07119918614625931\n",
      "epoch: 27, lr: 0.0001, bs: 32, btraining loss: 0.2568624019622803, valid loss: 0.11905594915151596\n",
      "epoch: 28, lr: 0.0001, bs: 32, btraining loss: 0.2456774115562439, valid loss: 0.16017822921276093\n",
      "epoch: 29, lr: 0.0001, bs: 32, btraining loss: 0.234747514128685, valid loss: 0.3156070411205292\n",
      "epoch: 30, lr: 0.0001, bs: 32, btraining loss: 0.1890929639339447, valid loss: 0.08565717935562134\n",
      "epoch: 31, lr: 0.0001, bs: 32, btraining loss: 0.20051974058151245, valid loss: 0.07730738818645477\n",
      "epoch: 32, lr: 0.0001, bs: 32, btraining loss: 0.27737149596214294, valid loss: 0.14909912645816803\n",
      "epoch: 33, lr: 0.0001, bs: 32, btraining loss: 0.1799412965774536, valid loss: 0.3142276704311371\n",
      "epoch: 34, lr: 0.0001, bs: 32, btraining loss: 0.22047242522239685, valid loss: 0.5367725491523743\n",
      "epoch: 35, lr: 0.0001, bs: 32, btraining loss: 0.24208201467990875, valid loss: 0.10391339659690857\n",
      "epoch: 36, lr: 0.0001, bs: 32, btraining loss: 0.24188652634620667, valid loss: 0.1236371099948883\n",
      "epoch: 37, lr: 0.0001, bs: 32, btraining loss: 0.1503075659275055, valid loss: 0.11877918988466263\n",
      "epoch: 38, lr: 0.0001, bs: 32, btraining loss: 0.22518521547317505, valid loss: 0.10680890083312988\n",
      "epoch: 39, lr: 0.0001, bs: 32, btraining loss: 0.24760788679122925, valid loss: 0.24908462166786194\n",
      "epoch: 40, lr: 0.0001, bs: 32, btraining loss: 0.16927091777324677, valid loss: 0.5131849050521851\n",
      "epoch: 41, lr: 0.0001, bs: 32, btraining loss: 0.24521282315254211, valid loss: 0.1529650241136551\n",
      "epoch: 42, lr: 0.0001, bs: 32, btraining loss: 0.19717106223106384, valid loss: 0.11371345072984695\n",
      "epoch: 43, lr: 0.0001, bs: 32, btraining loss: 0.18468382954597473, valid loss: 0.04558207094669342\n",
      "epoch: 44, lr: 0.0001, bs: 32, btraining loss: 0.17274920642375946, valid loss: 0.2934100031852722\n",
      "epoch: 45, lr: 0.0001, bs: 32, btraining loss: 0.23733028769493103, valid loss: 0.1410859078168869\n",
      "epoch: 46, lr: 0.0001, bs: 32, btraining loss: 0.18392199277877808, valid loss: 0.015601227059960365\n",
      "epoch: 47, lr: 0.0001, bs: 32, btraining loss: 0.13216254115104675, valid loss: 0.09339581429958344\n",
      "epoch: 48, lr: 0.0001, bs: 32, btraining loss: 0.21071907877922058, valid loss: 0.07832484692335129\n",
      "epoch: 49, lr: 0.0001, bs: 32, btraining loss: 0.3251435160636902, valid loss: 0.1261911243200302\n",
      "epoch: 50, lr: 0.0001, bs: 32, btraining loss: 0.17624540627002716, valid loss: 0.09237488359212875\n",
      "epoch: 51, lr: 0.0001, bs: 32, btraining loss: 0.18295861780643463, valid loss: 0.15749116241931915\n",
      "epoch: 52, lr: 0.0001, bs: 32, btraining loss: 0.10916230082511902, valid loss: 0.13512016832828522\n",
      "epoch: 53, lr: 0.0001, bs: 32, btraining loss: 0.20595744252204895, valid loss: 0.13595205545425415\n",
      "epoch: 54, lr: 0.0001, bs: 32, btraining loss: 0.2727409899234772, valid loss: 0.06926393508911133\n",
      "epoch: 55, lr: 0.0001, bs: 32, btraining loss: 0.1646239161491394, valid loss: 0.31149688363075256\n",
      "epoch: 56, lr: 0.0001, bs: 32, btraining loss: 0.12646031379699707, valid loss: 0.44761961698532104\n",
      "epoch: 57, lr: 0.0001, bs: 32, btraining loss: 0.2264167219400406, valid loss: 0.14574043452739716\n",
      "epoch: 58, lr: 0.0001, bs: 32, btraining loss: 0.23410169780254364, valid loss: 0.22416982054710388\n",
      "epoch: 59, lr: 0.0001, bs: 32, btraining loss: 0.16312028467655182, valid loss: 0.10708555579185486\n",
      "epoch: 60, lr: 0.0001, bs: 32, btraining loss: 0.22451041638851166, valid loss: 0.09986689686775208\n",
      "epoch: 61, lr: 0.0001, bs: 32, btraining loss: 0.1330164670944214, valid loss: 0.20374400913715363\n",
      "epoch: 62, lr: 0.0001, bs: 32, btraining loss: 0.33604469895362854, valid loss: 0.389175683259964\n",
      "epoch: 63, lr: 0.0001, bs: 32, btraining loss: 0.3221004903316498, valid loss: 0.7933059334754944\n",
      "epoch: 64, lr: 0.0001, bs: 32, btraining loss: 0.27236828207969666, valid loss: 0.15535703301429749\n",
      "epoch: 65, lr: 0.0001, bs: 32, btraining loss: 0.21851982176303864, valid loss: 0.2686586380004883\n",
      "epoch: 66, lr: 0.0001, bs: 32, btraining loss: 0.15273942053318024, valid loss: 0.15454483032226562\n",
      "epoch: 67, lr: 0.0001, bs: 32, btraining loss: 0.1414910852909088, valid loss: 0.10122962296009064\n",
      "epoch: 68, lr: 0.0001, bs: 32, btraining loss: 0.13493837416172028, valid loss: 0.06151571869850159\n",
      "epoch: 69, lr: 0.0001, bs: 32, btraining loss: 0.18087266385555267, valid loss: 0.2395753115415573\n",
      "epoch: 70, lr: 0.0001, bs: 32, btraining loss: 0.1851973682641983, valid loss: 0.08309117704629898\n",
      "epoch: 71, lr: 0.0001, bs: 32, btraining loss: 0.2412867397069931, valid loss: 0.5009750127792358\n",
      "epoch: 72, lr: 0.0001, bs: 32, btraining loss: 0.14653414487838745, valid loss: 0.16750609874725342\n",
      "epoch: 73, lr: 0.0001, bs: 32, btraining loss: 0.2130444347858429, valid loss: 0.147674560546875\n",
      "epoch: 74, lr: 0.0001, bs: 32, btraining loss: 0.2486908733844757, valid loss: 0.08057853579521179\n",
      "epoch: 75, lr: 0.0001, bs: 32, btraining loss: 0.18338485062122345, valid loss: 0.213370680809021\n",
      "epoch: 76, lr: 0.0001, bs: 32, btraining loss: 0.17106029391288757, valid loss: 0.11298754811286926\n",
      "epoch: 77, lr: 0.0001, bs: 32, btraining loss: 0.30497467517852783, valid loss: 0.09696919471025467\n",
      "epoch: 78, lr: 0.0001, bs: 32, btraining loss: 0.2501031458377838, valid loss: 0.4734818637371063\n",
      "epoch: 79, lr: 0.0001, bs: 32, btraining loss: 0.23366676270961761, valid loss: 0.06889401376247406\n",
      "epoch: 80, lr: 0.0001, bs: 32, btraining loss: 0.13833287358283997, valid loss: 0.3592725694179535\n",
      "epoch: 81, lr: 0.0001, bs: 32, btraining loss: 0.27499428391456604, valid loss: 0.049369048327207565\n",
      "epoch: 82, lr: 0.0001, bs: 32, btraining loss: 0.1733309030532837, valid loss: 0.08967415243387222\n",
      "epoch: 83, lr: 0.0001, bs: 32, btraining loss: 0.2647410035133362, valid loss: 0.4322623610496521\n",
      "epoch: 84, lr: 0.0001, bs: 32, btraining loss: 0.13120192289352417, valid loss: 0.04800969734787941\n",
      "epoch: 85, lr: 0.0001, bs: 32, btraining loss: 0.22914166748523712, valid loss: 0.12013407796621323\n",
      "epoch: 86, lr: 0.0001, bs: 32, btraining loss: 0.12137898057699203, valid loss: 0.18334920704364777\n",
      "epoch: 87, lr: 0.0001, bs: 32, btraining loss: 0.10309647768735886, valid loss: 0.14031343162059784\n",
      "epoch: 88, lr: 0.0001, bs: 32, btraining loss: 0.3537355065345764, valid loss: 0.13704000413417816\n",
      "epoch: 89, lr: 0.0001, bs: 32, btraining loss: 0.28098970651626587, valid loss: 0.2929408848285675\n",
      "epoch: 90, lr: 0.0001, bs: 32, btraining loss: 0.2968595027923584, valid loss: 0.07449498772621155\n",
      "epoch: 91, lr: 0.0001, bs: 32, btraining loss: 0.13679227232933044, valid loss: 0.05093669146299362\n",
      "epoch: 92, lr: 0.0001, bs: 32, btraining loss: 0.1582581251859665, valid loss: 0.11313113570213318\n",
      "epoch: 93, lr: 0.0001, bs: 32, btraining loss: 0.2555178999900818, valid loss: 0.10659108310937881\n",
      "epoch: 94, lr: 0.0001, bs: 32, btraining loss: 0.1373378187417984, valid loss: 0.06370550394058228\n",
      "epoch: 95, lr: 0.0001, bs: 32, btraining loss: 0.13279253244400024, valid loss: 0.17803257703781128\n",
      "epoch: 96, lr: 0.0001, bs: 32, btraining loss: 0.3460244834423065, valid loss: 0.08170633018016815\n",
      "epoch: 97, lr: 0.0001, bs: 32, btraining loss: 0.21740180253982544, valid loss: 0.0461680106818676\n",
      "epoch: 98, lr: 0.0001, bs: 32, btraining loss: 0.14475923776626587, valid loss: 0.14492705464363098\n",
      "epoch: 99, lr: 0.0001, bs: 32, btraining loss: 0.1290755271911621, valid loss: 0.8283533453941345\n",
      "epoch: 0, lr: 0.0001, bs: 64, btraining loss: 0.2156699299812317, valid loss: 0.3882523775100708\n",
      "epoch: 1, lr: 0.0001, bs: 64, btraining loss: 0.20014305412769318, valid loss: 0.05233386158943176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, lr: 0.0001, bs: 64, btraining loss: 0.23592771589756012, valid loss: 0.6006602048873901\n",
      "epoch: 3, lr: 0.0001, bs: 64, btraining loss: 0.21527458727359772, valid loss: 0.05443747341632843\n",
      "epoch: 4, lr: 0.0001, bs: 64, btraining loss: 0.15120914578437805, valid loss: 0.6732425689697266\n",
      "epoch: 5, lr: 0.0001, bs: 64, btraining loss: 0.19057470560073853, valid loss: 0.21825195848941803\n",
      "epoch: 6, lr: 0.0001, bs: 64, btraining loss: 0.1925438940525055, valid loss: 0.1460627317428589\n",
      "epoch: 7, lr: 0.0001, bs: 64, btraining loss: 0.17862927913665771, valid loss: 0.39206093549728394\n",
      "epoch: 8, lr: 0.0001, bs: 64, btraining loss: 0.22149410843849182, valid loss: 0.19241458177566528\n",
      "epoch: 9, lr: 0.0001, bs: 64, btraining loss: 0.18442878127098083, valid loss: 0.18874630331993103\n",
      "epoch: 10, lr: 0.0001, bs: 64, btraining loss: 0.21044428646564484, valid loss: 0.16189952194690704\n",
      "epoch: 11, lr: 0.0001, bs: 64, btraining loss: 0.17578940093517303, valid loss: 0.18759092688560486\n",
      "epoch: 12, lr: 0.0001, bs: 64, btraining loss: 0.18680277466773987, valid loss: 0.08795804530382156\n",
      "epoch: 13, lr: 0.0001, bs: 64, btraining loss: 0.24612805247306824, valid loss: 0.0773664116859436\n",
      "epoch: 14, lr: 0.0001, bs: 64, btraining loss: 0.1337800770998001, valid loss: 0.28199639916419983\n",
      "epoch: 15, lr: 0.0001, bs: 64, btraining loss: 0.2067076563835144, valid loss: 0.19592855870723724\n",
      "epoch: 16, lr: 0.0001, bs: 64, btraining loss: 0.1468314528465271, valid loss: 0.17262519896030426\n",
      "epoch: 17, lr: 0.0001, bs: 64, btraining loss: 0.19695807993412018, valid loss: 0.13681215047836304\n",
      "epoch: 18, lr: 0.0001, bs: 64, btraining loss: 0.2238202542066574, valid loss: 0.2804757356643677\n",
      "epoch: 19, lr: 0.0001, bs: 64, btraining loss: 0.18593916296958923, valid loss: 0.08709187805652618\n",
      "epoch: 20, lr: 0.0001, bs: 64, btraining loss: 0.17278119921684265, valid loss: 0.137338787317276\n",
      "epoch: 21, lr: 0.0001, bs: 64, btraining loss: 0.20414361357688904, valid loss: 0.280651718378067\n",
      "epoch: 22, lr: 0.0001, bs: 64, btraining loss: 0.2574327886104584, valid loss: 0.0837874710559845\n",
      "epoch: 23, lr: 0.0001, bs: 64, btraining loss: 0.14811673760414124, valid loss: 0.0669584646821022\n",
      "epoch: 24, lr: 0.0001, bs: 64, btraining loss: 0.16696633398532867, valid loss: 0.21421560645103455\n",
      "epoch: 25, lr: 0.0001, bs: 64, btraining loss: 0.25888022780418396, valid loss: 0.288408100605011\n",
      "epoch: 26, lr: 0.0001, bs: 64, btraining loss: 0.18269069492816925, valid loss: 0.11285322904586792\n",
      "epoch: 27, lr: 0.0001, bs: 64, btraining loss: 0.23937155306339264, valid loss: 0.10583344101905823\n",
      "epoch: 28, lr: 0.0001, bs: 64, btraining loss: 0.19970858097076416, valid loss: 0.233963280916214\n",
      "epoch: 29, lr: 0.0001, bs: 64, btraining loss: 0.22691869735717773, valid loss: 0.06573972851037979\n",
      "epoch: 30, lr: 0.0001, bs: 64, btraining loss: 0.23816907405853271, valid loss: 0.27134785056114197\n",
      "epoch: 31, lr: 0.0001, bs: 64, btraining loss: 0.19457055628299713, valid loss: 0.6561985611915588\n",
      "epoch: 32, lr: 0.0001, bs: 64, btraining loss: 0.1937360018491745, valid loss: 0.6136508584022522\n",
      "epoch: 33, lr: 0.0001, bs: 64, btraining loss: 0.20081302523612976, valid loss: 0.15566597878932953\n",
      "epoch: 34, lr: 0.0001, bs: 64, btraining loss: 0.14260439574718475, valid loss: 0.0713699609041214\n",
      "epoch: 35, lr: 0.0001, bs: 64, btraining loss: 0.21950729191303253, valid loss: 0.14049473404884338\n",
      "epoch: 36, lr: 0.0001, bs: 64, btraining loss: 0.18858718872070312, valid loss: 0.07968820631504059\n",
      "epoch: 37, lr: 0.0001, bs: 64, btraining loss: 0.21942299604415894, valid loss: 0.116641104221344\n",
      "epoch: 38, lr: 0.0001, bs: 64, btraining loss: 0.23462875187397003, valid loss: 0.06618896871805191\n",
      "epoch: 39, lr: 0.0001, bs: 64, btraining loss: 0.2624902129173279, valid loss: 0.5423747897148132\n",
      "epoch: 40, lr: 0.0001, bs: 64, btraining loss: 0.16250665485858917, valid loss: 0.297158420085907\n",
      "epoch: 41, lr: 0.0001, bs: 64, btraining loss: 0.15727360546588898, valid loss: 0.1756928265094757\n",
      "epoch: 42, lr: 0.0001, bs: 64, btraining loss: 0.209417462348938, valid loss: 0.17846736311912537\n",
      "epoch: 43, lr: 0.0001, bs: 64, btraining loss: 0.16587309539318085, valid loss: 0.5897632837295532\n",
      "epoch: 44, lr: 0.0001, bs: 64, btraining loss: 0.15053790807724, valid loss: 0.08923721313476562\n",
      "epoch: 45, lr: 0.0001, bs: 64, btraining loss: 0.2300502061843872, valid loss: 0.18717411160469055\n",
      "epoch: 46, lr: 0.0001, bs: 64, btraining loss: 0.19846470654010773, valid loss: 0.3908007740974426\n",
      "epoch: 47, lr: 0.0001, bs: 64, btraining loss: 0.2108609974384308, valid loss: 0.04666944593191147\n",
      "epoch: 48, lr: 0.0001, bs: 64, btraining loss: 0.12999597191810608, valid loss: 0.09341153502464294\n",
      "epoch: 49, lr: 0.0001, bs: 64, btraining loss: 0.21595703065395355, valid loss: 0.22240722179412842\n",
      "epoch: 50, lr: 0.0001, bs: 64, btraining loss: 0.19288985431194305, valid loss: 0.1928848773241043\n",
      "epoch: 51, lr: 0.0001, bs: 64, btraining loss: 0.14723528921604156, valid loss: 0.11073989421129227\n",
      "epoch: 52, lr: 0.0001, bs: 64, btraining loss: 0.2595372796058655, valid loss: 0.2989070415496826\n",
      "epoch: 53, lr: 0.0001, bs: 64, btraining loss: 0.3056569993495941, valid loss: 0.8579280972480774\n",
      "epoch: 54, lr: 0.0001, bs: 64, btraining loss: 0.22624516487121582, valid loss: 0.0796230360865593\n",
      "epoch: 55, lr: 0.0001, bs: 64, btraining loss: 0.18318291008472443, valid loss: 0.15992559492588043\n",
      "epoch: 56, lr: 0.0001, bs: 64, btraining loss: 0.152769535779953, valid loss: 0.12032005190849304\n",
      "epoch: 57, lr: 0.0001, bs: 64, btraining loss: 0.1817418783903122, valid loss: 0.12297585606575012\n",
      "epoch: 58, lr: 0.0001, bs: 64, btraining loss: 0.17341704666614532, valid loss: 0.24096634984016418\n",
      "epoch: 59, lr: 0.0001, bs: 64, btraining loss: 0.14845147728919983, valid loss: 0.09898052364587784\n",
      "epoch: 60, lr: 0.0001, bs: 64, btraining loss: 0.15073363482952118, valid loss: 0.11500884592533112\n",
      "epoch: 61, lr: 0.0001, bs: 64, btraining loss: 0.17898645997047424, valid loss: 0.11321068555116653\n",
      "epoch: 62, lr: 0.0001, bs: 64, btraining loss: 0.20836837589740753, valid loss: 0.8764826059341431\n",
      "epoch: 63, lr: 0.0001, bs: 64, btraining loss: 0.23361381888389587, valid loss: 0.12962615489959717\n",
      "epoch: 64, lr: 0.0001, bs: 64, btraining loss: 0.2415895164012909, valid loss: 0.3199451267719269\n",
      "epoch: 65, lr: 0.0001, bs: 64, btraining loss: 0.2162778079509735, valid loss: 0.12842971086502075\n",
      "epoch: 66, lr: 0.0001, bs: 64, btraining loss: 0.16939407587051392, valid loss: 0.09449851512908936\n",
      "epoch: 67, lr: 0.0001, bs: 64, btraining loss: 0.16273312270641327, valid loss: 0.7782647609710693\n",
      "epoch: 68, lr: 0.0001, bs: 64, btraining loss: 0.1985926777124405, valid loss: 0.1695653200149536\n",
      "epoch: 69, lr: 0.0001, bs: 64, btraining loss: 0.23406660556793213, valid loss: 0.24906349182128906\n",
      "epoch: 70, lr: 0.0001, bs: 64, btraining loss: 0.12364690750837326, valid loss: 0.17338547110557556\n",
      "epoch: 71, lr: 0.0001, bs: 64, btraining loss: 0.15871845185756683, valid loss: 0.13584862649440765\n",
      "epoch: 72, lr: 0.0001, bs: 64, btraining loss: 0.17986951768398285, valid loss: 0.5587553977966309\n",
      "epoch: 73, lr: 0.0001, bs: 64, btraining loss: 0.2413652092218399, valid loss: 0.2516149878501892\n",
      "epoch: 74, lr: 0.0001, bs: 64, btraining loss: 0.1885240375995636, valid loss: 0.1660766899585724\n",
      "epoch: 75, lr: 0.0001, bs: 64, btraining loss: 0.18161074817180634, valid loss: 0.08640658855438232\n",
      "epoch: 76, lr: 0.0001, bs: 64, btraining loss: 0.18903450667858124, valid loss: 0.037461236119270325\n",
      "epoch: 77, lr: 0.0001, bs: 64, btraining loss: 0.16521987318992615, valid loss: 0.29950183629989624\n",
      "epoch: 78, lr: 0.0001, bs: 64, btraining loss: 0.21584513783454895, valid loss: 0.08905649185180664\n",
      "epoch: 79, lr: 0.0001, bs: 64, btraining loss: 0.21729128062725067, valid loss: 0.09667962789535522\n",
      "epoch: 80, lr: 0.0001, bs: 64, btraining loss: 0.2213587909936905, valid loss: 0.10126172751188278\n",
      "epoch: 81, lr: 0.0001, bs: 64, btraining loss: 0.22402872145175934, valid loss: 0.09614823013544083\n",
      "epoch: 82, lr: 0.0001, bs: 64, btraining loss: 0.15497779846191406, valid loss: 0.16779039800167084\n",
      "epoch: 83, lr: 0.0001, bs: 64, btraining loss: 0.23573361337184906, valid loss: 0.21353904902935028\n",
      "epoch: 84, lr: 0.0001, bs: 64, btraining loss: 0.18461927771568298, valid loss: 0.046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 85, lr: 0.0001, bs: 64, btraining loss: 0.21189570426940918, valid loss: 0.1965898871421814\n",
      "epoch: 86, lr: 0.0001, bs: 64, btraining loss: 0.2171759307384491, valid loss: 0.2284073382616043\n",
      "epoch: 87, lr: 0.0001, bs: 64, btraining loss: 0.22395142912864685, valid loss: 0.046305060386657715\n",
      "epoch: 88, lr: 0.0001, bs: 64, btraining loss: 0.12126275151968002, valid loss: 0.14496223628520966\n",
      "epoch: 89, lr: 0.0001, bs: 64, btraining loss: 0.1705242395401001, valid loss: 0.07846201956272125\n",
      "epoch: 90, lr: 0.0001, bs: 64, btraining loss: 0.27238067984580994, valid loss: 0.30906689167022705\n",
      "epoch: 91, lr: 0.0001, bs: 64, btraining loss: 0.2564946413040161, valid loss: 0.16045941412448883\n",
      "epoch: 92, lr: 0.0001, bs: 64, btraining loss: 0.1719624102115631, valid loss: 0.08637122809886932\n",
      "epoch: 93, lr: 0.0001, bs: 64, btraining loss: 0.22235043346881866, valid loss: 0.1698017418384552\n",
      "epoch: 94, lr: 0.0001, bs: 64, btraining loss: 0.1493435800075531, valid loss: 0.18262848258018494\n",
      "epoch: 95, lr: 0.0001, bs: 64, btraining loss: 0.1267019808292389, valid loss: 0.03918764740228653\n",
      "epoch: 96, lr: 0.0001, bs: 64, btraining loss: 0.21250367164611816, valid loss: 0.2046331763267517\n",
      "epoch: 97, lr: 0.0001, bs: 64, btraining loss: 0.17880912125110626, valid loss: 0.1510549783706665\n",
      "epoch: 98, lr: 0.0001, bs: 64, btraining loss: 0.20071080327033997, valid loss: 0.2927199602127075\n",
      "epoch: 99, lr: 0.0001, bs: 64, btraining loss: 0.17135469615459442, valid loss: 0.10352030396461487\n",
      "epoch: 0, lr: 0.0001, bs: 128, btraining loss: 0.24856790900230408, valid loss: 0.1698998361825943\n",
      "epoch: 1, lr: 0.0001, bs: 128, btraining loss: 0.1945793628692627, valid loss: 0.1893414855003357\n",
      "epoch: 2, lr: 0.0001, bs: 128, btraining loss: 0.1846538484096527, valid loss: 0.21550945937633514\n",
      "epoch: 3, lr: 0.0001, bs: 128, btraining loss: 0.16791069507598877, valid loss: 0.18622228503227234\n",
      "epoch: 4, lr: 0.0001, bs: 128, btraining loss: 0.19415131211280823, valid loss: 0.21712826192378998\n",
      "epoch: 5, lr: 0.0001, bs: 128, btraining loss: 0.2328675240278244, valid loss: 0.17324718832969666\n",
      "epoch: 6, lr: 0.0001, bs: 128, btraining loss: 0.14101038873195648, valid loss: 0.16581670939922333\n",
      "epoch: 7, lr: 0.0001, bs: 128, btraining loss: 0.19417759776115417, valid loss: 0.21987973153591156\n",
      "epoch: 8, lr: 0.0001, bs: 128, btraining loss: 0.15493455529212952, valid loss: 0.15162885189056396\n",
      "epoch: 9, lr: 0.0001, bs: 128, btraining loss: 0.18193164467811584, valid loss: 0.18199297785758972\n",
      "epoch: 10, lr: 0.0001, bs: 128, btraining loss: 0.2215864658355713, valid loss: 0.17107538878917694\n",
      "epoch: 11, lr: 0.0001, bs: 128, btraining loss: 0.18872547149658203, valid loss: 0.21180623769760132\n",
      "epoch: 12, lr: 0.0001, bs: 128, btraining loss: 0.1949710249900818, valid loss: 0.19323979318141937\n",
      "epoch: 13, lr: 0.0001, bs: 128, btraining loss: 0.18606393039226532, valid loss: 0.17945879697799683\n",
      "epoch: 14, lr: 0.0001, bs: 128, btraining loss: 0.1780429184436798, valid loss: 0.17935843765735626\n",
      "epoch: 15, lr: 0.0001, bs: 128, btraining loss: 0.1398492008447647, valid loss: 0.15975536406040192\n",
      "epoch: 16, lr: 0.0001, bs: 128, btraining loss: 0.21910305321216583, valid loss: 0.2008116990327835\n",
      "epoch: 17, lr: 0.0001, bs: 128, btraining loss: 0.1538815200328827, valid loss: 0.22991544008255005\n",
      "epoch: 18, lr: 0.0001, bs: 128, btraining loss: 0.1801425963640213, valid loss: 0.2118252068758011\n",
      "epoch: 19, lr: 0.0001, bs: 128, btraining loss: 0.17056035995483398, valid loss: 0.16209439933300018\n",
      "epoch: 20, lr: 0.0001, bs: 128, btraining loss: 0.20070503652095795, valid loss: 0.19739878177642822\n",
      "epoch: 21, lr: 0.0001, bs: 128, btraining loss: 0.16941890120506287, valid loss: 0.21512317657470703\n",
      "epoch: 22, lr: 0.0001, bs: 128, btraining loss: 0.23607559502124786, valid loss: 0.22949150204658508\n",
      "epoch: 23, lr: 0.0001, bs: 128, btraining loss: 0.19212400913238525, valid loss: 0.19143293797969818\n",
      "epoch: 24, lr: 0.0001, bs: 128, btraining loss: 0.1299830675125122, valid loss: 0.20228292047977448\n",
      "epoch: 25, lr: 0.0001, bs: 128, btraining loss: 0.18274472653865814, valid loss: 0.19531750679016113\n",
      "epoch: 26, lr: 0.0001, bs: 128, btraining loss: 0.23025007545948029, valid loss: 0.1896243840456009\n",
      "epoch: 27, lr: 0.0001, bs: 128, btraining loss: 0.24153625965118408, valid loss: 0.19488823413848877\n",
      "epoch: 28, lr: 0.0001, bs: 128, btraining loss: 0.1867455393075943, valid loss: 0.17884348332881927\n",
      "epoch: 29, lr: 0.0001, bs: 128, btraining loss: 0.1999759078025818, valid loss: 0.14682818949222565\n",
      "epoch: 30, lr: 0.0001, bs: 128, btraining loss: 0.1991797536611557, valid loss: 0.1968488246202469\n",
      "epoch: 31, lr: 0.0001, bs: 128, btraining loss: 0.14827416837215424, valid loss: 0.2014930546283722\n",
      "epoch: 32, lr: 0.0001, bs: 128, btraining loss: 0.1299748718738556, valid loss: 0.19787317514419556\n",
      "epoch: 33, lr: 0.0001, bs: 128, btraining loss: 0.22995002567768097, valid loss: 0.19335131347179413\n",
      "epoch: 34, lr: 0.0001, bs: 128, btraining loss: 0.2657259404659271, valid loss: 0.2087852656841278\n",
      "epoch: 35, lr: 0.0001, bs: 128, btraining loss: 0.14936469495296478, valid loss: 0.16202157735824585\n",
      "epoch: 36, lr: 0.0001, bs: 128, btraining loss: 0.27030855417251587, valid loss: 0.19833043217658997\n",
      "epoch: 37, lr: 0.0001, bs: 128, btraining loss: 0.21217434108257294, valid loss: 0.2462899535894394\n",
      "epoch: 38, lr: 0.0001, bs: 128, btraining loss: 0.21549513936042786, valid loss: 0.2567106783390045\n",
      "epoch: 39, lr: 0.0001, bs: 128, btraining loss: 0.18293993175029755, valid loss: 0.1865106076002121\n",
      "epoch: 40, lr: 0.0001, bs: 128, btraining loss: 0.17883595824241638, valid loss: 0.1592189371585846\n",
      "epoch: 41, lr: 0.0001, bs: 128, btraining loss: 0.19462496042251587, valid loss: 0.16108281910419464\n",
      "epoch: 42, lr: 0.0001, bs: 128, btraining loss: 0.18293936550617218, valid loss: 0.21772582828998566\n",
      "epoch: 43, lr: 0.0001, bs: 128, btraining loss: 0.255487859249115, valid loss: 0.2390720248222351\n",
      "epoch: 44, lr: 0.0001, bs: 128, btraining loss: 0.1928248554468155, valid loss: 0.24167683720588684\n",
      "epoch: 45, lr: 0.0001, bs: 128, btraining loss: 0.12718477845191956, valid loss: 0.20986804366111755\n",
      "epoch: 46, lr: 0.0001, bs: 128, btraining loss: 0.20545633137226105, valid loss: 0.23889687657356262\n",
      "epoch: 47, lr: 0.0001, bs: 128, btraining loss: 0.16958557069301605, valid loss: 0.22649632394313812\n",
      "epoch: 48, lr: 0.0001, bs: 128, btraining loss: 0.1929636150598526, valid loss: 0.17329835891723633\n",
      "epoch: 49, lr: 0.0001, bs: 128, btraining loss: 0.2077091783285141, valid loss: 0.21402861177921295\n",
      "epoch: 50, lr: 0.0001, bs: 128, btraining loss: 0.15375098586082458, valid loss: 0.22703616321086884\n",
      "epoch: 51, lr: 0.0001, bs: 128, btraining loss: 0.1718442291021347, valid loss: 0.20180389285087585\n",
      "epoch: 52, lr: 0.0001, bs: 128, btraining loss: 0.19890616834163666, valid loss: 0.19019779562950134\n",
      "epoch: 53, lr: 0.0001, bs: 128, btraining loss: 0.13963350653648376, valid loss: 0.18752016127109528\n",
      "epoch: 54, lr: 0.0001, bs: 128, btraining loss: 0.1331968605518341, valid loss: 0.16396188735961914\n",
      "epoch: 55, lr: 0.0001, bs: 128, btraining loss: 0.2945988178253174, valid loss: 0.21359941363334656\n",
      "epoch: 56, lr: 0.0001, bs: 128, btraining loss: 0.15005865693092346, valid loss: 0.23742590844631195\n",
      "epoch: 57, lr: 0.0001, bs: 128, btraining loss: 0.22297020256519318, valid loss: 0.16992856562137604\n",
      "epoch: 58, lr: 0.0001, bs: 128, btraining loss: 0.250437468290329, valid loss: 0.21427375078201294\n",
      "epoch: 59, lr: 0.0001, bs: 128, btraining loss: 0.17696094512939453, valid loss: 0.19766806066036224\n",
      "epoch: 60, lr: 0.0001, bs: 128, btraining loss: 0.23634077608585358, valid loss: 0.17370617389678955\n",
      "epoch: 61, lr: 0.0001, bs: 128, btraining loss: 0.1673506200313568, valid loss: 0.19276754558086395\n",
      "epoch: 62, lr: 0.0001, bs: 128, btraining loss: 0.19564160704612732, valid loss: 0.2318563610315323\n",
      "epoch: 63, lr: 0.0001, bs: 128, btraining loss: 0.1364726722240448, valid loss: 0.1857142299413681\n",
      "epoch: 64, lr: 0.0001, bs: 128, btraining loss: 0.21531957387924194, valid loss: 0.255025714635849\n",
      "epoch: 65, lr: 0.0001, bs: 128, btraining loss: 0.2006954848766327, valid loss: 0.24801696836948395\n",
      "epoch: 66, lr: 0.0001, bs: 128, btraining loss: 0.24205681681632996, valid loss: 0.21681977808475494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 67, lr: 0.0001, bs: 128, btraining loss: 0.17693708837032318, valid loss: 0.18503913283348083\n",
      "epoch: 68, lr: 0.0001, bs: 128, btraining loss: 0.19211047887802124, valid loss: 0.16002823412418365\n",
      "epoch: 69, lr: 0.0001, bs: 128, btraining loss: 0.17803645133972168, valid loss: 0.16739562153816223\n",
      "epoch: 70, lr: 0.0001, bs: 128, btraining loss: 0.17924144864082336, valid loss: 0.15245875716209412\n",
      "epoch: 71, lr: 0.0001, bs: 128, btraining loss: 0.1711030900478363, valid loss: 0.23163682222366333\n",
      "epoch: 72, lr: 0.0001, bs: 128, btraining loss: 0.11808213591575623, valid loss: 0.21895958483219147\n",
      "epoch: 73, lr: 0.0001, bs: 128, btraining loss: 0.1565430611371994, valid loss: 0.2132212519645691\n",
      "epoch: 74, lr: 0.0001, bs: 128, btraining loss: 0.1847650110721588, valid loss: 0.17113319039344788\n",
      "epoch: 75, lr: 0.0001, bs: 128, btraining loss: 0.16473723948001862, valid loss: 0.1710190773010254\n",
      "epoch: 76, lr: 0.0001, bs: 128, btraining loss: 0.16113118827342987, valid loss: 0.25347891449928284\n",
      "epoch: 77, lr: 0.0001, bs: 128, btraining loss: 0.1928393840789795, valid loss: 0.21097257733345032\n",
      "epoch: 78, lr: 0.0001, bs: 128, btraining loss: 0.17451933026313782, valid loss: 0.20164018869400024\n",
      "epoch: 79, lr: 0.0001, bs: 128, btraining loss: 0.198741614818573, valid loss: 0.18916907906532288\n",
      "epoch: 80, lr: 0.0001, bs: 128, btraining loss: 0.14880450069904327, valid loss: 0.17525218427181244\n",
      "epoch: 81, lr: 0.0001, bs: 128, btraining loss: 0.14657780528068542, valid loss: 0.22030454874038696\n",
      "epoch: 82, lr: 0.0001, bs: 128, btraining loss: 0.19998222589492798, valid loss: 0.2628065347671509\n",
      "epoch: 83, lr: 0.0001, bs: 128, btraining loss: 0.2628241777420044, valid loss: 0.18837100267410278\n",
      "epoch: 84, lr: 0.0001, bs: 128, btraining loss: 0.18268489837646484, valid loss: 0.1778791844844818\n",
      "epoch: 85, lr: 0.0001, bs: 128, btraining loss: 0.14559563994407654, valid loss: 0.17191164195537567\n",
      "epoch: 86, lr: 0.0001, bs: 128, btraining loss: 0.1624118685722351, valid loss: 0.19807428121566772\n",
      "epoch: 87, lr: 0.0001, bs: 128, btraining loss: 0.1772594302892685, valid loss: 0.21733848750591278\n",
      "epoch: 88, lr: 0.0001, bs: 128, btraining loss: 0.24416814744472504, valid loss: 0.19217549264431\n",
      "epoch: 89, lr: 0.0001, bs: 128, btraining loss: 0.14253684878349304, valid loss: 0.18047204613685608\n",
      "epoch: 90, lr: 0.0001, bs: 128, btraining loss: 0.254692018032074, valid loss: 0.16377678513526917\n",
      "epoch: 91, lr: 0.0001, bs: 128, btraining loss: 0.15684229135513306, valid loss: 0.20069070160388947\n",
      "epoch: 92, lr: 0.0001, bs: 128, btraining loss: 0.21239347755908966, valid loss: 0.18414656817913055\n",
      "epoch: 93, lr: 0.0001, bs: 128, btraining loss: 0.1888311803340912, valid loss: 0.16421882808208466\n",
      "epoch: 94, lr: 0.0001, bs: 128, btraining loss: 0.16971774399280548, valid loss: 0.22398653626441956\n",
      "epoch: 95, lr: 0.0001, bs: 128, btraining loss: 0.17917421460151672, valid loss: 0.23299092054367065\n",
      "epoch: 96, lr: 0.0001, bs: 128, btraining loss: 0.2278306484222412, valid loss: 0.17288191616535187\n",
      "epoch: 97, lr: 0.0001, bs: 128, btraining loss: 0.2322072684764862, valid loss: 0.19673049449920654\n",
      "epoch: 98, lr: 0.0001, bs: 128, btraining loss: 0.23535199463367462, valid loss: 0.19851888716220856\n",
      "epoch: 99, lr: 0.0001, bs: 128, btraining loss: 0.1756322830915451, valid loss: 0.14750665426254272\n",
      "epoch: 0, lr: 1e-05, bs: 32, btraining loss: 0.38250261545181274, valid loss: 0.061482228338718414\n",
      "epoch: 1, lr: 1e-05, bs: 32, btraining loss: 0.18511800467967987, valid loss: 0.4047788381576538\n",
      "epoch: 2, lr: 1e-05, bs: 32, btraining loss: 0.13436828553676605, valid loss: 0.22455552220344543\n",
      "epoch: 3, lr: 1e-05, bs: 32, btraining loss: 0.10827276855707169, valid loss: 0.10578817874193192\n",
      "epoch: 4, lr: 1e-05, bs: 32, btraining loss: 0.23691529035568237, valid loss: 0.08073479682207108\n",
      "epoch: 5, lr: 1e-05, bs: 32, btraining loss: 0.2226371318101883, valid loss: 0.2557690143585205\n",
      "epoch: 6, lr: 1e-05, bs: 32, btraining loss: 0.2024356573820114, valid loss: 0.3728027045726776\n",
      "epoch: 7, lr: 1e-05, bs: 32, btraining loss: 0.17224077880382538, valid loss: 0.08123081922531128\n",
      "epoch: 8, lr: 1e-05, bs: 32, btraining loss: 0.13287553191184998, valid loss: 0.22068093717098236\n",
      "epoch: 9, lr: 1e-05, bs: 32, btraining loss: 0.30433014035224915, valid loss: 0.10962861776351929\n",
      "epoch: 10, lr: 1e-05, bs: 32, btraining loss: 0.16154226660728455, valid loss: 0.11220794916152954\n",
      "epoch: 11, lr: 1e-05, bs: 32, btraining loss: 0.2521815896034241, valid loss: 0.1889505833387375\n",
      "epoch: 12, lr: 1e-05, bs: 32, btraining loss: 0.2693415582180023, valid loss: 0.07619131356477737\n",
      "epoch: 13, lr: 1e-05, bs: 32, btraining loss: 0.19269970059394836, valid loss: 0.0520041398704052\n",
      "epoch: 14, lr: 1e-05, bs: 32, btraining loss: 0.21107929944992065, valid loss: 0.2835926413536072\n",
      "epoch: 15, lr: 1e-05, bs: 32, btraining loss: 0.24635711312294006, valid loss: 1.4201762676239014\n",
      "epoch: 16, lr: 1e-05, bs: 32, btraining loss: 0.11155392974615097, valid loss: 0.09229086339473724\n",
      "epoch: 17, lr: 1e-05, bs: 32, btraining loss: 0.17369480431079865, valid loss: 0.06985399127006531\n",
      "epoch: 18, lr: 1e-05, bs: 32, btraining loss: 0.11820352077484131, valid loss: 0.06517904996871948\n",
      "epoch: 19, lr: 1e-05, bs: 32, btraining loss: 0.17688418924808502, valid loss: 0.1352919042110443\n",
      "epoch: 20, lr: 1e-05, bs: 32, btraining loss: 0.3357662260532379, valid loss: 0.0759100392460823\n",
      "epoch: 21, lr: 1e-05, bs: 32, btraining loss: 0.10500426590442657, valid loss: 0.13415849208831787\n",
      "epoch: 22, lr: 1e-05, bs: 32, btraining loss: 0.22992633283138275, valid loss: 0.11843454092741013\n",
      "epoch: 23, lr: 1e-05, bs: 32, btraining loss: 0.12718519568443298, valid loss: 0.11169390380382538\n",
      "epoch: 24, lr: 1e-05, bs: 32, btraining loss: 0.24216198921203613, valid loss: 0.09940266609191895\n",
      "epoch: 25, lr: 1e-05, bs: 32, btraining loss: 0.19558344781398773, valid loss: 0.3938848674297333\n",
      "epoch: 26, lr: 1e-05, bs: 32, btraining loss: 0.26617205142974854, valid loss: 0.11194685846567154\n",
      "epoch: 27, lr: 1e-05, bs: 32, btraining loss: 0.1981637328863144, valid loss: 0.07738692313432693\n",
      "epoch: 28, lr: 1e-05, bs: 32, btraining loss: 0.35638412833213806, valid loss: 0.17936569452285767\n",
      "epoch: 29, lr: 1e-05, bs: 32, btraining loss: 0.2593199610710144, valid loss: 0.040257588028907776\n",
      "epoch: 30, lr: 1e-05, bs: 32, btraining loss: 0.3137177526950836, valid loss: 0.10239330679178238\n",
      "epoch: 31, lr: 1e-05, bs: 32, btraining loss: 0.2567819058895111, valid loss: 0.30524489283561707\n",
      "epoch: 32, lr: 1e-05, bs: 32, btraining loss: 0.1595502495765686, valid loss: 0.6348355412483215\n",
      "epoch: 33, lr: 1e-05, bs: 32, btraining loss: 0.18049131333827972, valid loss: 0.10308235883712769\n",
      "epoch: 34, lr: 1e-05, bs: 32, btraining loss: 0.1711897999048233, valid loss: 0.18333032727241516\n",
      "epoch: 35, lr: 1e-05, bs: 32, btraining loss: 0.12076849490404129, valid loss: 0.08016444742679596\n",
      "epoch: 36, lr: 1e-05, bs: 32, btraining loss: 0.09319869428873062, valid loss: 0.24049322307109833\n",
      "epoch: 37, lr: 1e-05, bs: 32, btraining loss: 0.14734166860580444, valid loss: 0.1472007781267166\n",
      "epoch: 38, lr: 1e-05, bs: 32, btraining loss: 0.1650632619857788, valid loss: 0.12247619777917862\n",
      "epoch: 39, lr: 1e-05, bs: 32, btraining loss: 0.14264576137065887, valid loss: 0.2008683830499649\n",
      "epoch: 40, lr: 1e-05, bs: 32, btraining loss: 0.2159855216741562, valid loss: 0.270128458738327\n",
      "epoch: 41, lr: 1e-05, bs: 32, btraining loss: 0.1473539024591446, valid loss: 0.21079248189926147\n",
      "epoch: 42, lr: 1e-05, bs: 32, btraining loss: 0.21469849348068237, valid loss: 0.06662219017744064\n",
      "epoch: 43, lr: 1e-05, bs: 32, btraining loss: 0.1594250649213791, valid loss: 0.04359133541584015\n",
      "epoch: 44, lr: 1e-05, bs: 32, btraining loss: 0.14575669169425964, valid loss: 0.23948504030704498\n",
      "epoch: 45, lr: 1e-05, bs: 32, btraining loss: 0.11581533402204514, valid loss: 0.31926268339157104\n",
      "epoch: 46, lr: 1e-05, bs: 32, btraining loss: 0.1780349612236023, valid loss: 0.1574486345052719\n",
      "epoch: 47, lr: 1e-05, bs: 32, btraining loss: 0.2094045728445053, valid loss: 0.06832747906446457\n",
      "epoch: 48, lr: 1e-05, bs: 32, btraining loss: 0.1251569241285324, valid loss: 0.0908239483833313\n",
      "epoch: 49, lr: 1e-05, bs: 32, btraining loss: 0.21361562609672546, valid loss: 0.5047759413719177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, lr: 1e-05, bs: 32, btraining loss: 0.2947675287723541, valid loss: 0.11097780615091324\n",
      "epoch: 51, lr: 1e-05, bs: 32, btraining loss: 0.19228675961494446, valid loss: 0.13113565742969513\n",
      "epoch: 52, lr: 1e-05, bs: 32, btraining loss: 0.32344549894332886, valid loss: 0.06432060152292252\n",
      "epoch: 53, lr: 1e-05, bs: 32, btraining loss: 0.1698938012123108, valid loss: 0.4967673718929291\n",
      "epoch: 54, lr: 1e-05, bs: 32, btraining loss: 0.1438179910182953, valid loss: 0.08810194581747055\n",
      "epoch: 55, lr: 1e-05, bs: 32, btraining loss: 0.14950676262378693, valid loss: 0.13160406053066254\n",
      "epoch: 56, lr: 1e-05, bs: 32, btraining loss: 0.17776131629943848, valid loss: 1.032118797302246\n",
      "epoch: 57, lr: 1e-05, bs: 32, btraining loss: 0.15687508881092072, valid loss: 0.16056498885154724\n",
      "epoch: 58, lr: 1e-05, bs: 32, btraining loss: 0.3068408966064453, valid loss: 0.6165729761123657\n",
      "epoch: 59, lr: 1e-05, bs: 32, btraining loss: 0.20260897278785706, valid loss: 0.23661290109157562\n",
      "epoch: 60, lr: 1e-05, bs: 32, btraining loss: 0.1738041192293167, valid loss: 0.1156364381313324\n",
      "epoch: 61, lr: 1e-05, bs: 32, btraining loss: 0.22160112857818604, valid loss: 0.04883699119091034\n",
      "epoch: 62, lr: 1e-05, bs: 32, btraining loss: 0.1285439133644104, valid loss: 0.1830381602048874\n",
      "epoch: 63, lr: 1e-05, bs: 32, btraining loss: 0.161521315574646, valid loss: 0.20878028869628906\n",
      "epoch: 64, lr: 1e-05, bs: 32, btraining loss: 0.11983557045459747, valid loss: 0.06764092296361923\n",
      "epoch: 65, lr: 1e-05, bs: 32, btraining loss: 0.21413807570934296, valid loss: 0.07931962609291077\n",
      "epoch: 66, lr: 1e-05, bs: 32, btraining loss: 0.2907216548919678, valid loss: 0.1253175139427185\n",
      "epoch: 67, lr: 1e-05, bs: 32, btraining loss: 0.21572048962116241, valid loss: 0.06844485551118851\n",
      "epoch: 68, lr: 1e-05, bs: 32, btraining loss: 0.2621641159057617, valid loss: 0.19721317291259766\n",
      "epoch: 69, lr: 1e-05, bs: 32, btraining loss: 0.20520919561386108, valid loss: 0.22221727669239044\n",
      "epoch: 70, lr: 1e-05, bs: 32, btraining loss: 0.22858183085918427, valid loss: 0.2694494426250458\n",
      "epoch: 71, lr: 1e-05, bs: 32, btraining loss: 0.09425397217273712, valid loss: 0.12495961040258408\n",
      "epoch: 72, lr: 1e-05, bs: 32, btraining loss: 0.32858943939208984, valid loss: 0.8638302683830261\n",
      "epoch: 73, lr: 1e-05, bs: 32, btraining loss: 0.1716485470533371, valid loss: 0.19577522575855255\n",
      "epoch: 74, lr: 1e-05, bs: 32, btraining loss: 0.17974981665611267, valid loss: 0.0918477326631546\n",
      "epoch: 75, lr: 1e-05, bs: 32, btraining loss: 0.17535148561000824, valid loss: 0.15709754824638367\n",
      "epoch: 76, lr: 1e-05, bs: 32, btraining loss: 0.2894589602947235, valid loss: 0.07754860073328018\n",
      "epoch: 77, lr: 1e-05, bs: 32, btraining loss: 0.17079254984855652, valid loss: 0.3209502100944519\n",
      "epoch: 78, lr: 1e-05, bs: 32, btraining loss: 0.11263605207204819, valid loss: 0.3635712265968323\n",
      "epoch: 79, lr: 1e-05, bs: 32, btraining loss: 0.21498438715934753, valid loss: 0.03604996204376221\n",
      "epoch: 80, lr: 1e-05, bs: 32, btraining loss: 0.12959730625152588, valid loss: 0.06036447733640671\n",
      "epoch: 81, lr: 1e-05, bs: 32, btraining loss: 0.2851380705833435, valid loss: 0.13138873875141144\n",
      "epoch: 82, lr: 1e-05, bs: 32, btraining loss: 0.15117448568344116, valid loss: 0.13683414459228516\n",
      "epoch: 83, lr: 1e-05, bs: 32, btraining loss: 0.22905150055885315, valid loss: 0.12505295872688293\n",
      "epoch: 84, lr: 1e-05, bs: 32, btraining loss: 0.19697213172912598, valid loss: 0.032958753407001495\n",
      "epoch: 85, lr: 1e-05, bs: 32, btraining loss: 0.24570196866989136, valid loss: 0.09621282666921616\n",
      "epoch: 86, lr: 1e-05, bs: 32, btraining loss: 0.11740480363368988, valid loss: 0.4190521538257599\n",
      "epoch: 87, lr: 1e-05, bs: 32, btraining loss: 0.1488559991121292, valid loss: 0.16409756243228912\n",
      "epoch: 88, lr: 1e-05, bs: 32, btraining loss: 0.2490510493516922, valid loss: 0.0685017853975296\n",
      "epoch: 89, lr: 1e-05, bs: 32, btraining loss: 0.16825059056282043, valid loss: 0.26640287041664124\n",
      "epoch: 90, lr: 1e-05, bs: 32, btraining loss: 0.16920466721057892, valid loss: 0.8959683179855347\n",
      "epoch: 91, lr: 1e-05, bs: 32, btraining loss: 0.1576375961303711, valid loss: 0.09072285145521164\n",
      "epoch: 92, lr: 1e-05, bs: 32, btraining loss: 0.2208860218524933, valid loss: 0.0904337540268898\n",
      "epoch: 93, lr: 1e-05, bs: 32, btraining loss: 0.09539546817541122, valid loss: 0.07405471056699753\n",
      "epoch: 94, lr: 1e-05, bs: 32, btraining loss: 0.12465504556894302, valid loss: 0.06212421506643295\n",
      "epoch: 95, lr: 1e-05, bs: 32, btraining loss: 0.17960859835147858, valid loss: 0.069447360932827\n",
      "epoch: 96, lr: 1e-05, bs: 32, btraining loss: 0.16899937391281128, valid loss: 0.07303205877542496\n",
      "epoch: 97, lr: 1e-05, bs: 32, btraining loss: 0.21694746613502502, valid loss: 0.27133381366729736\n",
      "epoch: 98, lr: 1e-05, bs: 32, btraining loss: 0.25717562437057495, valid loss: 0.17751139402389526\n",
      "epoch: 99, lr: 1e-05, bs: 32, btraining loss: 0.16066691279411316, valid loss: 0.21361343562602997\n",
      "epoch: 0, lr: 1e-05, bs: 64, btraining loss: 0.19084277749061584, valid loss: 0.0720893070101738\n",
      "epoch: 1, lr: 1e-05, bs: 64, btraining loss: 0.18487414717674255, valid loss: 0.09474356472492218\n",
      "epoch: 2, lr: 1e-05, bs: 64, btraining loss: 0.21837839484214783, valid loss: 0.3677467107772827\n",
      "epoch: 3, lr: 1e-05, bs: 64, btraining loss: 0.19062530994415283, valid loss: 0.7996100783348083\n",
      "epoch: 4, lr: 1e-05, bs: 64, btraining loss: 0.17445598542690277, valid loss: 0.6558388471603394\n",
      "epoch: 5, lr: 1e-05, bs: 64, btraining loss: 0.2327999770641327, valid loss: 0.05870478227734566\n",
      "epoch: 6, lr: 1e-05, bs: 64, btraining loss: 0.19777800142765045, valid loss: 0.12225284427404404\n",
      "epoch: 7, lr: 1e-05, bs: 64, btraining loss: 0.21832072734832764, valid loss: 0.1497780680656433\n",
      "epoch: 8, lr: 1e-05, bs: 64, btraining loss: 0.1980292797088623, valid loss: 0.27082398533821106\n",
      "epoch: 9, lr: 1e-05, bs: 64, btraining loss: 0.12857770919799805, valid loss: 0.020169170573353767\n",
      "epoch: 10, lr: 1e-05, bs: 64, btraining loss: 0.18671724200248718, valid loss: 0.1268327385187149\n",
      "epoch: 11, lr: 1e-05, bs: 64, btraining loss: 0.12928977608680725, valid loss: 0.3422250747680664\n",
      "epoch: 12, lr: 1e-05, bs: 64, btraining loss: 0.19161991775035858, valid loss: 0.5231569409370422\n",
      "epoch: 13, lr: 1e-05, bs: 64, btraining loss: 0.1209321916103363, valid loss: 0.13838960230350494\n",
      "epoch: 14, lr: 1e-05, bs: 64, btraining loss: 0.126236692070961, valid loss: 0.6343877911567688\n",
      "epoch: 15, lr: 1e-05, bs: 64, btraining loss: 0.2171601951122284, valid loss: 0.10431449115276337\n",
      "epoch: 16, lr: 1e-05, bs: 64, btraining loss: 0.24989232420921326, valid loss: 0.24768345057964325\n",
      "epoch: 17, lr: 1e-05, bs: 64, btraining loss: 0.1169501468539238, valid loss: 0.06679031252861023\n",
      "epoch: 18, lr: 1e-05, bs: 64, btraining loss: 0.1676081120967865, valid loss: 0.26664960384368896\n",
      "epoch: 19, lr: 1e-05, bs: 64, btraining loss: 0.21835632622241974, valid loss: 0.0530424602329731\n",
      "epoch: 20, lr: 1e-05, bs: 64, btraining loss: 0.15817204117774963, valid loss: 0.08110865205526352\n",
      "epoch: 21, lr: 1e-05, bs: 64, btraining loss: 0.16622605919837952, valid loss: 0.20934277772903442\n",
      "epoch: 22, lr: 1e-05, bs: 64, btraining loss: 0.20811524987220764, valid loss: 0.5977891683578491\n",
      "epoch: 23, lr: 1e-05, bs: 64, btraining loss: 0.17568649351596832, valid loss: 0.6089707612991333\n",
      "epoch: 24, lr: 1e-05, bs: 64, btraining loss: 0.11230380833148956, valid loss: 0.10180109739303589\n",
      "epoch: 25, lr: 1e-05, bs: 64, btraining loss: 0.22850073873996735, valid loss: 0.25828611850738525\n",
      "epoch: 26, lr: 1e-05, bs: 64, btraining loss: 0.17916718125343323, valid loss: 0.10482077300548553\n",
      "epoch: 27, lr: 1e-05, bs: 64, btraining loss: 0.124005988240242, valid loss: 0.15622232854366302\n",
      "epoch: 28, lr: 1e-05, bs: 64, btraining loss: 0.19545872509479523, valid loss: 0.10790027678012848\n",
      "epoch: 29, lr: 1e-05, bs: 64, btraining loss: 0.14433497190475464, valid loss: 0.10809683799743652\n",
      "epoch: 30, lr: 1e-05, bs: 64, btraining loss: 0.1824185997247696, valid loss: 0.3913000226020813\n",
      "epoch: 31, lr: 1e-05, bs: 64, btraining loss: 0.2645859718322754, valid loss: 0.4674677848815918\n",
      "epoch: 32, lr: 1e-05, bs: 64, btraining loss: 0.2025451958179474, valid loss: 0.3001633286476135\n",
      "epoch: 33, lr: 1e-05, bs: 64, btraining loss: 0.19965605437755585, valid loss: 0.3899514079093933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34, lr: 1e-05, bs: 64, btraining loss: 0.25393471121788025, valid loss: 0.10547583550214767\n",
      "epoch: 35, lr: 1e-05, bs: 64, btraining loss: 0.19419096410274506, valid loss: 0.2391810566186905\n",
      "epoch: 36, lr: 1e-05, bs: 64, btraining loss: 0.17867062985897064, valid loss: 0.3019377291202545\n",
      "epoch: 37, lr: 1e-05, bs: 64, btraining loss: 0.1700127124786377, valid loss: 0.6624457240104675\n",
      "epoch: 38, lr: 1e-05, bs: 64, btraining loss: 0.2033432573080063, valid loss: 0.23968465626239777\n",
      "epoch: 39, lr: 1e-05, bs: 64, btraining loss: 0.25599491596221924, valid loss: 0.0788220539689064\n",
      "epoch: 40, lr: 1e-05, bs: 64, btraining loss: 0.15137545764446259, valid loss: 0.0866183415055275\n",
      "epoch: 41, lr: 1e-05, bs: 64, btraining loss: 0.2307063788175583, valid loss: 0.1493932008743286\n",
      "epoch: 42, lr: 1e-05, bs: 64, btraining loss: 0.2177170068025589, valid loss: 0.17970281839370728\n",
      "epoch: 43, lr: 1e-05, bs: 64, btraining loss: 0.18177416920661926, valid loss: 0.12401184439659119\n",
      "epoch: 44, lr: 1e-05, bs: 64, btraining loss: 0.2342040091753006, valid loss: 0.2664267122745514\n",
      "epoch: 45, lr: 1e-05, bs: 64, btraining loss: 0.2062215358018875, valid loss: 0.13211482763290405\n",
      "epoch: 46, lr: 1e-05, bs: 64, btraining loss: 0.1328386515378952, valid loss: 0.09144007414579391\n",
      "epoch: 47, lr: 1e-05, bs: 64, btraining loss: 0.2927241325378418, valid loss: 0.13753049075603485\n",
      "epoch: 48, lr: 1e-05, bs: 64, btraining loss: 0.12088052183389664, valid loss: 0.4208746552467346\n",
      "epoch: 49, lr: 1e-05, bs: 64, btraining loss: 0.1254882961511612, valid loss: 0.3057154417037964\n",
      "epoch: 50, lr: 1e-05, bs: 64, btraining loss: 0.15592211484909058, valid loss: 0.06598181277513504\n",
      "epoch: 51, lr: 1e-05, bs: 64, btraining loss: 0.1982412189245224, valid loss: 0.09771870076656342\n",
      "epoch: 52, lr: 1e-05, bs: 64, btraining loss: 0.13205720484256744, valid loss: 0.1518455147743225\n",
      "epoch: 53, lr: 1e-05, bs: 64, btraining loss: 0.15438991785049438, valid loss: 0.10897023230791092\n",
      "epoch: 54, lr: 1e-05, bs: 64, btraining loss: 0.19115649163722992, valid loss: 0.21856729686260223\n",
      "epoch: 55, lr: 1e-05, bs: 64, btraining loss: 0.15497033298015594, valid loss: 0.19300934672355652\n",
      "epoch: 56, lr: 1e-05, bs: 64, btraining loss: 0.16037729382514954, valid loss: 0.11120214313268661\n",
      "epoch: 57, lr: 1e-05, bs: 64, btraining loss: 0.20881688594818115, valid loss: 0.16921058297157288\n",
      "epoch: 58, lr: 1e-05, bs: 64, btraining loss: 0.21620739996433258, valid loss: 0.22676905989646912\n",
      "epoch: 59, lr: 1e-05, bs: 64, btraining loss: 0.23837997019290924, valid loss: 0.08718779683113098\n",
      "epoch: 60, lr: 1e-05, bs: 64, btraining loss: 0.20210711658000946, valid loss: 0.14810125529766083\n",
      "epoch: 61, lr: 1e-05, bs: 64, btraining loss: 0.18321874737739563, valid loss: 0.09392615407705307\n",
      "epoch: 62, lr: 1e-05, bs: 64, btraining loss: 0.1706872582435608, valid loss: 0.06035291403532028\n",
      "epoch: 63, lr: 1e-05, bs: 64, btraining loss: 0.19724491238594055, valid loss: 0.1185387372970581\n",
      "epoch: 64, lr: 1e-05, bs: 64, btraining loss: 0.1942366659641266, valid loss: 0.15495246648788452\n",
      "epoch: 65, lr: 1e-05, bs: 64, btraining loss: 0.18504366278648376, valid loss: 0.5938924551010132\n",
      "epoch: 66, lr: 1e-05, bs: 64, btraining loss: 0.15969665348529816, valid loss: 0.12559998035430908\n",
      "epoch: 67, lr: 1e-05, bs: 64, btraining loss: 0.19982507824897766, valid loss: 0.09036370366811752\n",
      "epoch: 68, lr: 1e-05, bs: 64, btraining loss: 0.17424383759498596, valid loss: 0.08313502371311188\n",
      "epoch: 69, lr: 1e-05, bs: 64, btraining loss: 0.2004977911710739, valid loss: 0.06358642131090164\n",
      "epoch: 70, lr: 1e-05, bs: 64, btraining loss: 0.1703491061925888, valid loss: 0.07938701659440994\n",
      "epoch: 71, lr: 1e-05, bs: 64, btraining loss: 0.16616249084472656, valid loss: 0.290304034948349\n",
      "epoch: 72, lr: 1e-05, bs: 64, btraining loss: 0.19484221935272217, valid loss: 0.40997228026390076\n",
      "epoch: 73, lr: 1e-05, bs: 64, btraining loss: 0.1933060735464096, valid loss: 0.13295875489711761\n",
      "epoch: 74, lr: 1e-05, bs: 64, btraining loss: 0.21725919842720032, valid loss: 0.17045073211193085\n",
      "epoch: 75, lr: 1e-05, bs: 64, btraining loss: 0.18764455616474152, valid loss: 0.3817816972732544\n",
      "epoch: 76, lr: 1e-05, bs: 64, btraining loss: 0.19743798673152924, valid loss: 0.14443045854568481\n",
      "epoch: 77, lr: 1e-05, bs: 64, btraining loss: 0.1798279583454132, valid loss: 0.04048965126276016\n",
      "epoch: 78, lr: 1e-05, bs: 64, btraining loss: 0.1281280815601349, valid loss: 0.07480449974536896\n",
      "epoch: 79, lr: 1e-05, bs: 64, btraining loss: 0.20948940515518188, valid loss: 0.574097216129303\n",
      "epoch: 80, lr: 1e-05, bs: 64, btraining loss: 0.23180092871189117, valid loss: 0.1377355456352234\n",
      "epoch: 81, lr: 1e-05, bs: 64, btraining loss: 0.23456422984600067, valid loss: 0.7342284321784973\n",
      "epoch: 82, lr: 1e-05, bs: 64, btraining loss: 0.17604857683181763, valid loss: 0.11649349331855774\n",
      "epoch: 83, lr: 1e-05, bs: 64, btraining loss: 0.18045048415660858, valid loss: 0.06683573871850967\n",
      "epoch: 84, lr: 1e-05, bs: 64, btraining loss: 0.18047964572906494, valid loss: 0.14067910611629486\n",
      "epoch: 85, lr: 1e-05, bs: 64, btraining loss: 0.23603737354278564, valid loss: 0.11293835937976837\n",
      "epoch: 86, lr: 1e-05, bs: 64, btraining loss: 0.21581268310546875, valid loss: 0.16244426369667053\n",
      "epoch: 87, lr: 1e-05, bs: 64, btraining loss: 0.11959994584321976, valid loss: 0.151689350605011\n",
      "epoch: 88, lr: 1e-05, bs: 64, btraining loss: 0.09341732412576675, valid loss: 0.8442047238349915\n",
      "epoch: 89, lr: 1e-05, bs: 64, btraining loss: 0.13686631619930267, valid loss: 0.05973826348781586\n",
      "epoch: 90, lr: 1e-05, bs: 64, btraining loss: 0.30961084365844727, valid loss: 0.1725711077451706\n",
      "epoch: 91, lr: 1e-05, bs: 64, btraining loss: 0.13834139704704285, valid loss: 0.08313696086406708\n",
      "epoch: 92, lr: 1e-05, bs: 64, btraining loss: 0.2090010643005371, valid loss: 0.09312180429697037\n",
      "epoch: 93, lr: 1e-05, bs: 64, btraining loss: 0.19144286215305328, valid loss: 0.07655023783445358\n",
      "epoch: 94, lr: 1e-05, bs: 64, btraining loss: 0.19549843668937683, valid loss: 0.2868916988372803\n",
      "epoch: 95, lr: 1e-05, bs: 64, btraining loss: 0.12143916636705399, valid loss: 0.07388804852962494\n",
      "epoch: 96, lr: 1e-05, bs: 64, btraining loss: 0.18628597259521484, valid loss: 0.14640051126480103\n",
      "epoch: 97, lr: 1e-05, bs: 64, btraining loss: 0.2497742772102356, valid loss: 0.029494034126400948\n",
      "epoch: 98, lr: 1e-05, bs: 64, btraining loss: 0.1820477396249771, valid loss: 0.08213721215724945\n",
      "epoch: 99, lr: 1e-05, bs: 64, btraining loss: 0.20070260763168335, valid loss: 0.17345011234283447\n",
      "epoch: 0, lr: 1e-05, bs: 128, btraining loss: 0.19930464029312134, valid loss: 0.22944696247577667\n",
      "epoch: 1, lr: 1e-05, bs: 128, btraining loss: 0.23360031843185425, valid loss: 0.22653518617153168\n",
      "epoch: 2, lr: 1e-05, bs: 128, btraining loss: 0.20791113376617432, valid loss: 0.19793887436389923\n",
      "epoch: 3, lr: 1e-05, bs: 128, btraining loss: 0.1788029670715332, valid loss: 0.19066956639289856\n",
      "epoch: 4, lr: 1e-05, bs: 128, btraining loss: 0.17669782042503357, valid loss: 0.25913572311401367\n",
      "epoch: 5, lr: 1e-05, bs: 128, btraining loss: 0.2119937539100647, valid loss: 0.22596994042396545\n",
      "epoch: 6, lr: 1e-05, bs: 128, btraining loss: 0.22609464824199677, valid loss: 0.17396071553230286\n",
      "epoch: 7, lr: 1e-05, bs: 128, btraining loss: 0.1844787299633026, valid loss: 0.20260190963745117\n",
      "epoch: 8, lr: 1e-05, bs: 128, btraining loss: 0.13540582358837128, valid loss: 0.22358115017414093\n",
      "epoch: 9, lr: 1e-05, bs: 128, btraining loss: 0.14478938281536102, valid loss: 0.18169771134853363\n",
      "epoch: 10, lr: 1e-05, bs: 128, btraining loss: 0.13744109869003296, valid loss: 0.20208218693733215\n",
      "epoch: 11, lr: 1e-05, bs: 128, btraining loss: 0.1657724827528, valid loss: 0.18114973604679108\n",
      "epoch: 12, lr: 1e-05, bs: 128, btraining loss: 0.1313350796699524, valid loss: 0.22975093126296997\n",
      "epoch: 13, lr: 1e-05, bs: 128, btraining loss: 0.16117611527442932, valid loss: 0.20794259011745453\n",
      "epoch: 14, lr: 1e-05, bs: 128, btraining loss: 0.12949725985527039, valid loss: 0.2457531839609146\n",
      "epoch: 15, lr: 1e-05, bs: 128, btraining loss: 0.1640239655971527, valid loss: 0.15107496082782745\n",
      "epoch: 16, lr: 1e-05, bs: 128, btraining loss: 0.20727115869522095, valid loss: 0.18400530517101288\n",
      "epoch: 17, lr: 1e-05, bs: 128, btraining loss: 0.20696119964122772, valid loss: 0.23470169305801392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, lr: 1e-05, bs: 128, btraining loss: 0.28386446833610535, valid loss: 0.18792051076889038\n",
      "epoch: 19, lr: 1e-05, bs: 128, btraining loss: 0.18302005529403687, valid loss: 0.1973339319229126\n",
      "epoch: 20, lr: 1e-05, bs: 128, btraining loss: 0.21865704655647278, valid loss: 0.25640028715133667\n",
      "epoch: 21, lr: 1e-05, bs: 128, btraining loss: 0.20970217883586884, valid loss: 0.20952975749969482\n",
      "epoch: 22, lr: 1e-05, bs: 128, btraining loss: 0.23858995735645294, valid loss: 0.21463601291179657\n",
      "epoch: 23, lr: 1e-05, bs: 128, btraining loss: 0.1522698998451233, valid loss: 0.1993984431028366\n",
      "epoch: 24, lr: 1e-05, bs: 128, btraining loss: 0.19248560070991516, valid loss: 0.1975107491016388\n",
      "epoch: 25, lr: 1e-05, bs: 128, btraining loss: 0.27945709228515625, valid loss: 0.2150523066520691\n",
      "epoch: 26, lr: 1e-05, bs: 128, btraining loss: 0.20639093220233917, valid loss: 0.21436648070812225\n",
      "epoch: 27, lr: 1e-05, bs: 128, btraining loss: 0.17234574258327484, valid loss: 0.18992221355438232\n",
      "epoch: 28, lr: 1e-05, bs: 128, btraining loss: 0.17461365461349487, valid loss: 0.20027539134025574\n",
      "epoch: 29, lr: 1e-05, bs: 128, btraining loss: 0.1765749752521515, valid loss: 0.21793347597122192\n",
      "epoch: 30, lr: 1e-05, bs: 128, btraining loss: 0.25407660007476807, valid loss: 0.2634042799472809\n",
      "epoch: 31, lr: 1e-05, bs: 128, btraining loss: 0.20176361501216888, valid loss: 0.17177943885326385\n",
      "epoch: 32, lr: 1e-05, bs: 128, btraining loss: 0.1797647327184677, valid loss: 0.19686777889728546\n",
      "epoch: 33, lr: 1e-05, bs: 128, btraining loss: 0.167583167552948, valid loss: 0.17238782346248627\n",
      "epoch: 34, lr: 1e-05, bs: 128, btraining loss: 0.17482875287532806, valid loss: 0.18963748216629028\n",
      "epoch: 35, lr: 1e-05, bs: 128, btraining loss: 0.17434996366500854, valid loss: 0.23314312100410461\n",
      "epoch: 36, lr: 1e-05, bs: 128, btraining loss: 0.13412438333034515, valid loss: 0.21173806488513947\n",
      "epoch: 37, lr: 1e-05, bs: 128, btraining loss: 0.16629411280155182, valid loss: 0.2253245711326599\n",
      "epoch: 38, lr: 1e-05, bs: 128, btraining loss: 0.1703660935163498, valid loss: 0.18952405452728271\n",
      "epoch: 39, lr: 1e-05, bs: 128, btraining loss: 0.21750441193580627, valid loss: 0.17750021815299988\n",
      "epoch: 40, lr: 1e-05, bs: 128, btraining loss: 0.25280559062957764, valid loss: 0.18751969933509827\n",
      "epoch: 41, lr: 1e-05, bs: 128, btraining loss: 0.1674414426088333, valid loss: 0.2060965597629547\n",
      "epoch: 42, lr: 1e-05, bs: 128, btraining loss: 0.1723276674747467, valid loss: 0.16313885152339935\n",
      "epoch: 43, lr: 1e-05, bs: 128, btraining loss: 0.18253496289253235, valid loss: 0.20725351572036743\n",
      "epoch: 44, lr: 1e-05, bs: 128, btraining loss: 0.20532195270061493, valid loss: 0.19778263568878174\n",
      "epoch: 45, lr: 1e-05, bs: 128, btraining loss: 0.1994217038154602, valid loss: 0.2116340547800064\n",
      "epoch: 46, lr: 1e-05, bs: 128, btraining loss: 0.20069420337677002, valid loss: 0.19302567839622498\n",
      "epoch: 47, lr: 1e-05, bs: 128, btraining loss: 0.23506928980350494, valid loss: 0.21660096943378448\n",
      "epoch: 48, lr: 1e-05, bs: 128, btraining loss: 0.1940436214208603, valid loss: 0.2067156434059143\n",
      "epoch: 49, lr: 1e-05, bs: 128, btraining loss: 0.2160145789384842, valid loss: 0.22178317606449127\n",
      "epoch: 50, lr: 1e-05, bs: 128, btraining loss: 0.23038040101528168, valid loss: 0.22295962274074554\n",
      "epoch: 51, lr: 1e-05, bs: 128, btraining loss: 0.12225428223609924, valid loss: 0.17983458936214447\n",
      "epoch: 52, lr: 1e-05, bs: 128, btraining loss: 0.15633425116539001, valid loss: 0.23354357481002808\n",
      "epoch: 53, lr: 1e-05, bs: 128, btraining loss: 0.16216446459293365, valid loss: 0.27695325016975403\n",
      "epoch: 54, lr: 1e-05, bs: 128, btraining loss: 0.202412411570549, valid loss: 0.246420755982399\n",
      "epoch: 55, lr: 1e-05, bs: 128, btraining loss: 0.14323988556861877, valid loss: 0.18209314346313477\n",
      "epoch: 56, lr: 1e-05, bs: 128, btraining loss: 0.24576765298843384, valid loss: 0.20706087350845337\n",
      "epoch: 57, lr: 1e-05, bs: 128, btraining loss: 0.21169637143611908, valid loss: 0.1891324669122696\n",
      "epoch: 58, lr: 1e-05, bs: 128, btraining loss: 0.2007817178964615, valid loss: 0.20399653911590576\n",
      "epoch: 59, lr: 1e-05, bs: 128, btraining loss: 0.16285905241966248, valid loss: 0.1705547273159027\n",
      "epoch: 60, lr: 1e-05, bs: 128, btraining loss: 0.14386193454265594, valid loss: 0.2059444636106491\n",
      "epoch: 61, lr: 1e-05, bs: 128, btraining loss: 0.17640480399131775, valid loss: 0.22635288536548615\n",
      "epoch: 62, lr: 1e-05, bs: 128, btraining loss: 0.1560051590204239, valid loss: 0.22154392302036285\n",
      "epoch: 63, lr: 1e-05, bs: 128, btraining loss: 0.15969684720039368, valid loss: 0.23235708475112915\n",
      "epoch: 64, lr: 1e-05, bs: 128, btraining loss: 0.1840675324201584, valid loss: 0.25461822748184204\n",
      "epoch: 65, lr: 1e-05, bs: 128, btraining loss: 0.16049151122570038, valid loss: 0.15964142978191376\n",
      "epoch: 66, lr: 1e-05, bs: 128, btraining loss: 0.21636882424354553, valid loss: 0.20652300119400024\n",
      "epoch: 67, lr: 1e-05, bs: 128, btraining loss: 0.18325084447860718, valid loss: 0.2233266681432724\n",
      "epoch: 68, lr: 1e-05, bs: 128, btraining loss: 0.22243019938468933, valid loss: 0.18939721584320068\n",
      "epoch: 69, lr: 1e-05, bs: 128, btraining loss: 0.14253860712051392, valid loss: 0.1848628669977188\n",
      "epoch: 70, lr: 1e-05, bs: 128, btraining loss: 0.1490158587694168, valid loss: 0.17460568249225616\n",
      "epoch: 71, lr: 1e-05, bs: 128, btraining loss: 0.15930819511413574, valid loss: 0.2255023717880249\n",
      "epoch: 72, lr: 1e-05, bs: 128, btraining loss: 0.18022488057613373, valid loss: 0.22635206580162048\n",
      "epoch: 73, lr: 1e-05, bs: 128, btraining loss: 0.156178817152977, valid loss: 0.2510686218738556\n",
      "epoch: 74, lr: 1e-05, bs: 128, btraining loss: 0.1363774538040161, valid loss: 0.214554101228714\n",
      "epoch: 75, lr: 1e-05, bs: 128, btraining loss: 0.3065014183521271, valid loss: 0.21797116100788116\n",
      "epoch: 76, lr: 1e-05, bs: 128, btraining loss: 0.2559269666671753, valid loss: 0.17771725356578827\n",
      "epoch: 77, lr: 1e-05, bs: 128, btraining loss: 0.18566742539405823, valid loss: 0.19606387615203857\n",
      "epoch: 78, lr: 1e-05, bs: 128, btraining loss: 0.13098934292793274, valid loss: 0.23121145367622375\n",
      "epoch: 79, lr: 1e-05, bs: 128, btraining loss: 0.1895778924226761, valid loss: 0.2104683220386505\n",
      "epoch: 80, lr: 1e-05, bs: 128, btraining loss: 0.15455245971679688, valid loss: 0.20886880159378052\n",
      "epoch: 81, lr: 1e-05, bs: 128, btraining loss: 0.13034823536872864, valid loss: 0.17875832319259644\n",
      "epoch: 82, lr: 1e-05, bs: 128, btraining loss: 0.17202617228031158, valid loss: 0.27217209339141846\n",
      "epoch: 83, lr: 1e-05, bs: 128, btraining loss: 0.15803463757038116, valid loss: 0.1984432488679886\n",
      "epoch: 84, lr: 1e-05, bs: 128, btraining loss: 0.16416460275650024, valid loss: 0.16092820465564728\n",
      "epoch: 85, lr: 1e-05, bs: 128, btraining loss: 0.2505643367767334, valid loss: 0.21369639039039612\n",
      "epoch: 86, lr: 1e-05, bs: 128, btraining loss: 0.1628410816192627, valid loss: 0.22879287600517273\n",
      "epoch: 87, lr: 1e-05, bs: 128, btraining loss: 0.09879522025585175, valid loss: 0.2340606153011322\n",
      "epoch: 88, lr: 1e-05, bs: 128, btraining loss: 0.15209169685840607, valid loss: 0.23160897195339203\n",
      "epoch: 89, lr: 1e-05, bs: 128, btraining loss: 0.1818593293428421, valid loss: 0.19185879826545715\n",
      "epoch: 90, lr: 1e-05, bs: 128, btraining loss: 0.1784767061471939, valid loss: 0.1924251765012741\n",
      "epoch: 91, lr: 1e-05, bs: 128, btraining loss: 0.210421621799469, valid loss: 0.2555418014526367\n",
      "epoch: 92, lr: 1e-05, bs: 128, btraining loss: 0.20355546474456787, valid loss: 0.21348965167999268\n",
      "epoch: 93, lr: 1e-05, bs: 128, btraining loss: 0.23592983186244965, valid loss: 0.23197925090789795\n",
      "epoch: 94, lr: 1e-05, bs: 128, btraining loss: 0.16349075734615326, valid loss: 0.180725559592247\n",
      "epoch: 95, lr: 1e-05, bs: 128, btraining loss: 0.2019658386707306, valid loss: 0.17303915321826935\n",
      "epoch: 96, lr: 1e-05, bs: 128, btraining loss: 0.2296246886253357, valid loss: 0.20426887273788452\n",
      "epoch: 97, lr: 1e-05, bs: 128, btraining loss: 0.17495104670524597, valid loss: 0.25961005687713623\n",
      "epoch: 98, lr: 1e-05, bs: 128, btraining loss: 0.21367304027080536, valid loss: 0.20627151429653168\n",
      "epoch: 99, lr: 1e-05, bs: 128, btraining loss: 0.20795658230781555, valid loss: 0.3026818633079529\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric\n",
    "from models.gnn_dataset import *\n",
    "\n",
    "### Train the GNN policy using supervised learning (L2-norm loss)\n",
    "\n",
    "# Instantiate model and training parameters\n",
    "num_epochs = 100\n",
    "batch_sizes = [32, 64, 128]\n",
    "lrs = [0.01, 0.001, 0.0001, 0.00001]\n",
    "wt_power = 1\n",
    "Device = 'cuda'\n",
    "\n",
    "model = FCNLowerBound()\n",
    "model = model.to(Device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "result = {'lr': [], 'bs': [], 'error': []}\n",
    "\n",
    "for lr in lrs:\n",
    "    for batch_size in batch_sizes:\n",
    "        \n",
    "        data_filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/trainset1_linear_pruned.pkl'\n",
    "        train_dataset = LinearLowerBoundDataset(data_filepath)\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        valid_filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/validset1_linear_pruned.pkl'\n",
    "        valid_dataset =  LinearLowerBoundDataset(valid_filepath)\n",
    "        valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            for batch in train_dataloader:        \n",
    "                feats, (z_target, _, power_target) = batch\n",
    "                feats = feats.to(Device).to(torch.float32)\n",
    "                z_target = z_target.to(Device).to(torch.float32)\n",
    "                power_target = power_target.to(Device).to(torch.float32)\n",
    "\n",
    "                z_out, power_out = model(feats)\n",
    "        #         print(loss_func(z_out, z_target.flatten()), wt_power*loss_func(power_out, power_target))\n",
    "                train_loss = loss_func(z_out, z_target) + wt_power*loss_func(power_out, power_target)\n",
    "                optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(train_loss.detach().item())\n",
    "        #         print(next(model.parameters()))\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            for batch in valid_dataloader:\n",
    "                feats, (z_target, _, power_target) = batch\n",
    "                feats = feats.to(Device).to(torch.float32)\n",
    "                z_target = z_target.to(Device).to(torch.float32)\n",
    "                power_target = power_target.to(Device).to(torch.float32)\n",
    "\n",
    "                z_out, power_out = model(feats)\n",
    "                valid_loss = loss_func(z_out, z_target) + wt_power*loss_func(power_out, power_target) \n",
    "                valid_losses.append(valid_loss.detach().item())\n",
    "\n",
    "            print('epoch: {}, lr: {}, bs: {}, btraining loss: {}, valid loss: {}'.format(epoch, lr, batch_size, train_loss, valid_loss) )\n",
    "        \n",
    "        result['lr'].append(lr)\n",
    "        result['bs'].append(batch_size)\n",
    "        result['error'].append((train_loss, valid_loss))\n",
    "        \n",
    "# Using the supervised model do antenna selection with branch and bound (as_bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc345a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1761,  1.3226,  0.1227,  ...,  1.0000,  1.0000,  0.0000],\n",
       "        [-0.0466,  0.5019,  0.2496,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.1615,  1.2945,  1.4236,  ...,  0.0000,  1.0000,  1.0000],\n",
       "        ...,\n",
       "        [-1.6466,  0.2284,  0.9649,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.4147,  0.2942,  0.1549,  ...,  0.0000,  0.0000,  1.0000],\n",
       "        [ 1.0189, -1.9142,  0.9398,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0f22676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9483e-01, 9.4667e-01, 9.9998e-01, 9.9701e-01, 9.9919e-01, 7.1722e-04,\n",
       "         2.7494e-03, 2.5643e-02],\n",
       "        [7.9694e-04, 9.4067e-01, 1.7212e-02, 9.8850e-01, 9.9947e-01, 3.4941e-03,\n",
       "         9.4554e-01, 9.0782e-01],\n",
       "        [9.9965e-01, 9.9588e-01, 4.3471e-02, 8.6507e-01, 9.8674e-01, 9.7635e-01,\n",
       "         6.3899e-04, 9.0697e-03],\n",
       "        [5.7489e-01, 5.0944e-01, 5.5812e-01, 9.6759e-01, 3.8924e-01, 2.4599e-03,\n",
       "         5.7345e-01, 7.2794e-03],\n",
       "        [2.7578e-01, 3.1439e-01, 2.9849e-01, 3.0897e-01, 2.7940e-01, 2.5139e-01,\n",
       "         2.5992e-01, 3.0915e-01],\n",
       "        [6.0261e-01, 9.8918e-01, 4.0586e-01, 9.9614e-01, 5.0021e-01, 3.9452e-01,\n",
       "         5.4187e-01, 4.2790e-01],\n",
       "        [4.7805e-01, 9.7020e-01, 5.0852e-01, 4.4346e-01, 4.5006e-01, 4.7216e-01,\n",
       "         4.8237e-01, 5.1252e-01],\n",
       "        [3.5770e-01, 3.2286e-01, 3.5869e-02, 2.3286e-01, 2.7019e-01, 2.7486e-01,\n",
       "         1.3588e-02, 3.6820e-01],\n",
       "        [1.2948e-02, 9.9761e-01, 1.2332e-01, 2.6456e-05, 9.8853e-01, 9.2160e-01,\n",
       "         9.9797e-01, 9.8907e-01],\n",
       "        [9.9940e-01, 1.9158e-03, 9.9970e-01, 9.7013e-01, 6.1198e-01, 9.9626e-01,\n",
       "         1.2363e-02, 8.7674e-03],\n",
       "        [1.2739e-02, 9.9908e-01, 6.5014e-02, 9.9557e-01, 4.4283e-02, 9.8243e-01,\n",
       "         9.9903e-01, 9.9876e-01],\n",
       "        [3.1851e-01, 3.0948e-01, 3.1945e-01, 3.2503e-01, 3.1782e-01, 3.2392e-01,\n",
       "         3.2560e-01, 3.2072e-01],\n",
       "        [3.5332e-03, 3.0643e-04, 9.9963e-01, 2.0194e-01, 9.9485e-01, 9.9130e-01,\n",
       "         3.2187e-01, 9.9934e-01],\n",
       "        [2.6601e-01, 2.6381e-01, 2.8085e-01, 2.2535e-01, 2.3678e-01, 2.6656e-01,\n",
       "         2.7064e-01, 7.4848e-02],\n",
       "        [5.2735e-01, 4.0718e-01, 9.9745e-01, 4.2308e-01, 4.1710e-01, 5.2293e-01,\n",
       "         3.9614e-01, 5.4699e-01],\n",
       "        [2.7319e-01, 3.1033e-01, 3.3635e-01, 2.8406e-01, 2.9755e-01, 2.7779e-01,\n",
       "         3.0433e-01, 3.7867e-02],\n",
       "        [9.9687e-01, 3.8332e-01, 1.0568e-01, 4.2281e-01, 9.7230e-01, 3.3692e-01,\n",
       "         5.8777e-01, 5.9618e-01],\n",
       "        [5.5950e-01, 4.2484e-01, 6.2710e-01, 3.7416e-01, 9.8857e-01, 5.8832e-01,\n",
       "         2.9965e-02, 6.0594e-01],\n",
       "        [9.8193e-01, 1.8470e-01, 7.8629e-02, 1.2436e-01, 1.3352e-01, 9.8656e-01,\n",
       "         9.9588e-01, 9.9293e-01],\n",
       "        [3.2560e-01, 3.2122e-01, 3.3264e-01, 3.3455e-01, 3.2521e-01, 3.1848e-01,\n",
       "         3.3055e-01, 3.3978e-01],\n",
       "        [3.4690e-02, 9.6708e-01, 1.0096e-01, 8.1753e-01, 1.5492e-04, 9.7767e-01,\n",
       "         8.5018e-03, 9.9932e-01],\n",
       "        [2.4875e-01, 6.3345e-03, 2.3407e-01, 2.0312e-01, 2.1733e-01, 1.7724e-01,\n",
       "         4.3580e-02, 2.7756e-01],\n",
       "        [5.0513e-01, 3.3019e-01, 5.1737e-01, 4.6254e-01, 9.9607e-01, 4.8406e-01,\n",
       "         9.9291e-01, 5.9770e-01],\n",
       "        [1.9941e-01, 9.9874e-01, 3.0856e-02, 9.2277e-01, 1.3209e-03, 1.4923e-03,\n",
       "         9.9933e-01, 5.5866e-03],\n",
       "        [3.3014e-01, 2.8805e-01, 3.1311e-01, 1.6437e-02, 2.1810e-01, 2.7499e-01,\n",
       "         2.6231e-01, 3.8008e-01],\n",
       "        [9.8938e-01, 1.3662e-03, 1.4691e-01, 9.9526e-01, 8.8424e-01, 8.8698e-01,\n",
       "         7.5069e-02, 9.8711e-01],\n",
       "        [5.9198e-03, 1.6624e-04, 2.5722e-02, 8.9379e-01, 9.9282e-01, 9.9329e-01,\n",
       "         3.9096e-02, 8.2985e-03],\n",
       "        [6.1744e-01, 4.8271e-01, 5.2622e-01, 5.5213e-01, 4.8578e-01, 9.9855e-01,\n",
       "         4.5117e-01, 5.3383e-01],\n",
       "        [9.9658e-01, 5.0412e-01, 2.2846e-02, 6.0024e-01, 4.9216e-01, 5.5291e-01,\n",
       "         1.7935e-02, 9.9578e-01],\n",
       "        [3.1984e-01, 2.9923e-01, 3.3083e-01, 2.9786e-01, 2.9979e-01, 3.2992e-01,\n",
       "         3.1182e-01, 3.3216e-01],\n",
       "        [2.4862e-01, 5.4476e-02, 2.8131e-01, 2.9190e-01, 3.1800e-01, 2.7799e-01,\n",
       "         2.8466e-01, 2.6578e-01],\n",
       "        [9.9994e-01, 9.9898e-01, 8.8918e-02, 8.7733e-05, 3.3512e-04, 1.2141e-03,\n",
       "         9.9860e-01, 9.9773e-01],\n",
       "        [2.8690e-02, 9.9827e-01, 2.0793e-02, 9.9455e-01, 9.9261e-01, 9.9631e-01,\n",
       "         3.8163e-03, 9.9657e-01],\n",
       "        [4.0499e-01, 4.3575e-01, 4.1954e-01, 3.2795e-03, 2.6638e-01, 3.0657e-01,\n",
       "         4.1251e-01, 2.6990e-01],\n",
       "        [4.4059e-01, 9.9307e-01, 3.6870e-01, 9.9828e-01, 5.6250e-01, 4.3908e-01,\n",
       "         4.5087e-01, 3.9313e-01],\n",
       "        [7.7687e-01, 9.9029e-01, 9.1681e-02, 4.6125e-01, 9.9749e-01, 2.0584e-03,\n",
       "         9.0942e-01, 8.6966e-01],\n",
       "        [3.3695e-01, 3.0087e-01, 3.0283e-01, 2.7325e-01, 3.1890e-01, 3.2762e-01,\n",
       "         3.1735e-01, 3.3896e-01],\n",
       "        [9.9368e-01, 5.6098e-01, 4.2749e-02, 9.9631e-01, 4.4596e-01, 9.9938e-01,\n",
       "         4.8017e-01, 5.2094e-03],\n",
       "        [9.9370e-01, 4.3175e-01, 9.9949e-01, 9.9708e-01, 4.3621e-01, 5.1653e-04,\n",
       "         4.0195e-03, 9.9969e-01],\n",
       "        [9.5415e-01, 1.8796e-03, 9.8361e-01, 9.4314e-01, 4.4801e-03, 9.5993e-01,\n",
       "         9.8590e-01, 2.0826e-02],\n",
       "        [3.0663e-01, 3.2519e-01, 3.3112e-01, 3.1964e-01, 3.2254e-01, 3.2350e-01,\n",
       "         3.2515e-01, 3.3290e-01],\n",
       "        [8.1477e-01, 9.9372e-01, 6.5729e-02, 5.7014e-01, 1.8406e-03, 6.9110e-01,\n",
       "         9.9628e-01, 5.5347e-01],\n",
       "        [6.2895e-01, 5.2663e-01, 5.6869e-01, 5.1725e-01, 3.7180e-03, 5.0837e-01,\n",
       "         9.9488e-01, 5.7669e-01],\n",
       "        [3.5539e-02, 3.0603e-04, 9.9998e-01, 1.7077e-05, 1.3000e-03, 9.9621e-01,\n",
       "         2.9827e-02, 9.9782e-01],\n",
       "        [2.7557e-01, 2.8201e-01, 2.8278e-01, 2.8063e-01, 2.7880e-01, 2.7719e-01,\n",
       "         2.7106e-01, 2.9127e-01],\n",
       "        [5.5108e-03, 5.2424e-01, 9.9986e-01, 5.0603e-01, 4.8017e-01, 6.2093e-01,\n",
       "         3.9371e-01, 9.9405e-01],\n",
       "        [3.1010e-01, 3.1045e-01, 3.0793e-01, 3.1555e-01, 3.0407e-01, 3.0678e-01,\n",
       "         3.0827e-01, 3.0689e-01],\n",
       "        [3.0559e-01, 3.0794e-01, 3.2109e-01, 3.1164e-01, 3.1175e-01, 3.0572e-01,\n",
       "         3.1080e-01, 3.1896e-01],\n",
       "        [1.5926e-02, 9.8821e-01, 1.0371e-01, 9.8043e-01, 3.3269e-04, 3.7543e-03,\n",
       "         9.8036e-01, 8.4558e-01],\n",
       "        [5.5954e-01, 5.0924e-01, 4.6961e-01, 5.2381e-01, 4.7036e-01, 4.9797e-01,\n",
       "         9.9116e-01, 5.4907e-01],\n",
       "        [3.0724e-01, 2.4103e-01, 3.4940e-01, 2.8140e-01, 2.5137e-01, 2.1591e-01,\n",
       "         5.7160e-02, 2.7724e-01],\n",
       "        [2.6946e-01, 2.5983e-01, 3.1252e-01, 1.7773e-01, 2.3455e-01, 2.5626e-01,\n",
       "         4.0483e-02, 2.8609e-01],\n",
       "        [9.9123e-01, 2.3237e-01, 4.3261e-01, 9.7484e-04, 9.9406e-01, 9.9894e-01,\n",
       "         9.9802e-01, 1.1291e-03],\n",
       "        [9.3943e-03, 4.4297e-03, 2.1811e-01, 9.5429e-01, 9.5972e-01, 9.9385e-01,\n",
       "         8.6828e-03, 9.9276e-01],\n",
       "        [9.9495e-01, 9.6855e-01, 5.2845e-03, 1.1769e-04, 9.9986e-01, 9.6076e-01,\n",
       "         9.5737e-01, 9.6869e-04],\n",
       "        [2.9825e-01, 2.2427e-03, 2.6629e-01, 9.9763e-01, 3.2937e-01, 9.9927e-01,\n",
       "         9.9929e-01, 9.9670e-01],\n",
       "        [2.3617e-01, 6.9157e-02, 2.8379e-01, 2.9740e-01, 2.9433e-01, 2.6530e-01,\n",
       "         3.2699e-01, 2.8600e-01],\n",
       "        [5.0970e-01, 5.2667e-01, 5.4365e-01, 4.4162e-01, 3.6783e-01, 5.3504e-01,\n",
       "         9.9438e-01, 5.1406e-01],\n",
       "        [2.8042e-02, 9.8171e-01, 9.9369e-01, 9.4454e-01, 9.9252e-01, 6.0603e-05,\n",
       "         4.2823e-02, 1.5749e-02],\n",
       "        [3.6850e-04, 9.9200e-01, 1.5383e-01, 9.6699e-01, 9.2039e-01, 5.0933e-04,\n",
       "         9.9416e-01, 1.3747e-03],\n",
       "        [2.5174e-03, 9.7912e-01, 9.3312e-02, 9.6259e-01, 9.8847e-01, 9.9288e-01,\n",
       "         1.1282e-02, 7.8954e-04],\n",
       "        [5.6007e-01, 4.7202e-01, 1.1443e-01, 2.5725e-01, 4.0855e-01, 5.3303e-01,\n",
       "         9.9314e-01, 5.3974e-01],\n",
       "        [2.8357e-01, 1.9606e-02, 3.5977e-01, 1.8997e-01, 2.7438e-01, 3.3902e-01,\n",
       "         3.0916e-01, 1.3674e-02],\n",
       "        [4.9161e-01, 9.9703e-01, 3.9179e-01, 4.5790e-01, 4.3977e-01, 5.9914e-01,\n",
       "         4.8012e-01, 5.5524e-01]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc1b89e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9abb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750115e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcfc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/trainset1_pruned.pkl'\n",
    "train_dataset = GraphLowerBoundDataset(data_filepath)\n",
    "train_dataloader = torch_geometric.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb869a7",
   "metadata": {},
   "source": [
    "## Relaxed Beamforming Supervised Learning Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a96690a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa9a3e4e048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,1)\n",
    "\n",
    "axes.plot(train_losses)\n",
    "axes.plot(valid_losses)\n",
    "axes.set_xlabel('epoch')\n",
    "axes.set_ylabel('loss')\n",
    "axes.legend(['train', 'validation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8af7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('data/results/model_training.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "caa29654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.9999, 1.0000], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "33f71653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4641, 0.4625, 0.4641, 0.4637, 0.4633, 0.4637, 0.4636, 0.4663, 0.4635,\n",
       "         0.4649, 0.4630, 0.4654, 0.4650, 0.4633, 0.4649, 0.4650, 0.4641, 0.4637,\n",
       "         0.4642, 0.4643, 0.4658, 0.4633, 0.4643, 0.4636, 0.4606, 0.4670, 0.4570,\n",
       "         0.4575, 0.4560, 0.4585, 0.4545, 0.4570, 0.4656, 0.4635, 0.4636, 0.4636,\n",
       "         0.4646, 0.4667, 0.4638, 0.4619, 0.4630, 0.4660, 0.4541, 0.4595, 0.4602,\n",
       "         0.4544, 0.4569, 0.4619, 0.4586, 0.4594, 0.4675, 0.4584, 0.4561, 0.4649,\n",
       "         0.4567, 0.4561, 0.4522, 0.4680, 0.4661, 0.4640, 0.4629, 0.4608, 0.4561,\n",
       "         0.4685, 0.4652, 0.4672, 0.4635, 0.4634, 0.4656, 0.4649, 0.4642, 0.4655,\n",
       "         0.4630, 0.4641, 0.4639, 0.4659, 0.4657, 0.4607, 0.4665, 0.4648],\n",
       "        device='cuda:0', grad_fn=<SqueezeBackward1>),\n",
       " tensor(1.1692, device='cuda:0', grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "69b11523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2769, 0.2769, 0.2768, 0.2768, 0.2769, 0.2769, 0.2768, 0.2768],\n",
       "        [0.3813, 1.0000, 0.3810, 1.0000, 0.3811, 0.3812, 1.0000, 0.3812],\n",
       "        [0.2769, 0.2769, 0.2769, 0.2769, 0.2769, 0.2768, 0.2769, 0.2768],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2768, 0.2768, 0.2769, 0.2768, 0.2769, 0.2769, 0.2768, 0.2768],\n",
       "        [1.0000, 1.0000, -0.0000, -0.0000, 1.0000, -0.0000, -0.0000, 1.0000],\n",
       "        [-0.0000, -0.0000, 1.0000, -0.0000, -0.0000, 1.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, 1.0000, -0.0000, 1.0000, 1.0000, 1.0000, -0.0000, 1.0000],\n",
       "        [0.4539, 1.0000, 0.4539, 0.4539, 0.4539, 0.4539, 0.4539, 0.4539],\n",
       "        [0.4471, 0.4470, 0.4472, 0.4470, 1.0000, 0.4469, 1.0000, 0.4472]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3ed7c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1872,  0.2619,  0.1974,  0.0000,  0.2514,  0.6482, 17.7188,  0.3639,\n",
       "         0.3097,  0.3190], device='cuda:0')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e23aaf",
   "metadata": {},
   "source": [
    "## Linear Model and Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearObservation(object):\n",
    "    def __init__(self, H_complex, z_sol, z_mask):\n",
    "        self.obs = \n",
    "        \n",
    "    def extract(self, graph_observation):\n",
    "        return sel\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9df218",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7a3acba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 9441.38it/s]\n",
      "  0%|          | 3/1000 [00:00<03:32,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n",
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1000 [00:02<03:02,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 23/1000 [00:04<03:21,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 37/1000 [00:08<04:30,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1000 [00:09<04:32,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 48/1000 [00:11<04:33,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 53/1000 [00:13<04:15,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 64/1000 [00:16<04:02,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 67/1000 [00:16<03:27,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 74/1000 [00:18<03:33,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 85/1000 [00:21<03:13,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 90/1000 [00:22<03:06,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n",
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 91/1000 [00:22<03:10,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 93/1000 [00:22<03:14,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 94/1000 [00:23<03:24,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 104/1000 [00:25<03:33,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 110/1000 [00:27<04:09,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 115/1000 [00:28<04:11,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 122/1000 [00:30<04:01,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [00:31<03:55,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 131/1000 [00:33<04:28,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 136/1000 [00:34<04:17,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 139/1000 [00:35<03:31,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 148/1000 [00:37<03:06,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 150/1000 [00:38<03:24,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 153/1000 [00:38<03:25,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 166/1000 [00:42<03:06,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 176/1000 [00:44<03:16,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [00:45<02:48,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 259/1000 [01:00<02:24,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 261/1000 [01:00<02:28,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 273/1000 [01:03<02:34,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 287/1000 [01:06<03:07,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 304/1000 [01:10<02:58,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 307/1000 [01:11<02:24,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n",
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 318/1000 [01:13<02:16,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [01:14<02:22,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 323/1000 [01:14<02:13,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 326/1000 [01:15<02:02,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n",
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 329/1000 [01:16<02:29,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 342/1000 [01:18<02:20,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 347/1000 [01:19<02:08,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 372/1000 [01:24<02:05,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 376/1000 [01:25<01:56,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 382/1000 [01:26<01:42,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 386/1000 [01:27<01:41,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 394/1000 [01:28<01:51,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 398/1000 [01:29<01:36,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 435/1000 [01:36<01:09,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 437/1000 [01:37<01:05,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 441/1000 [01:37<01:03,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 444/1000 [01:41<08:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 453/1000 [01:45<02:18,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 478/1000 [01:50<01:44,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 479/1000 [01:50<02:00,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 484/1000 [01:51<01:55,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 490/1000 [01:53<01:39,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n",
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 499/1000 [01:54<01:43,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [01:55<01:44,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 502/1000 [01:55<02:02,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 504/1000 [01:56<01:59,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 510/1000 [01:57<02:24,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 541/1000 [02:07<02:12,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 542/1000 [02:07<02:10,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 544/1000 [02:08<02:19,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 554/1000 [02:11<02:10,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 556/1000 [02:11<01:54,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 557/1000 [02:11<01:56,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 568/1000 [02:14<01:40,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 571/1000 [02:15<01:29,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 578/1000 [02:16<01:41,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 580/1000 [02:17<01:32,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 582/1000 [02:17<01:38,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 615/1000 [02:26<01:29,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 625/1000 [02:28<01:37,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 628/1000 [02:29<01:33,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 633/1000 [02:30<01:15,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 636/1000 [02:31<01:29,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [02:34<01:06,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 654/1000 [02:34<01:16,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 659/1000 [02:36<01:32,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 708/1000 [02:50<01:10,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 722/1000 [02:53<01:03,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 743/1000 [02:57<00:47,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 761/1000 [03:00<00:44,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 770/1000 [03:02<00:40,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 791/1000 [03:09<00:53,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 794/1000 [03:10<00:45,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 798/1000 [03:11<00:36,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 804/1000 [03:12<00:41,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 806/1000 [03:12<00:44,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 817/1000 [03:15<00:35,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 829/1000 [03:17<00:42,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 834/1000 [03:19<00:40,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 840/1000 [03:20<00:46,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 845/1000 [03:22<00:43,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 849/1000 [03:23<00:43,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 866/1000 [03:27<00:29,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 877/1000 [03:29<00:22,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 889/1000 [03:32<00:25,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 892/1000 [03:33<00:25,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 902/1000 [03:36<00:27,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 904/1000 [03:36<00:26,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 909/1000 [03:38<00:25,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 917/1000 [03:40<00:23,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 929/1000 [03:43<00:19,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 942/1000 [03:46<00:12,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 944/1000 [03:47<00:12,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 951/1000 [03:48<00:10,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 961/1000 [03:51<00:07,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 965/1000 [03:51<00:07,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 981/1000 [03:55<00:03,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 999/1000 [03:58<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infeasible solution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:58<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from antenna_selection.beamforming_test import Beamforming\n",
    "from tqdm import tqdm, trange\n",
    "# Generate Training Examples \n",
    "# save the training examples in pkl\n",
    "NUM_TRAIN_H = 1000\n",
    "N, M = 8,3\n",
    "L = 5\n",
    "\n",
    "H_complex = np.random.randn(NUM_TRAIN_H, N,M) + 1j*np.random.randn(NUM_TRAIN_H,N,M)\n",
    "\n",
    "z_sol = []\n",
    "z_mask = []\n",
    "for i in trange(NUM_TRAIN_H):\n",
    "    p_sol = np.random.rand(1)\n",
    "    p_mask = np.random.rand(1)\n",
    "    z_sol.append(np.random.binomial(size=N, n=1, p=p_sol))\n",
    "    z_mask.append(np.random.binomial(size=N, n=1, p=p_mask))\n",
    "z_sol = np.array(z_sol)\n",
    "z_mask = np.array(z_mask)\n",
    "\n",
    "# Solve each problem using cvxpy\n",
    "sol = {'z': [], 'W': [], 'power': []}\n",
    "for i in trange(NUM_TRAIN_H):\n",
    "    bm_solver = Beamforming(H_complex[i,:,:], max_ant=L)\n",
    "    z, W, power = bm_solver.solve_beamforming(z_sol=z_sol[i,:], z_mask=z_mask[i,:])\n",
    "    if z is not None:\n",
    "        sol['z'].append(z)\n",
    "        sol['W'].append(W)\n",
    "        sol['power'].append(power)\n",
    "    else:\n",
    "        sol['z'].append(np.zeros(N))\n",
    "        sol['W'].append(np.zeros((N,M)))\n",
    "        sol['power'].append(np.float64(-1))\n",
    "        \n",
    "# sol['z'] = np.array(sol['z'])\n",
    "# sol['W'] = np.array(sol['W'])\n",
    "# sol['power'] = np.array(sol['power'])\n",
    "\n",
    "sol = (np.array(sol['z']), np.array(sol['W']), np.array(sol['power']))\n",
    "\n",
    "target = []\n",
    "obs = []\n",
    "for i in range(NUM_TRAIN_H):\n",
    "    obs.append(LowerBoundObservation(H_complex[i,:,:], z_sol[i,:], z_mask[i,:]))\n",
    "    target.append((sol[0][i,::], sol[1][i,::], sol[2][i]))\n",
    "    \n",
    "# Save the file in pkl\n",
    "data = {'params':{'H': H_complex, 'z_sol': z_sol, 'z_mask': z_mask}, 'in':obs, 'out': target}\n",
    "filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/validset1.pkl'\n",
    "with open(filepath, 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7372efb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e43977f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 18 is out of bounds for axis 0 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-49eede2f6462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_TRAIN_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLowerBoundObservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_complex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_sol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Save the file in pkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 18 is out of bounds for axis 0 with size 18"
     ]
    }
   ],
   "source": [
    "\n",
    "# sol = (np.array(sol['z']), np.array(sol['W']), np.array(sol['power']))\n",
    "\n",
    "target = []\n",
    "obs = []\n",
    "for i in range(NUM_TRAIN_H):\n",
    "    obs.append(LowerBoundObservation(H_complex[i,:,:], z_sol[i,:], z_mask[i,:]))\n",
    "    target.append((sol[0][i,::], sol[1][i,::], sol[2][i]))\n",
    "    \n",
    "# Save the file in pkl\n",
    "data = {'params':{'H': H_complex, 'z_sol': z_sol, 'z_mask': z_mask}, 'in':obs, 'out': target}\n",
    "filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/validset1.pkl'\n",
    "with open(filepath, 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62694368",
   "metadata": {},
   "source": [
    "## Data Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be837487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 8368\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/trainset1.pkl'\n",
    "with open(filepath, 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "# check data\n",
    "# for i in range(100):\n",
    "#     if data['out'][i][2] > 2:\n",
    "#         print(data['in'][i].antenna_features, data['out'][i][2])\n",
    "\n",
    "new_data = {'in':[], 'out':[]}\n",
    "for i in range(len(data['in'])):\n",
    "    if data['out'][i][2] > 0 and data['out'][i][2] < 2 :\n",
    "        new_data['in'].append(data['in'][i])\n",
    "        new_data['out'].append(data['out'][i])\n",
    "        \n",
    "print('data size', len(new_data['in']))\n",
    "\n",
    "# save data\n",
    "filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/trainset1_pruned.pkl'\n",
    "with open(filepath, 'wb') as handle:\n",
    "    pickle.dump(new_data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22b821",
   "metadata": {},
   "source": [
    "## Observation to Linear Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c0d545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size 834\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/validset1.pkl'\n",
    "with open(filepath, 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "# check data\n",
    "# for i in range(100):\n",
    "#     if data['out'][i][2] > 2:\n",
    "#         print(data['in'][i].antenna_features, data['out'][i][2])\n",
    "\n",
    "new_data = {'in':[], 'out':[]}\n",
    "for i in range(len(data['in'])):\n",
    "    if data['out'][i][2] > 0 and data['out'][i][2] < 2 :\n",
    "        linear_obs = LinearLowerBoundObservation(data['params']['H'][i], data['params']['z_sol'][i], data['params']['z_mask'][i])\n",
    "        new_data['in'].append(linear_obs)\n",
    "        new_data['out'].append(data['out'][i])\n",
    "\n",
    "print('data size', len(new_data['in']))\n",
    "\n",
    "# save data\n",
    "filepath = '/scratch/sagar/Projects/combopt/branch-and-bound-ml/antenna_selection/data/bound_approximation/validset1_linear_pruned.pkl'\n",
    "with open(filepath, 'wb') as handle:\n",
    "    pickle.dump(new_data, handle, protocol=pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a1dfaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "324348fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11564795, 1.43990595, 1.94171292, 0.73024635, 1.78498364,\n",
       "       1.86398361, 1.21960891, 2.0601011 , 1.75103837, 2.62009032,\n",
       "       1.94508909, 1.46316805, 0.81350504, 1.22580305, 1.57157851,\n",
       "       0.66226483, 0.26367738, 1.3295895 , 1.04369569, 0.96843053,\n",
       "       0.24188002, 1.96912241, 1.17307799, 0.84313454])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(data['params']['H'][0]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef9f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1389e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([[0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j],\n",
       "        [0.+0.j, 0.+0.j, 0.+0.j]]),\n",
       " -1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['out'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4824c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "95df920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['out'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e4e51041",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18105bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb6a968c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-2064b7fcd98a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "sol[3].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
