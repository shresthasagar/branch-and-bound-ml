{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d97f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from  acr_bb import Observation, ACRBBenv, DefaultBranchingPolicy, RandomPolicy, LinearObservation\n",
    "from fcn_policy import FCNDataset, FCNBranchingPolicy, FCNNodeSelectionPolicy \n",
    "\n",
    "MAX_SAMPLES = 100000\n",
    "\n",
    "N = 8 # antennas\n",
    "M = 4 # users\n",
    "expert_prob = 0.5\n",
    "\n",
    "def instance_generator(M, N):\n",
    "    while 1:\n",
    "        yield np.random.randn(2,N,M)\n",
    "\n",
    "# instances = np.random.randn(MAX_SAMPLES, 2, N, M)\n",
    "instances = instance_generator(M,N)\n",
    "\n",
    "env = ACRBBenv()\n",
    "\n",
    "expert_policy = DefaultBranchingPolicy()\n",
    "random_policy = RandomPolicy()\n",
    "\n",
    "episode_counter, sample_counter = 0, 0\n",
    "Path('positive_node_samples/').mkdir(exist_ok=True)\n",
    "Path('negative_node_samples/').mkdir(exist_ok=True)\n",
    "\n",
    "# We will solve problems (run episodes) until we have saved enough samples\n",
    "max_samples_reached = False\n",
    "\n",
    "while not max_samples_reached:\n",
    "    episode_counter += 1\n",
    "    \n",
    "    observation_list = []\n",
    "    node_indices = []\n",
    "    observation, action_set, reward, done, _ = env.reset(next(instances))\n",
    "    node_indices.append(env.active_node.node_index)\n",
    "    observation_list.append(observation)\n",
    "    while not done and reward > -5:\n",
    "        if np.random.rand(1) > expert_prob:\n",
    "            action_id = expert_policy.select_variable(observation, action_set)\n",
    "        else:\n",
    "            action_id = random_policy.select_variable(observation, action_set)\n",
    "\n",
    "        observation, action_set, reward, done, _ = env.step(action_id)\n",
    "    \n",
    "    for node in env.all_nodes:\n",
    "        if node.optimal:\n",
    "            for i in range(len(node_indices)):\n",
    "                if node_indices[i] == node.node_index:\n",
    "                    data = [observation_list[i], True]\n",
    "                    break\n",
    "        else:\n",
    "            for i in range(len(node_indices)):\n",
    "                if node_indices[i] == node.node_index:\n",
    "                    data = [observation_list[i], False]\n",
    "                    break\n",
    "            \n",
    "        if not max_samples_reached:\n",
    "            sample_counter += 1\n",
    "            \n",
    "            if node.optimal:\n",
    "                filename = f'positive_node_samples/sample_{sample_counter}.pkl'\n",
    "            else:\n",
    "                filename = f'negative_node_samples/sample_{sample_counter}.pkl'\n",
    "                \n",
    "            with gzip.open(filename, 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "            # If we collected enough samples, we finish the current episode but stop saving samples\n",
    "            if sample_counter >= MAX_SAMPLES:\n",
    "                max_samples_reached = True\n",
    "                break;\n",
    "    print(f\"Episode {episode_counter}, {sample_counter} samples collected so far\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fa0bc",
   "metadata": {},
   "source": [
    "# Train FCN model for node Selection classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449d0c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4132423\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:12<00:00, 45.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[130575,  80889],\n",
      "        [ 75927, 135537]])\n",
      "422928\n",
      "Train loss: 0.635, accuracy 0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:20<00:00, 40.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26043, 26824],\n",
      "        [10706, 42161]])\n",
      "105734\n",
      "Valid loss: 0.624, accuracy 0.692\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:18<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[130301,  81163],\n",
      "        [ 62623, 148841]])\n",
      "422928\n",
      "Train loss: 0.617, accuracy 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28017, 24850],\n",
      "        [11381, 41486]])\n",
      "105734\n",
      "Valid loss: 0.616, accuracy 0.696\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[132262,  79202],\n",
      "        [ 61245, 150219]])\n",
      "422928\n",
      "Train loss: 0.613, accuracy 0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31914, 20953],\n",
      "        [13732, 39135]])\n",
      "105734\n",
      "Valid loss: 0.611, accuracy 0.693\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:20<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[133740,  77724],\n",
      "        [ 59861, 151603]])\n",
      "422928\n",
      "Train loss: 0.610, accuracy 0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31721, 21146],\n",
      "        [13241, 39626]])\n",
      "105734\n",
      "Valid loss: 0.607, accuracy 0.697\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[134680,  76784],\n",
      "        [ 59004, 152460]])\n",
      "422928\n",
      "Train loss: 0.607, accuracy 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 46.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26658, 26209],\n",
      "        [ 8900, 43967]])\n",
      "105734\n",
      "Valid loss: 0.608, accuracy 0.715\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:17<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[135231,  76233],\n",
      "        [ 58550, 152914]])\n",
      "422928\n",
      "Train loss: 0.604, accuracy 0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 46.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30919, 21948],\n",
      "        [11931, 40936]])\n",
      "105734\n",
      "Valid loss: 0.601, accuracy 0.707\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[135826,  75638],\n",
      "        [ 57928, 153536]])\n",
      "422928\n",
      "Train loss: 0.601, accuracy 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28539, 24328],\n",
      "        [ 9600, 43267]])\n",
      "105734\n",
      "Valid loss: 0.600, accuracy 0.718\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:20<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[136258,  75206],\n",
      "        [ 57464, 154000]])\n",
      "422928\n",
      "Train loss: 0.599, accuracy 0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 46.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29575, 23292],\n",
      "        [10278, 42589]])\n",
      "105734\n",
      "Valid loss: 0.596, accuracy 0.717\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[136585,  74879],\n",
      "        [ 57303, 154161]])\n",
      "422928\n",
      "Train loss: 0.597, accuracy 0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 46.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32199, 20668],\n",
      "        [12370, 40497]])\n",
      "105734\n",
      "Valid loss: 0.593, accuracy 0.710\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:20<00:00, 41.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[136802,  74662],\n",
      "        [ 57039, 154425]])\n",
      "422928\n",
      "Train loss: 0.595, accuracy 0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32327, 20540],\n",
      "        [12347, 40520]])\n",
      "105734\n",
      "Valid loss: 0.591, accuracy 0.711\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:13<00:00, 44.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[137209,  74255],\n",
      "        [ 57086, 154378]])\n",
      "422928\n",
      "Train loss: 0.593, accuracy 0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37783, 15084],\n",
      "        [18074, 34793]])\n",
      "105734\n",
      "Valid loss: 0.590, accuracy 0.677\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:20<00:00, 40.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[137502,  73962],\n",
      "        [ 56895, 154569]])\n",
      "422928\n",
      "Train loss: 0.591, accuracy 0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 46.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[36769, 16098],\n",
      "        [16861, 36006]])\n",
      "105734\n",
      "Valid loss: 0.588, accuracy 0.686\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:18<00:00, 42.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[137642,  73822],\n",
      "        [ 56649, 154815]])\n",
      "422928\n",
      "Train loss: 0.590, accuracy 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 51.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30649, 22218],\n",
      "        [10518, 42349]])\n",
      "105734\n",
      "Valid loss: 0.588, accuracy 0.721\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[137762,  73702],\n",
      "        [ 56506, 154958]])\n",
      "422928\n",
      "Train loss: 0.589, accuracy 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33490, 19377],\n",
      "        [13075, 39792]])\n",
      "105734\n",
      "Valid loss: 0.585, accuracy 0.710\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[137996,  73468],\n",
      "        [ 56589, 154875]])\n",
      "422928\n",
      "Train loss: 0.587, accuracy 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 48.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34930, 17937],\n",
      "        [14544, 38323]])\n",
      "105734\n",
      "Valid loss: 0.581, accuracy 0.702\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[137802,  73662],\n",
      "        [ 56386, 155078]])\n",
      "422928\n",
      "Train loss: 0.586, accuracy 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 50.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32309, 20558],\n",
      "        [11825, 41042]])\n",
      "105734\n",
      "Valid loss: 0.581, accuracy 0.717\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138081,  73383],\n",
      "        [ 56246, 155218]])\n",
      "422928\n",
      "Train loss: 0.584, accuracy 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:15<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33515, 19352],\n",
      "        [13260, 39607]])\n",
      "105734\n",
      "Valid loss: 0.580, accuracy 0.708\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138259,  73205],\n",
      "        [ 56269, 155195]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 48.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35258, 17609],\n",
      "        [14820, 38047]])\n",
      "105734\n",
      "Valid loss: 0.578, accuracy 0.701\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138088,  73376],\n",
      "        [ 56056, 155408]])\n",
      "422928\n",
      "Train loss: 0.581, accuracy 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 51.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28707, 24160],\n",
      "        [ 8746, 44121]])\n",
      "105734\n",
      "Valid loss: 0.583, accuracy 0.728\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:13<00:00, 44.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138386,  73078],\n",
      "        [ 56271, 155193]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 49.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34982, 17885],\n",
      "        [14356, 38511]])\n",
      "105734\n",
      "Valid loss: 0.577, accuracy 0.705\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138114,  73350],\n",
      "        [ 55902, 155562]])\n",
      "422928\n",
      "Train loss: 0.581, accuracy 0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30932, 21935],\n",
      "        [10491, 42376]])\n",
      "105734\n",
      "Valid loss: 0.579, accuracy 0.723\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:13<00:00, 45.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138340,  73124],\n",
      "        [ 55849, 155615]])\n",
      "422928\n",
      "Train loss: 0.581, accuracy 0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33906, 18961],\n",
      "        [13282, 39585]])\n",
      "105734\n",
      "Valid loss: 0.576, accuracy 0.711\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:17<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138503,  72961],\n",
      "        [ 55975, 155489]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[36349, 16518],\n",
      "        [15711, 37156]])\n",
      "105734\n",
      "Valid loss: 0.576, accuracy 0.697\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138635,  72829],\n",
      "        [ 55609, 155855]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34223, 18644],\n",
      "        [13433, 39434]])\n",
      "105734\n",
      "Valid loss: 0.578, accuracy 0.711\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138476,  72988],\n",
      "        [ 55566, 155898]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[38132, 14735],\n",
      "        [17884, 34983]])\n",
      "105734\n",
      "Valid loss: 0.578, accuracy 0.682\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138699,  72765],\n",
      "        [ 55564, 155900]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 49.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[28086, 24781],\n",
      "        [ 7943, 44924]])\n",
      "105734\n",
      "Valid loss: 0.584, accuracy 0.733\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138510,  72954],\n",
      "        [ 55181, 156283]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 48.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37308, 15559],\n",
      "        [16901, 35966]])\n",
      "105734\n",
      "Valid loss: 0.578, accuracy 0.689\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:13<00:00, 44.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138650,  72814],\n",
      "        [ 55334, 156130]])\n",
      "422928\n",
      "Train loss: 0.583, accuracy 0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 50.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33356, 19511],\n",
      "        [12529, 40338]])\n",
      "105734\n",
      "Valid loss: 0.577, accuracy 0.716\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138710,  72754],\n",
      "        [ 55159, 156305]])\n",
      "422928\n",
      "Train loss: 0.583, accuracy 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33083, 19784],\n",
      "        [12179, 40688]])\n",
      "105734\n",
      "Valid loss: 0.579, accuracy 0.718\n",
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138523,  72941],\n",
      "        [ 55099, 156365]])\n",
      "422928\n",
      "Train loss: 0.583, accuracy 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 48.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34885, 17982],\n",
      "        [14088, 38779]])\n",
      "105734\n",
      "Valid loss: 0.579, accuracy 0.707\n",
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138471,  72993],\n",
      "        [ 54957, 156507]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 47.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34793, 18074],\n",
      "        [14000, 38867]])\n",
      "105734\n",
      "Valid loss: 0.580, accuracy 0.708\n",
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138560,  72904],\n",
      "        [ 55062, 156402]])\n",
      "422928\n",
      "Train loss: 0.583, accuracy 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:14<00:00, 56.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[34525, 18342],\n",
      "        [13535, 39332]])\n",
      "105734\n",
      "Valid loss: 0.580, accuracy 0.712\n",
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 43.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138668,  72796],\n",
      "        [ 54811, 156653]])\n",
      "422928\n",
      "Train loss: 0.582, accuracy 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[38408, 14459],\n",
      "        [18167, 34700]])\n",
      "105734\n",
      "Valid loss: 0.583, accuracy 0.680\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:16<00:00, 42.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138663,  72801],\n",
      "        [ 55082, 156382]])\n",
      "422928\n",
      "Train loss: 0.583, accuracy 0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35209, 17658],\n",
      "        [14333, 38534]])\n",
      "105734\n",
      "Valid loss: 0.581, accuracy 0.707\n",
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:13<00:00, 44.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138605,  72859],\n",
      "        [ 54796, 156668]])\n",
      "422928\n",
      "Train loss: 0.583, accuracy 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[31787, 21080],\n",
      "        [11010, 41857]])\n",
      "105734\n",
      "Valid loss: 0.585, accuracy 0.723\n",
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138678,  72786],\n",
      "        [ 54753, 156711]])\n",
      "422928\n",
      "Train loss: 0.584, accuracy 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:16<00:00, 48.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27734, 25133],\n",
      "        [ 7559, 45308]])\n",
      "105734\n",
      "Valid loss: 0.594, accuracy 0.735\n",
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:14<00:00, 44.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138624,  72840],\n",
      "        [ 54721, 156743]])\n",
      "422928\n",
      "Train loss: 0.584, accuracy 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:17<00:00, 48.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33087, 19780],\n",
      "        [12154, 40713]])\n",
      "105734\n",
      "Valid loss: 0.583, accuracy 0.718\n",
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3305/3305 [01:15<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[138743,  72721],\n",
      "        [ 54656, 156808]])\n",
      "422928\n",
      "Train loss: 0.585, accuracy 0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 443/827 [00:08<00:07, 50.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-71e0c7914cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mtrains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Valid loss: {valid_loss:0.3f}, accuracy {valid_acc:0.3f}\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mvalids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-71e0c7914cd5>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(policy, data_loader, optimizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpreds_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#             print(batch[0], batch[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/combopt/venv/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sagar/Projects/combopt/branch-and-bound-ml/acr_bb/fcn_policy.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0msample_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# out = sample_observation.observation - torch.mean(sample_observation.observation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_not_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mREAD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from fcn_policy import FCNNodeDataset, FCNNodeFakeDataset, FCNBranchingPolicy, FCNNodeSelectionPolicy, FCNNodeSelectionLinearPolicy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NB_EPOCHS = 150\n",
    "PATIENCE = 10\n",
    "EARLY_STOPPING = 20\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "def process(policy, data_loader, optimizer=None):\n",
    "    \"\"\"\n",
    "    This function will process a whole epoch of training or validation, depending on whether an optimizer is provided.\n",
    "    \"\"\"\n",
    "    mean_loss = 0\n",
    "    mean_acc = 0\n",
    "\n",
    "    n_samples_processed = 0\n",
    "    targets_list = torch.Tensor([]).to(DEVICE)\n",
    "    preds_list = torch.Tensor([]).to(DEVICE)\n",
    "    with torch.set_grad_enabled(optimizer is not None):\n",
    "        for batch_data in tqdm(data_loader):\n",
    "            batch, target = batch_data\n",
    "#             print(batch[0], batch[1])\n",
    "#             print(target.sum())\n",
    "            batch = batch.to(DEVICE)\n",
    "            target = target.squeeze().to(DEVICE)*1\n",
    "            \n",
    "            out = policy(batch).squeeze()\n",
    "\n",
    "            bce = nn.BCELoss()\n",
    "            \n",
    "            loss = bce(out, target.to(torch.float))\n",
    "            \n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            predicted_bestindex = (out>0.5)*1\n",
    "            accuracy = sum(predicted_bestindex.reshape(-1) == target)\n",
    "            \n",
    "            targets_list = torch.cat((targets_list, target))\n",
    "            preds_list = torch.cat((preds_list, predicted_bestindex))\n",
    "            \n",
    "            mean_loss += loss.item() * batch.shape[0]\n",
    "            mean_acc += float(accuracy)\n",
    "            n_samples_processed += batch.shape[0]\n",
    "\n",
    "    stacked = torch.stack((targets_list, preds_list), dim=1).to(torch.int)\n",
    "    cmt = torch.zeros(2,2,dtype=torch.int64)\n",
    "    for p in stacked:\n",
    "        tl, pl = p.tolist()\n",
    "        cmt[tl, pl] = cmt[tl, pl] + 1\n",
    "    print(cmt)\n",
    "    precision = cmt[1,1]/(cmt[0,1]+cmt[1,1])\n",
    "    recall = cmt[1,1]/(cmt[1,0]+cmt[1,1])\n",
    "    mean_acc = 2* (precision*recall)/(precision+recall)\n",
    "    print(n_samples_processed)\n",
    "    mean_loss /= n_samples_processed\n",
    "#     mean_acc /= n_samples_processed\n",
    "    return mean_loss, mean_acc\n",
    "\n",
    "\n",
    "def pad_tensor(input_, pad_sizes, pad_value=-1e8):\n",
    "    \"\"\"\n",
    "    This utility function splits a tensor and pads each split to make them all the same size, then stacks them.\n",
    "    \"\"\"\n",
    "    max_pad_size = pad_sizes.max()\n",
    "    output = input_.split(pad_sizes.cpu().numpy().tolist())\n",
    "    output = torch.stack([F.pad(slice_, (0, max_pad_size-slice_.size(0)), 'constant', pad_value)\n",
    "                          for slice_ in output], dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "positive_sample_files = [str(path) for path in Path('data/2_fcn_10k_positive_node_samples/').glob('sample_*.pkl')]\n",
    "positive_trains = positive_sample_files[:int(0.8*len(positive_sample_files))]\n",
    "positive_valids = positive_sample_files[int(0.8*len(positive_sample_files)):]\n",
    "\n",
    "# negative_sample_files = ['data/1_fcn_10k_negative_node_samples/sample_'+str(i)+'.pkl' for i in sample_indices]\n",
    "negative_sample_files = [str(path) for path in Path('data/2_fcn_10k_negative_node_samples/').glob('sample_*.pkl')]\n",
    "print(len(negative_sample_files))\n",
    "negative_trains = negative_sample_files[:int(0.8*len(negative_sample_files))]\n",
    "negative_valids = negative_sample_files[int(0.8*len(negative_sample_files)):]\n",
    "\n",
    "random.shuffle(negative_trains)\n",
    "negative_trains = negative_trains[:len(positive_trains)]\n",
    "\n",
    "random.shuffle(negative_valids)\n",
    "negative_valids = negative_valids[:len(positive_valids)]\n",
    "\n",
    "\n",
    "train_files = positive_trains + negative_trains\n",
    "valid_files = positive_valids + negative_valids\n",
    "\n",
    "random.shuffle(train_files)\n",
    "\n",
    "\n",
    "# positive_sample_files1 = [str(path) for path in Path('data/1_fcn_10k_positive_node_samples/').glob('sample_*.pkl')]\n",
    "# # positive_sample_files2 = [str(path) for path in Path('positive_node_samples3/').glob('sample_*.pkl')]\n",
    "# positive_sample_files = positive_sample_files1\n",
    "# random.shuffle(positive_sample_files)\n",
    "# positive_sample_files = positive_sample_files[:100000]\n",
    "# print('files loaded')\n",
    "\n",
    "# sample_indices = random.sample(range(0, 3831121), 100000)\n",
    "# negative_sample_files = ['data/1_fcn_10k_negative_node_samples/sample_'+str(i)+'.pkl' for i in sample_indices]\n",
    "# # negative_sample_files = [str(path) for path in Path('data/10k_negative_node_samples/').glob('sample_*.pkl')]\n",
    "# print(len(negative_sample_files))\n",
    "# imbalance_ratio = len(negative_sample_files)/len(positive_sample_files)\n",
    "\n",
    "# random.shuffle(negative_sample_files)\n",
    "# print(len(positive_sample_files), len(negative_sample_files))\n",
    "# negative_sample_files = negative_sample_files[:len(positive_sample_files)]\n",
    "# sample_files = positive_sample_files + negative_sample_files\n",
    "# random.shuffle(sample_files)\n",
    "\n",
    "# valid_sample_files = [str(path) for path in Path('node_samples/').glob('sample_*.pkl')]\n",
    "# random.shuffle(valid_sample_files)\n",
    "# valid_sample_files = valid_sample_files[:2000]\n",
    "\n",
    "# train_files = sample_files[:int(0.8*len(sample_files))]\n",
    "# valid_files = sample_files[int(0.8*len(sample_files)):]\n",
    "\n",
    "\n",
    "train_data = FCNNodeDataset(train_files)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "valid_data = FCNNodeDataset(valid_files)\n",
    "valid_loader = DataLoader(valid_data, batch_size=128, shuffle=False)\n",
    "\n",
    "policy = FCNNodeSelectionLinearPolicy().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "valids = []\n",
    "trains = []\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    train_loss, train_acc = process(policy, train_loader, optimizer)\n",
    "    print(f\"Train loss: {train_loss:0.3f}, accuracy {train_acc:0.3f}\" )\n",
    "    trains.append(train_acc)\n",
    "    \n",
    "    valid_loss, valid_acc = process(policy, valid_loader, None)\n",
    "    print(f\"Valid loss: {valid_loss:0.3f}, accuracy {valid_acc:0.3f}\" )\n",
    "    valids.append(valid_acc)\n",
    "\n",
    "torch.save(policy.state_dict(), 'trained_params_fcn.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f0b37",
   "metadata": {},
   "source": [
    "# Train svm for node selection classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817214b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4165808\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from fcn_policy import FCNNodeDataset, FCNNodeFakeDataset, FCNBranchingPolicy, FCNNodeSelectionPolicy, FCNNodeSelectionLinearPolicy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math \n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "NB_EPOCHS = 150\n",
    "PATIENCE = 10\n",
    "EARLY_STOPPING = 20\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "positive_sample_files = [str(path) for path in Path('data/1_fcn_10k_positive_node_samples/').glob('sample_*.pkl')]\n",
    "positive_trains = positive_sample_files[:int(0.8*len(positive_sample_files))]\n",
    "positive_valids = positive_sample_files[int(0.8*len(positive_sample_files)):]\n",
    "\n",
    "# negative_sample_files = ['data/1_fcn_10k_negative_node_samples/sample_'+str(i)+'.pkl' for i in sample_indices]\n",
    "negative_sample_files = [str(path) for path in Path('data/1_fcn_10k_negative_node_samples/').glob('sample_*.pkl')]\n",
    "print(len(negative_sample_files))\n",
    "negative_trains = negative_sample_files[:int(0.8*len(negative_sample_files))]\n",
    "negative_valids = negative_sample_files[int(0.8*len(negative_sample_files)):]\n",
    "\n",
    "random.shuffle(negative_trains)\n",
    "negative_trains = negative_trains[:len(positive_trains)]\n",
    "\n",
    "random.shuffle(negative_valids)\n",
    "negative_valids = negative_valids[:len(positive_valids)]\n",
    "\n",
    "\n",
    "train_files = positive_trains + negative_trains\n",
    "valid_files = positive_valids + negative_valids\n",
    "\n",
    "random.shuffle(train_files)\n",
    "random.shuffle(valid_files)\n",
    "\n",
    "\n",
    "train_data = FCNNodeDataset(train_files)\n",
    "train_loader = DataLoader(train_data, batch_size=10000, shuffle=True)\n",
    "train_loader_iter = iter(train_loader)\n",
    "train_set = next(train_loader_iter)\n",
    "\n",
    "valid_data = FCNNodeDataset(valid_files)\n",
    "valid_loader = DataLoader(valid_data, batch_size=1000, shuffle=False)\n",
    "valid_loader_iter = iter(valid_loader)\n",
    "valid_set = next(valid_loader_iter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bfa848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "print('training model')\n",
    "# model = svm.SVC(kernel='rbf', probability=True, verbose=True, gamma=0.01)\n",
    "model = svm.SVC(kernel='linear', probability=True, verbose=True)\n",
    "clf = model.fit(train_set[0], train_set[1])\n",
    "\n",
    "score_valid = model.score(valid_set[0], valid_set[1])\n",
    "score_train = model.score(train_set[0], train_set[1])\n",
    "print(score_valid, score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a21e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.546875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3b0fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f895608",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_train = model.predict(train_set[:1000])\n",
    "pred_labels_valid = model.predict(valid_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75887269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  ..., False,  True, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c380d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1-score')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(trains)\n",
    "plt.plot(valids)\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('F1-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eece6b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211791"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "885c1a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d4e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from fcn_policy import FCNNodeDataset, FCNBranchingPolicy, FCNNodeSelectionPolicy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math \n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from  acr_bb import Observation, ACRBBenv, DefaultBranchingPolicy, RandomPolicy, LinearObservation\n",
    "from fcn_training import FCNDataset, FCNBranchingPolicy, FCNNodeSelectionPolicy \n",
    "\n",
    "MAX_SAMPLES = 100000\n",
    "\n",
    "N = 8 # antennas\n",
    "M = 4 # users\n",
    "expert_prob = 0.5\n",
    "\n",
    "def instance_generator(M, N):\n",
    "    while 1:\n",
    "        yield np.random.randn(2,N,M)\n",
    "\n",
    "# instances = np.random.randn(MAX_SAMPLES, 2, N, M)\n",
    "instances = instance_generator(M,N)\n",
    "\n",
    "env = ACRBBenv(observation_function=LinearObservation)\n",
    "\n",
    "obs, _,_,_,_  = env.reset(next(instances))\n",
    "\n",
    "obs, _,_,_,_ = env.step(2)\n",
    "\n",
    "\n",
    "# a = obs.observation[24:28] + 1j*obs.observation[28:32]\n",
    "# angle = np.angle(a) \n",
    "# angle[angle<0] += 2*np.pi\n",
    "# lb = obs.observation[24+3*8*4+2:126]\n",
    "# ub = obs.observation[126:130]\n",
    "# if np.random.rand(1)>0.3:\n",
    "#     mid = lb + np.random.rand(4)*(ub-lb)\n",
    "#     r = 1\n",
    "#     comp = np.exp(1j*mid)\n",
    "#     print('here')\n",
    "# else:\n",
    "#     mid = np.random.rand(4)*2*np.pi\n",
    "#     r = 1\n",
    "#     comp = np.exp(1j*mid)\n",
    "# if sum(mid<ub)+sum(mid>lb) == 8:\n",
    "#     label = 1\n",
    "# else:\n",
    "#     label = 0\n",
    "\n",
    "# print(mid)\n",
    "# print(lb)\n",
    "# print(ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.H_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.observation[24:24+ 32*2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "fcc28fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([158])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cat((torch.tensor(np.real(mid)), torch.tensor(np.imag(mid)), torch.tensor(np.abs(mid)), torch.tensor(obs.observation))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca36ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f61e6c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76917677, 0.74182199, 0.45606417, 0.49266163, 0.1881559 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8c015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a659e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(4)*2*np.pi\n",
    "b = np.random.rand(4)*2*np.pi\n",
    "c = np.random.rand(4)*2*np.pi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0cc1d4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(c< a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "797fb55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b<c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8e915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ab9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60488929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5268b37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.+1.2246468e-16j, -1.+1.2246468e-16j, -1.+1.2246468e-16j,\n",
       "       -1.+1.2246468e-16j])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd8c869a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37277933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.28318531, 6.28318531, 6.28318531, 6.28318531])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7cd3709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3*np.pi/2 + np.pi/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bf60a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.497787143782138"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2481f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1*np.exp(1j*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c2697b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.497787143782138"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.angle(b)+2*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9e3937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249e10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53537ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1)> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14221424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14602925, 3.63327729, 1.08245673, 1.55202076])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cc6f766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.90497712+0.28017676j, -2.52041463-1.34981818j,\n",
       "        1.24287801+2.33950317j,  0.02418395+1.28790262j])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca6524f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<acr_bb.Observation at 0x7f6e097478d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a5aad03",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ACRBBenv' object has no attribute 'observation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f6d3d8ab6b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ACRBBenv' object has no attribute 'observation'"
     ]
    }
   ],
   "source": [
    "env.observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40d122de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<acr_bb.ACRBBenv at 0x7f713c9ba358>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = FCNNodeSelectionPolicy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a8ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d476fb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([146])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d5c6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b36965fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "with gzip.open('fcn_negative_node_samples/sample_10.pkl','rb') as f:\n",
    "    sample = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f80cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3041506361597035"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.linalg.norm(np.random.randn(5,1),'fro')**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4731fecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.49778714])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*np.pi + np.angle([1-1j])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfe34b9b52c4e45fab7b1847c7129bfa972d8ad3fe0814fefa0caa86633382ec"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
