{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0044bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, inp):\n",
    "#         for layer in self.main:\n",
    "#             inp = layer(inp)\n",
    "        print('forward')\n",
    "        return self.main(inp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a051803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setupsetupsetup\n",
      "setup\n",
      "\n",
      "setupforwardforward\n",
      "\n",
      "\n",
      "forwardforward\n",
      "forward\n",
      "\n",
      "\n",
      "output\n",
      "output\n",
      "output\n",
      "output\n",
      "output\n",
      "[tensor([[0.4567],\n",
      "        [0.5829]]), tensor([[0.3078],\n",
      "        [0.7254]]), tensor([[0.3757],\n",
      "        [0.6612]]), tensor([[0.4358],\n",
      "        [0.6033]]), tensor([[0.4414],\n",
      "        [0.5979]])]\n",
      "setupsetupsetup\n",
      "\n",
      "setupforwardsetup\n",
      "forward\n",
      "\n",
      "forward\n",
      "\n",
      "forward\n",
      "forward\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-39:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 220, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 411, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ca4d9ceee2fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "# import torch.multiprocessing as mp\n",
    "ref_net = network()\n",
    "def f(x):\n",
    "    net = network()\n",
    "    net.load_state_dict(ref_net.state_dict())\n",
    "    print('setup')\n",
    "#     with torch.no_grad():\n",
    "#         print(next(net.parameters()))\n",
    "    out = net(x)\n",
    "    print('output')\n",
    "    return out.detach()\n",
    "\n",
    "a = list(torch.randn(5,2,100))\n",
    "# for i in range(2):\n",
    "with Pool(5) as p:\n",
    "    print(p.map(f, a))\n",
    "fcn = torch.nn.Sequential(\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "b = fcn(torch.randn(2,100))\n",
    "with Pool(5) as p:\n",
    "    print(p.map(f, a))\n",
    "\n",
    "with Pool(5) as p:\n",
    "    print(p.map(f, a))\n",
    "\n",
    "with Pool(5) as p:\n",
    "    print(p.map(f, a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6329ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKPOINT One\n",
      "CHECKPOINT Two\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import multiprocessing,nn \n",
    " \n",
    "output_size = 13 \n",
    "input_dim = output_size \n",
    "hidden_dim = 128 \n",
    "layer_dim = 1 \n",
    " \n",
    "lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=layer_dim, batch_first=True) \n",
    "torch.save(lstm.state_dict(),\"plain.pt\") \n",
    " \n",
    "def run(state): \n",
    "    model = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=layer_dim, batch_first=True) \n",
    "    model.load_state_dict(torch.load(\"plain.pt\")) \n",
    "    x=model(state) \n",
    "    return x \n",
    " \n",
    "state=torch.rand(1,10,13) \n",
    "threads=[] \n",
    "for i in range(1): \n",
    "    p = multiprocessing.Process(target=run,args=(state,)) \n",
    "    threads.append(p) \n",
    "for i in threads: \n",
    "    i.start() \n",
    "for i in threads: \n",
    "    i.join() \n",
    "print(\"CHECKPOINT One\") \n",
    "# run(state) \n",
    "fcn = torch.nn.Sequential(\n",
    "            nn.Linear(100, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.Linear(100,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "a = fcn(torch.randn(2,100))\n",
    "print(\"CHECKPOINT Two\")\n",
    "threads=[] \n",
    "for i in range(1): \n",
    "    p = multiprocessing.Process(target=run,args=(state,)) \n",
    "    threads.append(p) \n",
    "for i in threads: \n",
    "    i.start() \n",
    "for i in threads: \n",
    "    i.join()\n",
    "print(\"CHECKPOINT Three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077ff7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9191,  0.5761, -0.8266, -1.2741,  0.6247,  0.2905, -0.6033,  0.1773,\n",
       "          0.9678,  1.5657,  0.6728,  1.1733, -0.1721, -0.7883, -0.1769,  0.0442,\n",
       "          1.0815, -1.6525, -1.2967,  0.8736,  0.1240,  0.3329, -0.1628, -0.4552,\n",
       "         -1.9090, -0.3202, -0.6133, -0.1693, -0.3698,  0.0447, -1.2526,  0.8087,\n",
       "          0.2611, -0.3090,  0.8964, -0.3075,  0.5231,  0.2576, -0.9545,  0.2401,\n",
       "         -0.8211,  1.1077, -0.0126, -1.2956,  0.5740, -0.4767,  1.0674, -0.6908,\n",
       "         -0.7485,  0.0574, -2.2930,  1.1796,  0.1569,  0.1387, -0.2047, -0.7179,\n",
       "         -0.9344,  0.8584, -0.7811, -1.3700,  1.2836,  2.0756, -0.1297,  0.8812,\n",
       "          0.1470,  0.5177,  0.3993, -1.7327,  0.2303,  0.0840,  0.8305, -0.3574,\n",
       "         -0.8228,  1.2897, -0.6825, -0.8002, -0.2280, -0.1035,  0.6795,  0.7520,\n",
       "         -0.0608,  1.2787,  0.3450,  0.2175, -0.5777,  0.8274,  0.9988, -0.1459,\n",
       "          2.1954, -0.0731,  0.0051,  1.2742,  0.3184, -1.5703,  0.1134,  1.1136,\n",
       "         -1.1635, -1.9181, -0.2112,  0.5626],\n",
       "        [-1.2725,  0.2288, -0.2513,  0.6228, -1.1828,  0.3494, -1.2372, -0.5458,\n",
       "          0.1213, -1.1713,  0.2168,  1.6994,  1.0868, -1.1787,  0.2543,  0.0758,\n",
       "          1.1975,  0.1618, -0.3274,  1.1558,  2.2576, -0.8443, -0.0053,  0.8174,\n",
       "         -1.6603, -1.0752,  0.0075, -0.8961, -0.7274, -0.3478,  2.8510, -1.6781,\n",
       "         -2.4549, -0.1719, -0.7283, -0.7659,  0.3513, -0.3503,  0.3786,  1.9955,\n",
       "         -0.4534,  0.0926,  0.9764,  0.2325,  0.0210,  0.3091, -0.0559, -0.0707,\n",
       "          0.5328,  0.8877, -1.3030, -1.1933,  0.0356,  0.4461,  0.4529, -0.4098,\n",
       "         -2.2384, -1.0221,  0.1201,  0.2310,  0.8441, -0.4067,  0.3157, -1.1801,\n",
       "          0.7786, -1.5166,  0.5559, -0.1414,  1.4705,  0.1302,  0.6534,  1.0151,\n",
       "          1.9449, -0.3627, -1.6020, -0.5535,  0.8363, -1.6541,  2.3489,  0.4233,\n",
       "          0.3899, -0.2110, -0.4105, -0.7100, -0.1331, -1.3647, -0.2871, -0.5723,\n",
       "         -0.1383,  0.6174, -1.0524, -2.6710, -1.2535,  0.8311,  0.9467, -1.7081,\n",
       "          0.7123, -0.8488, -0.5084,  0.4606]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from setting import TASK\n",
    "\n",
    "from antenna_selection.as_bb import ASBBenv as Environment, DefaultBranchingPolicy, solve_bb\n",
    "if TASK == 'antenna_selection':\n",
    "    from antenna_selection.observation import Observation, LinearObservation\n",
    "\n",
    "elif TASK == 'single_cast_beamforming':\n",
    "    from single_beamforming.observation import Observation, LinearObservation\n",
    "    # from single_beamforming.acr_bb import ACRBBenv as Environment, DefaultBranchingPolicy, solve_bb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from gnn_policy import GNNPolicy, GNNNodeSelectionPolicy\n",
    "from tqdm import tqdm\n",
    "import torch_geometric\n",
    "import gzip\n",
    "import pickle\n",
    "from gnn_dataset import GraphNodeDataset, instance_generator\n",
    "from pathlib import Path\n",
    "from gnn_dataset import get_graph_from_obs\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from models.fcn_policy import FCNNodeSelectionLinearPolicy, FCNNodeDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MAX_STEPS = 1000\n",
    "    \n",
    "\n",
    "\n",
    "class DataCollect(object):\n",
    "    def __init__(self, observation_function=Observation, max_ant=None, policy='oracle',filepath=None, policy_type='gnn'):\n",
    "        # env = Environment(observation_function=observation_function, epsilon=0.002)\n",
    "        self.observation_function = observation_function\n",
    "        self.max_ant = max_ant\n",
    "        self.filepath = filepath\n",
    "        self.branching_policy = DefaultBranchingPolicy()\n",
    "        self.policy_type = policy_type\n",
    "        self.node_select_policy = None\n",
    "\n",
    "\n",
    "    def collect_data(self, instance_gen, num_instances=10, policy='oracle'):\n",
    "        # self.node_select_policy = policy.copy()\n",
    "        N, M = next(instance_gen).shape[1], next(instance_gen).shape[2]\n",
    "        H = np.random.randn(num_instances, N, M) + 1j*np.random.randn(num_instances, N,M)    \n",
    "        instances = np.stack((np.real(H), np.imag(H)), axis=1)\n",
    "        \n",
    "\n",
    "        arguments_oracle = list(zip(list(instances), [self.max_ant]*num_instances))\n",
    "        print('starting first pool')\n",
    "        with Pool(num_instances) as p:\n",
    "            out_oracle = p.map(self.solve_bb_process, arguments_oracle)\n",
    "            print('first pool ended')\n",
    "\n",
    "\n",
    "        optimal_solution_list = [out_oracle[i][0] for i in range(len(out_oracle))]\n",
    "        optimal_objective_list = [out_oracle[i][1] for i in range(len(out_oracle))]\n",
    "\n",
    "        arguments_ml = list(zip(list(instances), optimal_solution_list, optimal_objective_list, range(num_instances), [policy]*num_instances))\n",
    "        print('starting second pool')\n",
    "        with Pool(num_instances) as p:\n",
    "            out_ml = p.map(self.collect_data_instance, arguments_ml)\n",
    "            # out_ml = p.map(self.dummy_collect_instance, arguments_ml)\n",
    "\n",
    "            print('second pool ended')\n",
    "        \n",
    "        avg_oracle_steps = np.mean(np.array([out_oracle[i][2] for i in range(len(out_oracle))]))\n",
    "        avg_oracle_time = np.mean(np.array([out_oracle[i][3] for i in range(len(out_oracle))]))\n",
    "        avg_ml_time = np.mean(np.array([out_ml[i][0] for i in range(len(out_ml))]))\n",
    "        avg_ml_ogap = np.mean(np.array([out_ml[i][1] for i in range(len(out_ml))]))\n",
    "        avg_ml_steps = np.mean(np.array([out_ml[i][2] for i in range(len(out_ml))]))\n",
    "\n",
    "        return avg_ml_time/avg_oracle_time, avg_ml_ogap, avg_ml_steps/avg_oracle_steps\n",
    "        # return 0, 0, 0\n",
    "\n",
    "    def dummy_collect_instance(self, arguments):\n",
    "        instance, w_optimal, optimal_objective, file_count = arguments\n",
    "        print('started collect instance {}'.format(file_count))\n",
    "        import time\n",
    "        time.sleep(1)\n",
    "        print('ended collect instance {}'.format(file_count))\n",
    "\n",
    "\n",
    "    def collect_data_instance(self, arguments):\n",
    "        instance, w_optimal, optimal_objective, file_count, policy = arguments\n",
    "        print('function {} started'.format(file_count))\n",
    "        #TODO: do the following with parameters not filename\n",
    "        env = Environment(observation_function=self.observation_function, epsilon=0.002)\n",
    "        env.set_node_select_policy(node_select_policy_path=policy, policy_type=self.policy_type)\n",
    "        \n",
    "        env.reset(instance, max_ant=self.max_ant,  oracle_opt=w_optimal)\n",
    "        branching_policy = DefaultBranchingPolicy()\n",
    "        t1 = time.time()\n",
    "        timestep = 0\n",
    "        done = False\n",
    "        time_taken = 0\n",
    "        sum_label = 0\n",
    "        node_counter = 0\n",
    "        while timestep < MAX_STEPS and len(env.nodes)>0 and not done:\n",
    "            print('data instance timestep', timestep, env.global_U, env.global_L)\n",
    "            print('function {} now fathom'.format(file_count))\n",
    "            \n",
    "            env.fathom_nodes()\n",
    "            if len(env.nodes) == 0:\n",
    "                break\n",
    "            node_id, node_feats, label = env.select_node()\n",
    "\n",
    "            if len(env.nodes) == 0:\n",
    "                break\n",
    "            time_taken += time.time()-t1\n",
    "            sum_label += label\n",
    "            self.save_file((node_feats, label), file_count, node_counter)\n",
    "            node_counter += 1\n",
    "            t1 = time.time()\n",
    "            print('function {} now prune'.format(file_count))\n",
    "\n",
    "            prune_node = env.prune(node_feats)\n",
    "            # prune_node = False\n",
    "            if prune_node:\n",
    "                env.delete_node(node_id)\n",
    "                continue\n",
    "            else:\n",
    "                print('function {} now push children'.format(file_count))\n",
    "\n",
    "                branching_var = branching_policy.select_variable(node_feats, env.action_set_indices)\n",
    "                done = env.push_children(branching_var, node_id)\n",
    "            timestep = timestep+1\n",
    "        print('function {} now ended'.format(file_count))\n",
    "        \n",
    "        ml = np.linalg.norm(env.W_incumbent, 'fro')**2\n",
    "        ogap = ((ml - optimal_objective)/optimal_objective)*100\n",
    "        time_taken += time.time() - t1\n",
    "        print('instance result', timestep, ogap, time_taken, sum_label, optimal_objective, ml)\n",
    "        return timestep, ogap, time_taken\n",
    "\n",
    "    def solve_bb_process(self, tup):\n",
    "        instance, max_ant = tup\n",
    "        return solve_bb(instance, max_ant)\n",
    "        \n",
    "\n",
    "    def save_file(self, sample, file_count, node_counter):\n",
    "        print('file {}_{} save started'.format(file_count, node_counter))\n",
    "        if self.filepath is not None:\n",
    "            filename = self.filepath + f'sample_{file_count}_{node_counter}.pkl'\n",
    "            with gzip.open(filename, 'wb') as f:\n",
    "                pickle.dump(sample, f)\n",
    "        print('file {} {} saved'.format(file_count, node_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance, w_optimal, optimal_objective, file_count, policy = arguments\n",
    "        print('function {} started'.format(file_count))\n",
    "        #TODO: do the following with parameters not filename\n",
    "        env = Environment(observation_function=self.observation_function, epsilon=0.002)\n",
    "        env.set_node_select_policy(node_select_policy_path=policy, policy_type=self.policy_type)\n",
    "        \n",
    "        env.reset(instance, max_ant=self.max_ant,  oracle_opt=w_optimal)\n",
    "        branching_policy = DefaultBranchingPolicy()\n",
    "        t1 = time.time()\n",
    "        timestep = 0\n",
    "        done = False\n",
    "        time_taken = 0\n",
    "        sum_label = 0\n",
    "        node_counter = 0\n",
    "        while timestep < MAX_STEPS and len(env.nodes)>0 and not done:\n",
    "            print('data instance timestep', timestep, env.global_U, env.global_L)\n",
    "            print('function {} now fathom'.format(file_count))\n",
    "            \n",
    "            env.fathom_nodes()\n",
    "            if len(env.nodes) == 0:\n",
    "                break\n",
    "            node_id, node_feats, label = env.select_node()\n",
    "\n",
    "            if len(env.nodes) == 0:\n",
    "                break\n",
    "            time_taken += time.time()-t1\n",
    "            sum_label += label\n",
    "            node_counter += 1\n",
    "            t1 = time.time()\n",
    "            print('function {} now prune'.format(file_count))\n",
    "\n",
    "            prune_node = env.prune(node_feats)\n",
    "            # prune_node = False\n",
    "            if prune_node:\n",
    "                env.delete_node(node_id)\n",
    "                continue\n",
    "            else:\n",
    "                print('function {} now push children'.format(file_count))\n",
    "\n",
    "                branching_var = branching_policy.select_variable(node_feats, env.action_set_indices)\n",
    "                done = env.push_children(branching_var, node_id)\n",
    "            timestep = timestep+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc2544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98407d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47be25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(torch.randn(5,2,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca7870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
